{"status": "failed", "score": 0.0, "error": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input.1 for the following indices\n index: 2 Got: 64 Expected: 256\n index: 3 Got: 64 Expected: 256\n Please fix either the inputs/outputs or the model.\n\nNo module named 'onnxruntime'\n\nNo module named 'onnxruntime'\n\n...", "details": {"name": "bioimageio format validation", "source_name": "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/rdf.yaml?version=v0", "id": "affable-shark", "type": "model", "format_version": "0.5.5", "status": "failed", "metadata_completeness": 0.7888888888888889, "details": [{"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/zero_mean_unit_variance.ijm?version=v0": null, "zero_mean_unit_variance.ijm": "767f2c3a50e36365c30b9e46e57fcf82e606d337e8a48d4a2440dc512813d186", "https://www.nature.com/articles/s41592-019-0612-7": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_input_0.npy?version=v0": null, "test_input_0.npy": "c29bd6e16e3f7856217b407ba948222b1c2a0da41922a0f79297e25588614fe2", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_input_0.tif?version=v0": null, "sample_input_0.tif": "a24b3c708b6ca6825494eb7c5a4d221335fb3eef5eb9d03f4108907cdaad2bf9", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_output_0.npy?version=v0": null, "test_output_0.npy": "510181f38930e59e4fd8ecc03d6ea7c980eb6609759655f2d4a41fe36108d5f5", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_output_0.tif?version=v0": null, "sample_output_0.tif": "e8f99aabe8405427f515eba23a49f58ba50302f57d1fdfd07026e1984f836c5e", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.onnx?version=v0": null, "weights.onnx": "df913b85947f5132bcdaf81d91af0963f60d44f4caf8a4fec672d96a2f327b44", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/unet.py?version=v0": null, "unet.py": "7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3", "weights.pt": "608f52cd7f5119f7a7b8272395b0c169714e8be34536eaf159820f72a1d6a5b7", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "8410950508655a300793b389c815dc30b1334062fc1dadb1e15e55a93cbb99a0"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.5.5", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/zero_mean_unit_variance.ijm?version=v0": null, "zero_mean_unit_variance.ijm": "767f2c3a50e36365c30b9e46e57fcf82e606d337e8a48d4a2440dc512813d186", "https://www.nature.com/articles/s41592-019-0612-7": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_input_0.npy?version=v0": null, "test_input_0.npy": "c29bd6e16e3f7856217b407ba948222b1c2a0da41922a0f79297e25588614fe2", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_input_0.tif?version=v0": null, "sample_input_0.tif": "a24b3c708b6ca6825494eb7c5a4d221335fb3eef5eb9d03f4108907cdaad2bf9", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_output_0.npy?version=v0": null, "test_output_0.npy": "510181f38930e59e4fd8ecc03d6ea7c980eb6609759655f2d4a41fe36108d5f5", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_output_0.tif?version=v0": null, "sample_output_0.tif": "e8f99aabe8405427f515eba23a49f58ba50302f57d1fdfd07026e1984f836c5e", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.onnx?version=v0": null, "weights.onnx": "df913b85947f5132bcdaf81d91af0963f60d44f4caf8a4fec672d96a2f327b44", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/unet.py?version=v0": null, "unet.py": "7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3", "weights.pt": "608f52cd7f5119f7a7b8272395b0c169714e8be34536eaf159820f72a1d6a5b7", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "8410950508655a300793b389c815dc30b1334062fc1dadb1e15e55a93cbb99a0"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (onnx)", "status": "passed", "loc": ["weights", "onnx"], "errors": [], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "onnxruntime", "pip"]}, "saved_conda_compare": "Success. All the packages in the specification file are present in the environment with matching version and build string.\n"}, {"name": "Run onnx inference for parametrized inputs", "status": "failed", "loc": ["weights", "onnx"], "errors": [{"loc": ["weights", "onnx"], "msg": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input.1 for the following indices\n index: 2 Got: 64 Expected: 256\n index: 3 Got: 64 Expected: 256\n Please fix either the inputs/outputs or the model.", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    998 \u2502   \u2502   ) as prediction_pipeline:                                                         \u2502\n\u2502    999 \u2502   \u2502   \u2502   for n, batch_size, inputs, exptected_output_shape in generate_test_cases():   \u2502\n\u2502   1000 \u2502   \u2502   \u2502   \u2502   error: Optional[str] = None                                               \u2502\n\u2502 \u2771 1001 \u2502   \u2502   \u2502   \u2502   result = prediction_pipeline.predict_sample_without_blocking(inputs)      \u2502\n\u2502   1002 \u2502   \u2502   \u2502   \u2502   if len(result.members) != len(exptected_output_shape):                    \u2502\n\u2502   1003 \u2502   \u2502   \u2502   \u2502   \u2502   error = (                                                             \u2502\n\u2502   1004 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   f\"Expected {len(exptected_output_shape)} outputs,\"                \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   157 \u2502   \u2502   if not skip_preprocessing:                                                         \u2502\n\u2502   158 \u2502   \u2502   \u2502   self.apply_preprocessing(sample)                                               \u2502\n\u2502   159 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 160 \u2502   \u2502   output = self._adapter.forward(sample)                                             \u2502\n\u2502   161 \u2502   \u2502   if not skip_postprocessing:                                                        \u2502\n\u2502   162 \u2502   \u2502   \u2502   self.apply_postprocessing(output)                                              \u2502\n\u2502   163                                                                                            \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   199 \u2502   \u2502   \u2502   )                                                                              \u2502\n\u2502   200 \u2502   \u2502   \u2502   for in_id, in_order in zip(self._input_ids, self._input_axes)                  \u2502\n\u2502   201 \u2502   \u2502   ]                                                                                  \u2502\n\u2502 \u2771 202 \u2502   \u2502   output_arrays = self._forward_impl(input_arrays)                                   \u2502\n\u2502   203 \u2502   \u2502   assert len(output_arrays) <= len(self._output_ids)                                 \u2502\n\u2502   204 \u2502   \u2502   output_tensors = [                                                                 \u2502\n\u2502   205 \u2502   \u2502   \u2502   None if a is None else Tensor(a, dims=d)                                       \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   36 \u2502   def _forward_impl(                                                                      \u2502\n\u2502   37 \u2502   \u2502   self, input_arrays: Sequence[Optional[NDArray[Any]]]                                \u2502\n\u2502   38 \u2502   ) -> List[Optional[NDArray[Any]]]:                                                      \u2502\n\u2502 \u2771 39 \u2502   \u2502   result: Any = self._session.run(                                                    \u2502\n\u2502   40 \u2502   \u2502   \u2502   None, dict(zip(self._input_names, input_arrays))                                \u2502\n\u2502   41 \u2502   \u2502   )                                                                                   \u2502\n\u2502   42 \u2502   \u2502   if is_list(result) or is_tuple(result):                                             \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    270 \u2502   \u2502   if not output_names:                                                              \u2502\n\u2502    271 \u2502   \u2502   \u2502   output_names = [output.name for output in self._outputs_meta]                 \u2502\n\u2502    272 \u2502   \u2502   try:                                                                              \u2502\n\u2502 \u2771  273 \u2502   \u2502   \u2502   return self._sess.run(output_names, input_feed, run_options)                  \u2502\n\u2502    274 \u2502   \u2502   except C.EPFail as err:                                                           \u2502\n\u2502    275 \u2502   \u2502   \u2502   if self._enable_fallback:                                                     \u2502\n\u2502    276 \u2502   \u2502   \u2502   \u2502   print(f\"EP Error: {err!s} using {self._providers}\")                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nInvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input.1 for the following indices\n index: 2 Got: 64 Expected: 256\n index: 3 Got: 64 Expected: 256\n Please fix either the inputs/outputs or the model.\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #00ffff; text-decoration-color: #00ffff}\n.r8 {color: #808000; text-decoration-color: #808000}\n.r9 {color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline}\n.r10 {font-weight: bold; text-decoration: underline}\n.r11 {color: #808080; text-decoration-color: #808080}\n.r12 {color: #00ff00; text-decoration-color: #00ff00}\n.r13 {color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline}\n.r14 {color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline}\n.r15 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r16 {font-weight: bold}\n.r17 {color: #008080; text-decoration-color: #008080; font-weight: bold}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 998 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 999 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">for</span> n, batch_size, inputs, exptected_output_shape <span class=\"r6\">in</span> generate_test_cases():   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">1000 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span>error: Optional[<span class=\"r7\">str</span>] = <span class=\"r5\">None</span>                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>1001 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span>result = prediction_pipeline.predict_sample_without_blocking(inputs)      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">1002 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r7\">len</span>(result.members) != <span class=\"r7\">len</span>(exptected_output_shape):                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">1003 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>error = (                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">1004 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r8\">f&quot;Expected {</span><span class=\"r7\">len</span>(exptected_output_shape)<span class=\"r8\">} outputs,&quot;</span>                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">157 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r6\">not</span> skip_preprocessing:                                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">158 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">self</span>.apply_preprocessing(sample)                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">159 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>160 <span class=\"r4\">\u2502   \u2502   </span>output = <span class=\"r9\">self</span><span class=\"r10\">._adapter.forward(sample)</span>                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">161 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r6\">not</span> skip_postprocessing:                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">162 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">self</span>.apply_postprocessing(output)                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">163 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">199 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>)                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">200 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">for</span> in_id, in_order <span class=\"r6\">in</span> <span class=\"r7\">zip</span>(<span class=\"r7\">self</span>._input_ids, <span class=\"r7\">self</span>._input_axes)                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">201 </span><span class=\"r4\">\u2502   \u2502   </span>]                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>202 <span class=\"r4\">\u2502   \u2502   </span>output_arrays = <span class=\"r9\">self</span><span class=\"r10\">._forward_impl(input_arrays)</span>                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">203 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r7\">len</span>(output_arrays) &lt;= <span class=\"r7\">len</span>(<span class=\"r7\">self</span>._output_ids)                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">204 </span><span class=\"r4\">\u2502   \u2502   </span>output_tensors = [                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">205 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">None</span> <span class=\"r5\">if</span> a <span class=\"r6\">is</span> <span class=\"r5\">None</span> <span class=\"r5\">else</span> Tensor(a, dims=d)                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">36 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">def</span><span class=\"r11\"> </span><span class=\"r12\">_forward_impl</span>(                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">37 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r7\">self</span>, input_arrays: Sequence[Optional[NDArray[Any]]]                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">38 </span><span class=\"r4\">\u2502   </span>) -&gt; List[Optional[NDArray[Any]]]:                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>39 <span class=\"r4\">\u2502   \u2502   </span>result: Any = <span class=\"r9\">self</span><span class=\"r10\">._session.run(</span>                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">40 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r13\">None</span><span class=\"r10\">, </span><span class=\"r9\">dict</span><span class=\"r10\">(</span><span class=\"r9\">zip</span><span class=\"r10\">(</span><span class=\"r9\">self</span><span class=\"r10\">._input_names, input_arrays))</span>                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">41 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r10\">)</span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">42 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> is_list(result) <span class=\"r6\">or</span> is_tuple(result):                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 270 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r6\">not</span> output_names:                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 271 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>output_names = [output.name <span class=\"r5\">for</span> output <span class=\"r6\">in</span> <span class=\"r7\">self</span>._outputs_meta]                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 272 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 273 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> <span class=\"r7\">self</span>._sess.run(output_names, input_feed, run_options)                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 274 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r13\">except</span><span class=\"r10\"> C.EPFail </span><span class=\"r13\">as</span><span class=\"r10\"> err:</span>                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 275 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r13\">if</span><span class=\"r10\"> </span><span class=\"r9\">self</span><span class=\"r10\">._enable_fallback:</span>                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 276 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r9\">print</span><span class=\"r10\">(</span><span class=\"r14\">f&quot;EP Error: {</span><span class=\"r10\">err</span><span class=\"r14\">!s} using {</span><span class=\"r9\">self</span><span class=\"r10\">._providers</span><span class=\"r14\">}&quot;</span><span class=\"r10\">)</span>                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r15\">InvalidArgument: </span><span class=\"r16\">[</span>ONNXRuntimeError<span class=\"r16\">]</span> : <span class=\"r17\">2</span> : INVALID_ARGUMENT : Got invalid dimensions for input: input.<span class=\"r17\">1</span> for the following indices\n index: <span class=\"r17\">2</span> Got: <span class=\"r17\">64</span> Expected: <span class=\"r17\">256</span>\n index: <span class=\"r17\">3</span> Got: <span class=\"r17\">64</span> Expected: <span class=\"r17\">256</span>\n Please fix either the inputs/outputs or the model.\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/zero_mean_unit_variance.ijm?version=v0": null, "zero_mean_unit_variance.ijm": "767f2c3a50e36365c30b9e46e57fcf82e606d337e8a48d4a2440dc512813d186", "https://www.nature.com/articles/s41592-019-0612-7": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_input_0.npy?version=v0": null, "test_input_0.npy": "c29bd6e16e3f7856217b407ba948222b1c2a0da41922a0f79297e25588614fe2", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_input_0.tif?version=v0": null, "sample_input_0.tif": "a24b3c708b6ca6825494eb7c5a4d221335fb3eef5eb9d03f4108907cdaad2bf9", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_output_0.npy?version=v0": null, "test_output_0.npy": "510181f38930e59e4fd8ecc03d6ea7c980eb6609759655f2d4a41fe36108d5f5", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_output_0.tif?version=v0": null, "sample_output_0.tif": "e8f99aabe8405427f515eba23a49f58ba50302f57d1fdfd07026e1984f836c5e", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.onnx?version=v0": null, "weights.onnx": "df913b85947f5132bcdaf81d91af0963f60d44f4caf8a4fec672d96a2f327b44", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/unet.py?version=v0": null, "unet.py": "7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3", "weights.pt": "608f52cd7f5119f7a7b8272395b0c169714e8be34536eaf159820f72a1d6a5b7", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "8410950508655a300793b389c815dc30b1334062fc1dadb1e15e55a93cbb99a0"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.5.4", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/zero_mean_unit_variance.ijm?version=v0": null, "zero_mean_unit_variance.ijm": "767f2c3a50e36365c30b9e46e57fcf82e606d337e8a48d4a2440dc512813d186", "https://www.nature.com/articles/s41592-019-0612-7": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_input_0.npy?version=v0": null, "test_input_0.npy": "c29bd6e16e3f7856217b407ba948222b1c2a0da41922a0f79297e25588614fe2", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_input_0.tif?version=v0": null, "sample_input_0.tif": "a24b3c708b6ca6825494eb7c5a4d221335fb3eef5eb9d03f4108907cdaad2bf9", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_output_0.npy?version=v0": null, "test_output_0.npy": "510181f38930e59e4fd8ecc03d6ea7c980eb6609759655f2d4a41fe36108d5f5", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_output_0.tif?version=v0": null, "sample_output_0.tif": "e8f99aabe8405427f515eba23a49f58ba50302f57d1fdfd07026e1984f836c5e", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.onnx?version=v0": null, "weights.onnx": "df913b85947f5132bcdaf81d91af0963f60d44f4caf8a4fec672d96a2f327b44", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/unet.py?version=v0": null, "unet.py": "7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3", "weights.pt": "608f52cd7f5119f7a7b8272395b0c169714e8be34536eaf159820f72a1d6a5b7", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "8410950508655a300793b389c815dc30b1334062fc1dadb1e15e55a93cbb99a0"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (onnx)", "status": "failed", "loc": ["weights", "onnx"], "errors": [{"loc": ["weights", "onnx"], "msg": "No module named 'onnxruntime'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   642 \u2502   \u2502   inputs = get_test_inputs(model)                                                    \u2502\n\u2502   643 \u2502   \u2502   expected = get_test_outputs(model)                                                 \u2502\n\u2502   644 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 645 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   646 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   647 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   648 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(inputs)          \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   127 \u2502   \u2502   \u2502   elif wf == \"onnx\":                                                             \u2502\n\u2502   128 \u2502   \u2502   \u2502   \u2502   assert weights.onnx is not None                                            \u2502\n\u2502   129 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502 \u2771 130 \u2502   \u2502   \u2502   \u2502   \u2502   from .onnx_backend import ONNXModelAdapter                             \u2502\n\u2502   131 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502   132 \u2502   \u2502   \u2502   \u2502   \u2502   return ONNXModelAdapter(                                               \u2502\n\u2502   133 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    2 import warnings                                                                             \u2502\n\u2502    3 from typing import Any, List, Optional, Sequence, Union                                     \u2502\n\u2502    4                                                                                             \u2502\n\u2502 \u2771  5 import onnxruntime as rt  # pyright: ignore[reportMissingTypeStubs]                         \u2502\n\u2502    6 from numpy.typing import NDArray                                                            \u2502\n\u2502    7                                                                                             \u2502\n\u2502    8 from bioimageio.spec.model import v0_4, v0_5                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nModuleNotFoundError: No module named 'onnxruntime'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #808000; text-decoration-color: #808000}\n.r7 {color: #00ffff; text-decoration-color: #00ffff}\n.r8 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r9 {color: #808080; text-decoration-color: #808080}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r11 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r12 {color: #008000; text-decoration-color: #008000}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">642 </span><span class=\"r4\">\u2502   \u2502   </span>inputs = get_test_inputs(model)                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">643 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_outputs(model)                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">644 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>645 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">646 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">647 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">648 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(inputs)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r6\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r7\">set</span>(deprecated_kwargs)<span class=\"r6\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r8\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r8\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r7\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r7\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">127 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">elif</span> wf == <span class=\"r6\">&quot;onnx&quot;</span>:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">128 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> weights.onnx <span class=\"r8\">is</span> <span class=\"r8\">not</span> <span class=\"r5\">None</span>                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">129 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>130 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">.onnx_backend</span><span class=\"r9\"> </span><span class=\"r5\">import</span> ONNXModelAdapter                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">131 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> ONNXModelAdapter(                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 2 </span><span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">warnings</span>                                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 3 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> Any, List, Optional, Sequence, Union                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 4 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 5 <span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">onnxruntime</span><span class=\"r9\"> </span><span class=\"r5\">as</span><span class=\"r9\"> </span><span class=\"r10\">rt</span>  <span class=\"r4\"># pyright: ignore[reportMissingTypeStubs]</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 6 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">numpy.typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> NDArray                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 7 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 8 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">bioimageio.spec.model</span><span class=\"r9\"> </span><span class=\"r5\">import</span> v0_4, v0_5                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r11\">ModuleNotFoundError: </span>No module named <span class=\"r12\">&#x27;onnxruntime&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "onnxruntime", "pip"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Run onnx inference for parametrized inputs", "status": "failed", "loc": ["weights", "onnx"], "errors": [{"loc": ["weights", "onnx"], "msg": "No module named 'onnxruntime'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   820 \u2502   try:                                                                                   \u2502\n\u2502   821 \u2502   \u2502   test_inputs = get_test_inputs(model)                                               \u2502\n\u2502   822 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 823 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   824 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   825 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   826 \u2502   \u2502   \u2502   for n, batch_size, inputs, exptected_output_shape in generate_test_cases():    \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   127 \u2502   \u2502   \u2502   elif wf == \"onnx\":                                                             \u2502\n\u2502   128 \u2502   \u2502   \u2502   \u2502   assert weights.onnx is not None                                            \u2502\n\u2502   129 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502 \u2771 130 \u2502   \u2502   \u2502   \u2502   \u2502   from .onnx_backend import ONNXModelAdapter                             \u2502\n\u2502   131 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502   132 \u2502   \u2502   \u2502   \u2502   \u2502   return ONNXModelAdapter(                                               \u2502\n\u2502   133 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    2 import warnings                                                                             \u2502\n\u2502    3 from typing import Any, List, Optional, Sequence, Union                                     \u2502\n\u2502    4                                                                                             \u2502\n\u2502 \u2771  5 import onnxruntime as rt  # pyright: ignore[reportMissingTypeStubs]                         \u2502\n\u2502    6 from numpy.typing import NDArray                                                            \u2502\n\u2502    7                                                                                             \u2502\n\u2502    8 from bioimageio.spec.model import v0_4, v0_5                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nModuleNotFoundError: No module named 'onnxruntime'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #00ffff; text-decoration-color: #00ffff}\n.r9 {color: #808080; text-decoration-color: #808080}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r11 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r12 {color: #008000; text-decoration-color: #008000}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">820 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">821 </span><span class=\"r4\">\u2502   \u2502   </span>test_inputs = get_test_inputs(model)                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">822 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>823 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">824 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">825 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">826 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">for</span> n, batch_size, inputs, exptected_output_shape <span class=\"r6\">in</span> generate_test_cases():    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r8\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r6\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r6\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r8\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r8\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">127 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">elif</span> wf == <span class=\"r7\">&quot;onnx&quot;</span>:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">128 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> weights.onnx <span class=\"r6\">is</span> <span class=\"r6\">not</span> <span class=\"r5\">None</span>                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">129 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>130 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">.onnx_backend</span><span class=\"r9\"> </span><span class=\"r5\">import</span> ONNXModelAdapter                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">131 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> ONNXModelAdapter(                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 2 </span><span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">warnings</span>                                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 3 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> Any, List, Optional, Sequence, Union                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 4 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 5 <span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">onnxruntime</span><span class=\"r9\"> </span><span class=\"r5\">as</span><span class=\"r9\"> </span><span class=\"r10\">rt</span>  <span class=\"r4\"># pyright: ignore[reportMissingTypeStubs]</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 6 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">numpy.typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> NDArray                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 7 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 8 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">bioimageio.spec.model</span><span class=\"r9\"> </span><span class=\"r5\">import</span> v0_4, v0_5                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r11\">ModuleNotFoundError: </span>No module named <span class=\"r12\">&#x27;onnxruntime&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (pytorch_state_dict)", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "'unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   108 \u2502   module = sys.modules.get(module_name)                                                  \u2502\n\u2502   109 \u2502   if module is None:                                                                     \u2502\n\u2502   110 \u2502   \u2502   try:                                                                               \u2502\n\u2502 \u2771 111 \u2502   \u2502   \u2502   tmp_dir = TemporaryDirectory(ignore_cleanup_errors=True)                       \u2502\n\u2502   112 \u2502   \u2502   \u2502   module_path = Path(tmp_dir.name) / module_name                                 \u2502\n\u2502   113 \u2502   \u2502   \u2502   if reader.original_file_name.endswith(\".zip\") or is_zipfile(reader):           \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   module_path.mkdir()                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nTypeError: __init__() got an unexpected keyword argument 'ignore_cleanup_errors'\n\nDuring handling of the above exception, another exception occurred:\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   642 \u2502   \u2502   inputs = get_test_inputs(model)                                                    \u2502\n\u2502   643 \u2502   \u2502   expected = get_test_outputs(model)                                                 \u2502\n\u2502   644 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 645 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   646 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   647 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   648 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(inputs)          \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502   110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502 \u2771 112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   \u2502   )                                                                      \u2502\n\u2502   115 \u2502   \u2502   \u2502   \u2502   except Exception as e:                                                     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    35 \u2502   \u2502   \u2502   raise ValueError(\"No `pytorch_state_dict` weights found\")                      \u2502\n\u2502    36 \u2502   \u2502                                                                                      \u2502\n\u2502    37 \u2502   \u2502   devices = get_devices(devices)                                                     \u2502\n\u2502 \u2771  38 \u2502   \u2502   self._model = load_torch_model(weights, load_state=True, devices=devices)          \u2502\n\u2502    39 \u2502   \u2502   if mode == \"eval\":                                                                 \u2502\n\u2502    40 \u2502   \u2502   \u2502   self._model = self._model.eval()                                               \u2502\n\u2502    41 \u2502   \u2502   elif mode == \"train\":                                                              \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   100 \u2502   load_state: bool = True,                                                               \u2502\n\u2502   101 \u2502   devices: Optional[Sequence[Union[str, torch.device]]] = None,                          \u2502\n\u2502   102 ) -> nn.Module:                                                                            \u2502\n\u2502 \u2771 103 \u2502   custom_callable = import_callable(                                                     \u2502\n\u2502   104 \u2502   \u2502   weight_spec.architecture,                                                          \u2502\n\u2502   105 \u2502   \u2502   sha256=(                                                                           \u2502\n\u2502   106 \u2502   \u2502   \u2502   weight_spec.architecture_sha256                                                \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    74 \u2502   elif isinstance(node, CallableFromFile):                                               \u2502\n\u2502    75 \u2502   \u2502   c = _import_from_file_impl(node.source_file, str(node.callable_name), **kwargs)    \u2502\n\u2502    76 \u2502   elif isinstance(node, ArchitectureFromFileDescr):                                      \u2502\n\u2502 \u2771  77 \u2502   \u2502   c = _import_from_file_impl(node.source, str(node.callable), sha256=node.sha256)    \u2502\n\u2502    78 \u2502   else:                                                                                  \u2502\n\u2502    79 \u2502   \u2502   assert_never(node)                                                                 \u2502\n\u2502    80                                                                                            \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   132 \u2502   \u2502   \u2502   importlib_spec.loader.exec_module(module)                                      \u2502\n\u2502   133 \u2502   \u2502                                                                                      \u2502\n\u2502   134 \u2502   \u2502   except Exception as e:                                                             \u2502\n\u2502 \u2771 135 \u2502   \u2502   \u2502   del sys.modules[module_name]                                                   \u2502\n\u2502   136 \u2502   \u2502   \u2502   raise ImportError(f\"Failed to import {source}\") from e                         \u2502\n\u2502   137 \u2502                                                                                          \u2502\n\u2502   138 \u2502   try:                                                                                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nKeyError: 'unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r9 {color: #800080; text-decoration-color: #800080; font-weight: bold}\n.r10 {font-weight: bold}\n.r11 {color: #008000; text-decoration-color: #008000}\n.r12 {font-style: italic}\n.r13 {color: #00ffff; text-decoration-color: #00ffff}\n.r14 {color: #808080; text-decoration-color: #808080}\n.r15 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">108 </span><span class=\"r4\">\u2502   </span>module = sys.modules.get(module_name)                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">if</span> module <span class=\"r6\">is</span> <span class=\"r5\">None</span>:                                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>111 <span class=\"r4\">\u2502   \u2502   \u2502   </span>tmp_dir = TemporaryDirectory(ignore_cleanup_errors=<span class=\"r5\">True</span>)                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">112 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>module_path = Path(tmp_dir.name) / module_name                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> reader.original_file_name.endswith(<span class=\"r7\">&quot;.zip&quot;</span>) <span class=\"r6\">or</span> is_zipfile(reader):           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span>module_path.mkdir()                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">TypeError: </span><span class=\"r9\">__init__</span><span class=\"r10\">()</span> got an unexpected keyword argument <span class=\"r11\">&#x27;ignore_cleanup_errors&#x27;</span>\n\n<span class=\"r12\">During handling of the above exception, another exception occurred:</span>\n\n<span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">642 </span><span class=\"r4\">\u2502   \u2502   </span>inputs = get_test_inputs(model)                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">643 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_outputs(model)                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">644 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>645 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">646 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">647 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">648 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(inputs)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r13\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r6\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r6\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r13\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r13\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">.pytorch_backend</span><span class=\"r14\"> </span><span class=\"r5\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">111 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>112 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>)                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">115 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 35 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ValueError</span>(<span class=\"r7\">&quot;No `pytorch_state_dict` weights found&quot;</span>)                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 36 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 37 </span><span class=\"r4\">\u2502   \u2502   </span>devices = get_devices(devices)                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 38 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r13\">self</span>._model = load_torch_model(weights, load_state=<span class=\"r5\">True</span>, devices=devices)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 39 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> mode == <span class=\"r7\">&quot;eval&quot;</span>:                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 40 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r13\">self</span>._model = <span class=\"r13\">self</span>._model.eval()                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 41 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">elif</span> mode == <span class=\"r7\">&quot;train&quot;</span>:                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">100 </span><span class=\"r4\">\u2502   </span>load_state: <span class=\"r13\">bool</span> = <span class=\"r5\">True</span>,                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">101 </span><span class=\"r4\">\u2502   </span>devices: Optional[Sequence[Union[<span class=\"r13\">str</span>, torch.device]]] = <span class=\"r5\">None</span>,                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">102 </span>) -&gt; nn.Module:                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>103 <span class=\"r4\">\u2502   </span>custom_callable = import_callable(                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">104 </span><span class=\"r4\">\u2502   \u2502   </span>weight_spec.architecture,                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">105 </span><span class=\"r4\">\u2502   \u2502   </span>sha256=(                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">106 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>weight_spec.architecture_sha256                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 74 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, CallableFromFile):                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 75 </span><span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source_file, <span class=\"r13\">str</span>(node.callable_name), **kwargs)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 76 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, ArchitectureFromFileDescr):                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 77 <span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source, <span class=\"r13\">str</span>(node.callable), sha256=node.sha256)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 78 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">else</span>:                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 79 </span><span class=\"r4\">\u2502   \u2502   </span>assert_never(node)                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 80 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>importlib_spec.loader.exec_module(module)                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">134 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>135 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">del</span> sys.modules[module_name]                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">136 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ImportError</span>(<span class=\"r7\">f&quot;Failed to import {</span>source<span class=\"r7\">}&quot;</span>) <span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">e</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">137 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">138 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">KeyError: </span><span class=\"r11\">&#x27;unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==1.10.0", "setuptools <70.0.0", "torchaudio==0.10.0", "torchvision==0.11.0"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Run pytorch_state_dict inference for parametrized inputs", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "'unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   108 \u2502   module = sys.modules.get(module_name)                                                  \u2502\n\u2502   109 \u2502   if module is None:                                                                     \u2502\n\u2502   110 \u2502   \u2502   try:                                                                               \u2502\n\u2502 \u2771 111 \u2502   \u2502   \u2502   tmp_dir = TemporaryDirectory(ignore_cleanup_errors=True)                       \u2502\n\u2502   112 \u2502   \u2502   \u2502   module_path = Path(tmp_dir.name) / module_name                                 \u2502\n\u2502   113 \u2502   \u2502   \u2502   if reader.original_file_name.endswith(\".zip\") or is_zipfile(reader):           \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   module_path.mkdir()                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nTypeError: __init__() got an unexpected keyword argument 'ignore_cleanup_errors'\n\nDuring handling of the above exception, another exception occurred:\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   820 \u2502   try:                                                                                   \u2502\n\u2502   821 \u2502   \u2502   test_inputs = get_test_inputs(model)                                               \u2502\n\u2502   822 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 823 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   824 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   825 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   826 \u2502   \u2502   \u2502   for n, batch_size, inputs, exptected_output_shape in generate_test_cases():    \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502   110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502 \u2771 112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   \u2502   )                                                                      \u2502\n\u2502   115 \u2502   \u2502   \u2502   \u2502   except Exception as e:                                                     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    35 \u2502   \u2502   \u2502   raise ValueError(\"No `pytorch_state_dict` weights found\")                      \u2502\n\u2502    36 \u2502   \u2502                                                                                      \u2502\n\u2502    37 \u2502   \u2502   devices = get_devices(devices)                                                     \u2502\n\u2502 \u2771  38 \u2502   \u2502   self._model = load_torch_model(weights, load_state=True, devices=devices)          \u2502\n\u2502    39 \u2502   \u2502   if mode == \"eval\":                                                                 \u2502\n\u2502    40 \u2502   \u2502   \u2502   self._model = self._model.eval()                                               \u2502\n\u2502    41 \u2502   \u2502   elif mode == \"train\":                                                              \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   100 \u2502   load_state: bool = True,                                                               \u2502\n\u2502   101 \u2502   devices: Optional[Sequence[Union[str, torch.device]]] = None,                          \u2502\n\u2502   102 ) -> nn.Module:                                                                            \u2502\n\u2502 \u2771 103 \u2502   custom_callable = import_callable(                                                     \u2502\n\u2502   104 \u2502   \u2502   weight_spec.architecture,                                                          \u2502\n\u2502   105 \u2502   \u2502   sha256=(                                                                           \u2502\n\u2502   106 \u2502   \u2502   \u2502   weight_spec.architecture_sha256                                                \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    74 \u2502   elif isinstance(node, CallableFromFile):                                               \u2502\n\u2502    75 \u2502   \u2502   c = _import_from_file_impl(node.source_file, str(node.callable_name), **kwargs)    \u2502\n\u2502    76 \u2502   elif isinstance(node, ArchitectureFromFileDescr):                                      \u2502\n\u2502 \u2771  77 \u2502   \u2502   c = _import_from_file_impl(node.source, str(node.callable), sha256=node.sha256)    \u2502\n\u2502    78 \u2502   else:                                                                                  \u2502\n\u2502    79 \u2502   \u2502   assert_never(node)                                                                 \u2502\n\u2502    80                                                                                            \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   132 \u2502   \u2502   \u2502   importlib_spec.loader.exec_module(module)                                      \u2502\n\u2502   133 \u2502   \u2502                                                                                      \u2502\n\u2502   134 \u2502   \u2502   except Exception as e:                                                             \u2502\n\u2502 \u2771 135 \u2502   \u2502   \u2502   del sys.modules[module_name]                                                   \u2502\n\u2502   136 \u2502   \u2502   \u2502   raise ImportError(f\"Failed to import {source}\") from e                         \u2502\n\u2502   137 \u2502                                                                                          \u2502\n\u2502   138 \u2502   try:                                                                                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nKeyError: 'unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r9 {color: #800080; text-decoration-color: #800080; font-weight: bold}\n.r10 {font-weight: bold}\n.r11 {color: #008000; text-decoration-color: #008000}\n.r12 {font-style: italic}\n.r13 {color: #00ffff; text-decoration-color: #00ffff}\n.r14 {color: #808080; text-decoration-color: #808080}\n.r15 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">108 </span><span class=\"r4\">\u2502   </span>module = sys.modules.get(module_name)                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">if</span> module <span class=\"r6\">is</span> <span class=\"r5\">None</span>:                                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>111 <span class=\"r4\">\u2502   \u2502   \u2502   </span>tmp_dir = TemporaryDirectory(ignore_cleanup_errors=<span class=\"r5\">True</span>)                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">112 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>module_path = Path(tmp_dir.name) / module_name                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> reader.original_file_name.endswith(<span class=\"r7\">&quot;.zip&quot;</span>) <span class=\"r6\">or</span> is_zipfile(reader):           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span>module_path.mkdir()                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">TypeError: </span><span class=\"r9\">__init__</span><span class=\"r10\">()</span> got an unexpected keyword argument <span class=\"r11\">&#x27;ignore_cleanup_errors&#x27;</span>\n\n<span class=\"r12\">During handling of the above exception, another exception occurred:</span>\n\n<span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">820 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">821 </span><span class=\"r4\">\u2502   \u2502   </span>test_inputs = get_test_inputs(model)                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">822 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>823 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">824 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">825 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">826 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">for</span> n, batch_size, inputs, exptected_output_shape <span class=\"r6\">in</span> generate_test_cases():    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r13\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r6\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r6\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r13\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r13\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">.pytorch_backend</span><span class=\"r14\"> </span><span class=\"r5\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">111 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>112 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>)                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">115 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 35 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ValueError</span>(<span class=\"r7\">&quot;No `pytorch_state_dict` weights found&quot;</span>)                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 36 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 37 </span><span class=\"r4\">\u2502   \u2502   </span>devices = get_devices(devices)                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 38 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r13\">self</span>._model = load_torch_model(weights, load_state=<span class=\"r5\">True</span>, devices=devices)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 39 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> mode == <span class=\"r7\">&quot;eval&quot;</span>:                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 40 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r13\">self</span>._model = <span class=\"r13\">self</span>._model.eval()                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 41 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">elif</span> mode == <span class=\"r7\">&quot;train&quot;</span>:                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">100 </span><span class=\"r4\">\u2502   </span>load_state: <span class=\"r13\">bool</span> = <span class=\"r5\">True</span>,                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">101 </span><span class=\"r4\">\u2502   </span>devices: Optional[Sequence[Union[<span class=\"r13\">str</span>, torch.device]]] = <span class=\"r5\">None</span>,                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">102 </span>) -&gt; nn.Module:                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>103 <span class=\"r4\">\u2502   </span>custom_callable = import_callable(                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">104 </span><span class=\"r4\">\u2502   \u2502   </span>weight_spec.architecture,                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">105 </span><span class=\"r4\">\u2502   \u2502   </span>sha256=(                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">106 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>weight_spec.architecture_sha256                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 74 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, CallableFromFile):                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 75 </span><span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source_file, <span class=\"r13\">str</span>(node.callable_name), **kwargs)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 76 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, ArchitectureFromFileDescr):                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 77 <span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source, <span class=\"r13\">str</span>(node.callable), sha256=node.sha256)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 78 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">else</span>:                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 79 </span><span class=\"r4\">\u2502   \u2502   </span>assert_never(node)                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 80 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>importlib_spec.loader.exec_module(module)                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">134 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>135 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">del</span> sys.modules[module_name]                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">136 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ImportError</span>(<span class=\"r7\">f&quot;Failed to import {</span>source<span class=\"r7\">}&quot;</span>) <span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">e</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">137 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">138 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">KeyError: </span><span class=\"r11\">&#x27;unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (torchscript)", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==1.10.0", "setuptools <70.0.0", "torchaudio==0.10.0", "torchvision==0.11.0"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Run torchscript inference for inputs with batch_size: 1 and size parameter n: 0", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 1 and size parameter n: 1", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 1 and size parameter n: 2", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 2 and size parameter n: 0", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 2 and size parameter n: 1", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 2 and size parameter n: 2", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/zero_mean_unit_variance.ijm?version=v0": null, "zero_mean_unit_variance.ijm": "767f2c3a50e36365c30b9e46e57fcf82e606d337e8a48d4a2440dc512813d186", "https://www.nature.com/articles/s41592-019-0612-7": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_input_0.npy?version=v0": null, "test_input_0.npy": "c29bd6e16e3f7856217b407ba948222b1c2a0da41922a0f79297e25588614fe2", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_input_0.tif?version=v0": null, "sample_input_0.tif": "a24b3c708b6ca6825494eb7c5a4d221335fb3eef5eb9d03f4108907cdaad2bf9", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_output_0.npy?version=v0": null, "test_output_0.npy": "510181f38930e59e4fd8ecc03d6ea7c980eb6609759655f2d4a41fe36108d5f5", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_output_0.tif?version=v0": null, "sample_output_0.tif": "e8f99aabe8405427f515eba23a49f58ba50302f57d1fdfd07026e1984f836c5e", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.onnx?version=v0": null, "weights.onnx": "df913b85947f5132bcdaf81d91af0963f60d44f4caf8a4fec672d96a2f327b44", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/unet.py?version=v0": null, "unet.py": "7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3", "weights.pt": "608f52cd7f5119f7a7b8272395b0c169714e8be34536eaf159820f72a1d6a5b7", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "8410950508655a300793b389c815dc30b1334062fc1dadb1e15e55a93cbb99a0"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.5.4", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/zero_mean_unit_variance.ijm?version=v0": null, "zero_mean_unit_variance.ijm": "767f2c3a50e36365c30b9e46e57fcf82e606d337e8a48d4a2440dc512813d186", "https://www.nature.com/articles/s41592-019-0612-7": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_input_0.npy?version=v0": null, "test_input_0.npy": "c29bd6e16e3f7856217b407ba948222b1c2a0da41922a0f79297e25588614fe2", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_input_0.tif?version=v0": null, "sample_input_0.tif": "a24b3c708b6ca6825494eb7c5a4d221335fb3eef5eb9d03f4108907cdaad2bf9", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/test_output_0.npy?version=v0": null, "test_output_0.npy": "510181f38930e59e4fd8ecc03d6ea7c980eb6609759655f2d4a41fe36108d5f5", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/sample_output_0.tif?version=v0": null, "sample_output_0.tif": "e8f99aabe8405427f515eba23a49f58ba50302f57d1fdfd07026e1984f836c5e", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.onnx?version=v0": null, "weights.onnx": "df913b85947f5132bcdaf81d91af0963f60d44f4caf8a4fec672d96a2f327b44", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/unet.py?version=v0": null, "unet.py": "7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3", "weights.pt": "608f52cd7f5119f7a7b8272395b0c169714e8be34536eaf159820f72a1d6a5b7", "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "8410950508655a300793b389c815dc30b1334062fc1dadb1e15e55a93cbb99a0"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/affable-shark/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (onnx)", "status": "failed", "loc": ["weights", "onnx"], "errors": [{"loc": ["weights", "onnx"], "msg": "No module named 'onnxruntime'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   642 \u2502   \u2502   inputs = get_test_inputs(model)                                                    \u2502\n\u2502   643 \u2502   \u2502   expected = get_test_outputs(model)                                                 \u2502\n\u2502   644 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 645 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   646 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   647 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   648 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(inputs)          \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   127 \u2502   \u2502   \u2502   elif wf == \"onnx\":                                                             \u2502\n\u2502   128 \u2502   \u2502   \u2502   \u2502   assert weights.onnx is not None                                            \u2502\n\u2502   129 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502 \u2771 130 \u2502   \u2502   \u2502   \u2502   \u2502   from .onnx_backend import ONNXModelAdapter                             \u2502\n\u2502   131 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502   132 \u2502   \u2502   \u2502   \u2502   \u2502   return ONNXModelAdapter(                                               \u2502\n\u2502   133 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    2 import warnings                                                                             \u2502\n\u2502    3 from typing import Any, List, Optional, Sequence, Union                                     \u2502\n\u2502    4                                                                                             \u2502\n\u2502 \u2771  5 import onnxruntime as rt  # pyright: ignore[reportMissingTypeStubs]                         \u2502\n\u2502    6 from numpy.typing import NDArray                                                            \u2502\n\u2502    7                                                                                             \u2502\n\u2502    8 from bioimageio.spec.model import v0_4, v0_5                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nModuleNotFoundError: No module named 'onnxruntime'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #808000; text-decoration-color: #808000}\n.r7 {color: #00ffff; text-decoration-color: #00ffff}\n.r8 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r9 {color: #808080; text-decoration-color: #808080}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r11 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r12 {color: #008000; text-decoration-color: #008000}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">642 </span><span class=\"r4\">\u2502   \u2502   </span>inputs = get_test_inputs(model)                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">643 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_outputs(model)                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">644 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>645 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">646 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">647 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">648 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(inputs)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r6\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r7\">set</span>(deprecated_kwargs)<span class=\"r6\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r8\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r8\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r7\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r7\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">127 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">elif</span> wf == <span class=\"r6\">&quot;onnx&quot;</span>:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">128 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> weights.onnx <span class=\"r8\">is</span> <span class=\"r8\">not</span> <span class=\"r5\">None</span>                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">129 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>130 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">.onnx_backend</span><span class=\"r9\"> </span><span class=\"r5\">import</span> ONNXModelAdapter                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">131 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> ONNXModelAdapter(                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 2 </span><span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">warnings</span>                                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 3 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> Any, List, Optional, Sequence, Union                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 4 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 5 <span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">onnxruntime</span><span class=\"r9\"> </span><span class=\"r5\">as</span><span class=\"r9\"> </span><span class=\"r10\">rt</span>  <span class=\"r4\"># pyright: ignore[reportMissingTypeStubs]</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 6 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">numpy.typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> NDArray                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 7 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 8 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">bioimageio.spec.model</span><span class=\"r9\"> </span><span class=\"r5\">import</span> v0_4, v0_5                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r11\">ModuleNotFoundError: </span>No module named <span class=\"r12\">&#x27;onnxruntime&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "onnxruntime", "pip"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Run onnx inference for parametrized inputs", "status": "failed", "loc": ["weights", "onnx"], "errors": [{"loc": ["weights", "onnx"], "msg": "No module named 'onnxruntime'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   820 \u2502   try:                                                                                   \u2502\n\u2502   821 \u2502   \u2502   test_inputs = get_test_inputs(model)                                               \u2502\n\u2502   822 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 823 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   824 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   825 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   826 \u2502   \u2502   \u2502   for n, batch_size, inputs, exptected_output_shape in generate_test_cases():    \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   127 \u2502   \u2502   \u2502   elif wf == \"onnx\":                                                             \u2502\n\u2502   128 \u2502   \u2502   \u2502   \u2502   assert weights.onnx is not None                                            \u2502\n\u2502   129 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502 \u2771 130 \u2502   \u2502   \u2502   \u2502   \u2502   from .onnx_backend import ONNXModelAdapter                             \u2502\n\u2502   131 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502   132 \u2502   \u2502   \u2502   \u2502   \u2502   return ONNXModelAdapter(                                               \u2502\n\u2502   133 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    2 import warnings                                                                             \u2502\n\u2502    3 from typing import Any, List, Optional, Sequence, Union                                     \u2502\n\u2502    4                                                                                             \u2502\n\u2502 \u2771  5 import onnxruntime as rt  # pyright: ignore[reportMissingTypeStubs]                         \u2502\n\u2502    6 from numpy.typing import NDArray                                                            \u2502\n\u2502    7                                                                                             \u2502\n\u2502    8 from bioimageio.spec.model import v0_4, v0_5                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nModuleNotFoundError: No module named 'onnxruntime'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #00ffff; text-decoration-color: #00ffff}\n.r9 {color: #808080; text-decoration-color: #808080}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r11 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r12 {color: #008000; text-decoration-color: #008000}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">820 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">821 </span><span class=\"r4\">\u2502   \u2502   </span>test_inputs = get_test_inputs(model)                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">822 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>823 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">824 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">825 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">826 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">for</span> n, batch_size, inputs, exptected_output_shape <span class=\"r6\">in</span> generate_test_cases():    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r8\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r6\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r6\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r8\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r8\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">127 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">elif</span> wf == <span class=\"r7\">&quot;onnx&quot;</span>:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">128 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> weights.onnx <span class=\"r6\">is</span> <span class=\"r6\">not</span> <span class=\"r5\">None</span>                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">129 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>130 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">.onnx_backend</span><span class=\"r9\"> </span><span class=\"r5\">import</span> ONNXModelAdapter                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">131 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> ONNXModelAdapter(                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 2 </span><span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">warnings</span>                                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 3 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> Any, List, Optional, Sequence, Union                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 4 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 5 <span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">onnxruntime</span><span class=\"r9\"> </span><span class=\"r5\">as</span><span class=\"r9\"> </span><span class=\"r10\">rt</span>  <span class=\"r4\"># pyright: ignore[reportMissingTypeStubs]</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 6 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">numpy.typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> NDArray                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 7 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 8 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">bioimageio.spec.model</span><span class=\"r9\"> </span><span class=\"r5\">import</span> v0_4, v0_5                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r11\">ModuleNotFoundError: </span>No module named <span class=\"r12\">&#x27;onnxruntime&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (pytorch_state_dict)", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "'unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   108 \u2502   module = sys.modules.get(module_name)                                                  \u2502\n\u2502   109 \u2502   if module is None:                                                                     \u2502\n\u2502   110 \u2502   \u2502   try:                                                                               \u2502\n\u2502 \u2771 111 \u2502   \u2502   \u2502   tmp_dir = TemporaryDirectory(ignore_cleanup_errors=True)                       \u2502\n\u2502   112 \u2502   \u2502   \u2502   module_path = Path(tmp_dir.name) / module_name                                 \u2502\n\u2502   113 \u2502   \u2502   \u2502   if reader.original_file_name.endswith(\".zip\") or is_zipfile(reader):           \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   module_path.mkdir()                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nTypeError: __init__() got an unexpected keyword argument 'ignore_cleanup_errors'\n\nDuring handling of the above exception, another exception occurred:\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   642 \u2502   \u2502   inputs = get_test_inputs(model)                                                    \u2502\n\u2502   643 \u2502   \u2502   expected = get_test_outputs(model)                                                 \u2502\n\u2502   644 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 645 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   646 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   647 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   648 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(inputs)          \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502   110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502 \u2771 112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   \u2502   )                                                                      \u2502\n\u2502   115 \u2502   \u2502   \u2502   \u2502   except Exception as e:                                                     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    35 \u2502   \u2502   \u2502   raise ValueError(\"No `pytorch_state_dict` weights found\")                      \u2502\n\u2502    36 \u2502   \u2502                                                                                      \u2502\n\u2502    37 \u2502   \u2502   devices = get_devices(devices)                                                     \u2502\n\u2502 \u2771  38 \u2502   \u2502   self._model = load_torch_model(weights, load_state=True, devices=devices)          \u2502\n\u2502    39 \u2502   \u2502   if mode == \"eval\":                                                                 \u2502\n\u2502    40 \u2502   \u2502   \u2502   self._model = self._model.eval()                                               \u2502\n\u2502    41 \u2502   \u2502   elif mode == \"train\":                                                              \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   100 \u2502   load_state: bool = True,                                                               \u2502\n\u2502   101 \u2502   devices: Optional[Sequence[Union[str, torch.device]]] = None,                          \u2502\n\u2502   102 ) -> nn.Module:                                                                            \u2502\n\u2502 \u2771 103 \u2502   custom_callable = import_callable(                                                     \u2502\n\u2502   104 \u2502   \u2502   weight_spec.architecture,                                                          \u2502\n\u2502   105 \u2502   \u2502   sha256=(                                                                           \u2502\n\u2502   106 \u2502   \u2502   \u2502   weight_spec.architecture_sha256                                                \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    74 \u2502   elif isinstance(node, CallableFromFile):                                               \u2502\n\u2502    75 \u2502   \u2502   c = _import_from_file_impl(node.source_file, str(node.callable_name), **kwargs)    \u2502\n\u2502    76 \u2502   elif isinstance(node, ArchitectureFromFileDescr):                                      \u2502\n\u2502 \u2771  77 \u2502   \u2502   c = _import_from_file_impl(node.source, str(node.callable), sha256=node.sha256)    \u2502\n\u2502    78 \u2502   else:                                                                                  \u2502\n\u2502    79 \u2502   \u2502   assert_never(node)                                                                 \u2502\n\u2502    80                                                                                            \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   132 \u2502   \u2502   \u2502   importlib_spec.loader.exec_module(module)                                      \u2502\n\u2502   133 \u2502   \u2502                                                                                      \u2502\n\u2502   134 \u2502   \u2502   except Exception as e:                                                             \u2502\n\u2502 \u2771 135 \u2502   \u2502   \u2502   del sys.modules[module_name]                                                   \u2502\n\u2502   136 \u2502   \u2502   \u2502   raise ImportError(f\"Failed to import {source}\") from e                         \u2502\n\u2502   137 \u2502                                                                                          \u2502\n\u2502   138 \u2502   try:                                                                                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nKeyError: 'unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r9 {color: #800080; text-decoration-color: #800080; font-weight: bold}\n.r10 {font-weight: bold}\n.r11 {color: #008000; text-decoration-color: #008000}\n.r12 {font-style: italic}\n.r13 {color: #00ffff; text-decoration-color: #00ffff}\n.r14 {color: #808080; text-decoration-color: #808080}\n.r15 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">108 </span><span class=\"r4\">\u2502   </span>module = sys.modules.get(module_name)                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">if</span> module <span class=\"r6\">is</span> <span class=\"r5\">None</span>:                                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>111 <span class=\"r4\">\u2502   \u2502   \u2502   </span>tmp_dir = TemporaryDirectory(ignore_cleanup_errors=<span class=\"r5\">True</span>)                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">112 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>module_path = Path(tmp_dir.name) / module_name                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> reader.original_file_name.endswith(<span class=\"r7\">&quot;.zip&quot;</span>) <span class=\"r6\">or</span> is_zipfile(reader):           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span>module_path.mkdir()                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">TypeError: </span><span class=\"r9\">__init__</span><span class=\"r10\">()</span> got an unexpected keyword argument <span class=\"r11\">&#x27;ignore_cleanup_errors&#x27;</span>\n\n<span class=\"r12\">During handling of the above exception, another exception occurred:</span>\n\n<span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">642 </span><span class=\"r4\">\u2502   \u2502   </span>inputs = get_test_inputs(model)                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">643 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_outputs(model)                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">644 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>645 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">646 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">647 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">648 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(inputs)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r13\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r6\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r6\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r13\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r13\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">.pytorch_backend</span><span class=\"r14\"> </span><span class=\"r5\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">111 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>112 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>)                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">115 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 35 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ValueError</span>(<span class=\"r7\">&quot;No `pytorch_state_dict` weights found&quot;</span>)                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 36 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 37 </span><span class=\"r4\">\u2502   \u2502   </span>devices = get_devices(devices)                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 38 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r13\">self</span>._model = load_torch_model(weights, load_state=<span class=\"r5\">True</span>, devices=devices)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 39 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> mode == <span class=\"r7\">&quot;eval&quot;</span>:                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 40 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r13\">self</span>._model = <span class=\"r13\">self</span>._model.eval()                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 41 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">elif</span> mode == <span class=\"r7\">&quot;train&quot;</span>:                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">100 </span><span class=\"r4\">\u2502   </span>load_state: <span class=\"r13\">bool</span> = <span class=\"r5\">True</span>,                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">101 </span><span class=\"r4\">\u2502   </span>devices: Optional[Sequence[Union[<span class=\"r13\">str</span>, torch.device]]] = <span class=\"r5\">None</span>,                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">102 </span>) -&gt; nn.Module:                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>103 <span class=\"r4\">\u2502   </span>custom_callable = import_callable(                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">104 </span><span class=\"r4\">\u2502   \u2502   </span>weight_spec.architecture,                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">105 </span><span class=\"r4\">\u2502   \u2502   </span>sha256=(                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">106 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>weight_spec.architecture_sha256                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 74 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, CallableFromFile):                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 75 </span><span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source_file, <span class=\"r13\">str</span>(node.callable_name), **kwargs)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 76 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, ArchitectureFromFileDescr):                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 77 <span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source, <span class=\"r13\">str</span>(node.callable), sha256=node.sha256)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 78 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">else</span>:                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 79 </span><span class=\"r4\">\u2502   \u2502   </span>assert_never(node)                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 80 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>importlib_spec.loader.exec_module(module)                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">134 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>135 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">del</span> sys.modules[module_name]                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">136 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ImportError</span>(<span class=\"r7\">f&quot;Failed to import {</span>source<span class=\"r7\">}&quot;</span>) <span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">e</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">137 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">138 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">KeyError: </span><span class=\"r11\">&#x27;unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==1.10.0", "setuptools <70.0.0", "torchaudio==0.10.0", "torchvision==0.11.0"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Run pytorch_state_dict inference for parametrized inputs", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "'unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   108 \u2502   module = sys.modules.get(module_name)                                                  \u2502\n\u2502   109 \u2502   if module is None:                                                                     \u2502\n\u2502   110 \u2502   \u2502   try:                                                                               \u2502\n\u2502 \u2771 111 \u2502   \u2502   \u2502   tmp_dir = TemporaryDirectory(ignore_cleanup_errors=True)                       \u2502\n\u2502   112 \u2502   \u2502   \u2502   module_path = Path(tmp_dir.name) / module_name                                 \u2502\n\u2502   113 \u2502   \u2502   \u2502   if reader.original_file_name.endswith(\".zip\") or is_zipfile(reader):           \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   module_path.mkdir()                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nTypeError: __init__() got an unexpected keyword argument 'ignore_cleanup_errors'\n\nDuring handling of the above exception, another exception occurred:\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   820 \u2502   try:                                                                                   \u2502\n\u2502   821 \u2502   \u2502   test_inputs = get_test_inputs(model)                                               \u2502\n\u2502   822 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 823 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   824 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   825 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   826 \u2502   \u2502   \u2502   for n, batch_size, inputs, exptected_output_shape in generate_test_cases():    \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502   110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502 \u2771 112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   \u2502   )                                                                      \u2502\n\u2502   115 \u2502   \u2502   \u2502   \u2502   except Exception as e:                                                     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    35 \u2502   \u2502   \u2502   raise ValueError(\"No `pytorch_state_dict` weights found\")                      \u2502\n\u2502    36 \u2502   \u2502                                                                                      \u2502\n\u2502    37 \u2502   \u2502   devices = get_devices(devices)                                                     \u2502\n\u2502 \u2771  38 \u2502   \u2502   self._model = load_torch_model(weights, load_state=True, devices=devices)          \u2502\n\u2502    39 \u2502   \u2502   if mode == \"eval\":                                                                 \u2502\n\u2502    40 \u2502   \u2502   \u2502   self._model = self._model.eval()                                               \u2502\n\u2502    41 \u2502   \u2502   elif mode == \"train\":                                                              \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   100 \u2502   load_state: bool = True,                                                               \u2502\n\u2502   101 \u2502   devices: Optional[Sequence[Union[str, torch.device]]] = None,                          \u2502\n\u2502   102 ) -> nn.Module:                                                                            \u2502\n\u2502 \u2771 103 \u2502   custom_callable = import_callable(                                                     \u2502\n\u2502   104 \u2502   \u2502   weight_spec.architecture,                                                          \u2502\n\u2502   105 \u2502   \u2502   sha256=(                                                                           \u2502\n\u2502   106 \u2502   \u2502   \u2502   weight_spec.architecture_sha256                                                \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    74 \u2502   elif isinstance(node, CallableFromFile):                                               \u2502\n\u2502    75 \u2502   \u2502   c = _import_from_file_impl(node.source_file, str(node.callable_name), **kwargs)    \u2502\n\u2502    76 \u2502   elif isinstance(node, ArchitectureFromFileDescr):                                      \u2502\n\u2502 \u2771  77 \u2502   \u2502   c = _import_from_file_impl(node.source, str(node.callable), sha256=node.sha256)    \u2502\n\u2502    78 \u2502   else:                                                                                  \u2502\n\u2502    79 \u2502   \u2502   assert_never(node)                                                                 \u2502\n\u2502    80                                                                                            \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   132 \u2502   \u2502   \u2502   importlib_spec.loader.exec_module(module)                                      \u2502\n\u2502   133 \u2502   \u2502                                                                                      \u2502\n\u2502   134 \u2502   \u2502   except Exception as e:                                                             \u2502\n\u2502 \u2771 135 \u2502   \u2502   \u2502   del sys.modules[module_name]                                                   \u2502\n\u2502   136 \u2502   \u2502   \u2502   raise ImportError(f\"Failed to import {source}\") from e                         \u2502\n\u2502   137 \u2502                                                                                          \u2502\n\u2502   138 \u2502   try:                                                                                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nKeyError: 'unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r9 {color: #800080; text-decoration-color: #800080; font-weight: bold}\n.r10 {font-weight: bold}\n.r11 {color: #008000; text-decoration-color: #008000}\n.r12 {font-style: italic}\n.r13 {color: #00ffff; text-decoration-color: #00ffff}\n.r14 {color: #808080; text-decoration-color: #808080}\n.r15 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">108 </span><span class=\"r4\">\u2502   </span>module = sys.modules.get(module_name)                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">if</span> module <span class=\"r6\">is</span> <span class=\"r5\">None</span>:                                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>111 <span class=\"r4\">\u2502   \u2502   \u2502   </span>tmp_dir = TemporaryDirectory(ignore_cleanup_errors=<span class=\"r5\">True</span>)                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">112 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>module_path = Path(tmp_dir.name) / module_name                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> reader.original_file_name.endswith(<span class=\"r7\">&quot;.zip&quot;</span>) <span class=\"r6\">or</span> is_zipfile(reader):           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span>module_path.mkdir()                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">TypeError: </span><span class=\"r9\">__init__</span><span class=\"r10\">()</span> got an unexpected keyword argument <span class=\"r11\">&#x27;ignore_cleanup_errors&#x27;</span>\n\n<span class=\"r12\">During handling of the above exception, another exception occurred:</span>\n\n<span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">820 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">821 </span><span class=\"r4\">\u2502   \u2502   </span>test_inputs = get_test_inputs(model)                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">822 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>823 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">824 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">825 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">826 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">for</span> n, batch_size, inputs, exptected_output_shape <span class=\"r6\">in</span> generate_test_cases():    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r13\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r6\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r6\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r13\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r13\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">.pytorch_backend</span><span class=\"r14\"> </span><span class=\"r5\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">111 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>112 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>)                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">115 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 35 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ValueError</span>(<span class=\"r7\">&quot;No `pytorch_state_dict` weights found&quot;</span>)                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 36 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 37 </span><span class=\"r4\">\u2502   \u2502   </span>devices = get_devices(devices)                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 38 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r13\">self</span>._model = load_torch_model(weights, load_state=<span class=\"r5\">True</span>, devices=devices)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 39 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> mode == <span class=\"r7\">&quot;eval&quot;</span>:                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 40 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r13\">self</span>._model = <span class=\"r13\">self</span>._model.eval()                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 41 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">elif</span> mode == <span class=\"r7\">&quot;train&quot;</span>:                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">100 </span><span class=\"r4\">\u2502   </span>load_state: <span class=\"r13\">bool</span> = <span class=\"r5\">True</span>,                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">101 </span><span class=\"r4\">\u2502   </span>devices: Optional[Sequence[Union[<span class=\"r13\">str</span>, torch.device]]] = <span class=\"r5\">None</span>,                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">102 </span>) -&gt; nn.Module:                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>103 <span class=\"r4\">\u2502   </span>custom_callable = import_callable(                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">104 </span><span class=\"r4\">\u2502   \u2502   </span>weight_spec.architecture,                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">105 </span><span class=\"r4\">\u2502   \u2502   </span>sha256=(                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">106 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>weight_spec.architecture_sha256                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 74 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, CallableFromFile):                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 75 </span><span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source_file, <span class=\"r13\">str</span>(node.callable_name), **kwargs)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 76 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, ArchitectureFromFileDescr):                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 77 <span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source, <span class=\"r13\">str</span>(node.callable), sha256=node.sha256)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 78 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">else</span>:                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 79 </span><span class=\"r4\">\u2502   \u2502   </span>assert_never(node)                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 80 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/78eb4fa53055abd847a1d3b0d24337a0fd712c902548587c106015eae7288265/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>importlib_spec.loader.exec_module(module)                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">134 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>135 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">del</span> sys.modules[module_name]                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">136 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ImportError</span>(<span class=\"r7\">f&quot;Failed to import {</span>source<span class=\"r7\">}&quot;</span>) <span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">e</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">137 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">138 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">KeyError: </span><span class=\"r11\">&#x27;unet_7f5b15948e8e2c91f78dcff34fbf30af517073e91ba487f3edb982b948d099b3&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (torchscript)", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==1.10.0", "setuptools <70.0.0", "torchaudio==0.10.0", "torchvision==0.11.0"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Run torchscript inference for inputs with batch_size: 1 and size parameter n: 0", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 1 and size parameter n: 1", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 1 and size parameter n: 2", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 2 and size parameter n: 0", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 2 and size parameter n: 1", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Run torchscript inference for inputs with batch_size: 2 and size parameter n: 2", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}], "env": [["bioimageio.spec", "0.5.5.6", "", ""], ["bioimageio.core", "0.9.4", "", ""]], "saved_conda_list": "# packages in environment at /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8:\n#\n# Name                     Version          Build                    Channel\n_libgcc_mutex              0.1              conda_forge              conda-forge\n_openmp_mutex              4.5              2_gnu                    conda-forge\nannotated-types            0.7.0            pyhd8ed1ab_1             conda-forge\nanyio                      4.11.0           pyhcf101f3_0             conda-forge\naom                        3.9.1            hac33072_0               conda-forge\nbioimageio.core            0.9.4            pyhd8ed1ab_0             conda-forge\nbioimageio.spec            0.5.5.6          pyhd8ed1ab_0             conda-forge\nblosc                      1.21.6           he440d0b_1               conda-forge\nbrunsli                    0.1              he3183e4_1               conda-forge\nbzip2                      1.0.8            hda65f42_8               conda-forge\nc-ares                     1.34.5           hb9d3cd8_0               conda-forge\nc-blosc2                   2.21.3           h4cfbee9_0               conda-forge\nca-certificates            2025.10.5        hbd8a1cb_0               conda-forge\ncached-property            1.5.2            hd8ed1ab_1               conda-forge\ncached_property            1.5.2            pyha770c72_1             conda-forge\ncertifi                    2025.10.5        pyhd8ed1ab_0             conda-forge\ncharls                     2.4.2            h59595ed_0               conda-forge\ncolorama                   0.4.6            pyhd8ed1ab_1             conda-forge\ncoloredlogs                15.0.1           pyhd8ed1ab_4             conda-forge\ncpython                    3.13.9           py313hd8ed1ab_100        conda-forge\ndav1d                      1.2.1            hd590300_0               conda-forge\ndistro                     1.9.0            pyhd8ed1ab_1             conda-forge\ndnspython                  2.8.0            pyhcf101f3_0             conda-forge\nemail-validator            2.3.0            pyhd8ed1ab_0             conda-forge\nemail_validator            2.3.0            hd8ed1ab_0               conda-forge\nexceptiongroup             1.3.0            pyhd8ed1ab_0             conda-forge\nfilelock                   3.20.0           pyhd8ed1ab_0             conda-forge\ngenericache                0.5.2            pyhd8ed1ab_0             conda-forge\ngiflib                     5.2.2            hd590300_0               conda-forge\ngmp                        6.3.0            hac33072_2               conda-forge\ngmpy2                      2.2.1            py313h86d8783_1          conda-forge\nh11                        0.16.0           pyhd8ed1ab_0             conda-forge\nh2                         4.3.0            pyhcf101f3_0             conda-forge\nh5py                       3.15.1           nompi_py313h253c126_100  conda-forge\nhdf5                       1.14.6           nompi_h6e4c0c1_103       conda-forge\nhpack                      4.1.0            pyhd8ed1ab_0             conda-forge\nhttpcore                   1.0.9            pyh29332c3_0             conda-forge\nhttpx                      0.28.1           pyhd8ed1ab_0             conda-forge\nhumanfriendly              10.0             pyh707e725_8             conda-forge\nhyperframe                 6.1.0            pyhd8ed1ab_0             conda-forge\nidna                       3.11             pyhd8ed1ab_0             conda-forge\nimagecodecs                2025.8.2         py313h718aa22_4          conda-forge\nimageio                    2.37.0           pyhfb79c49_0             conda-forge\nimportlib-metadata         8.7.0            pyhe01879c_1             conda-forge\njxrlib                     1.1              hd590300_3               conda-forge\nkeyutils                   1.6.3            hb9d3cd8_0               conda-forge\nkrb5                       1.21.3           h659f571_0               conda-forge\nlcms2                      2.17             h717163a_0               conda-forge\nld_impl_linux-64           2.44             ha97dd6f_2               conda-forge\nlerc                       4.0.0            h0aef613_1               conda-forge\nlibabseil                  20250814.1       cxx17_hee66210_0         conda-forge\nlibaec                     1.1.4            h3f801dc_0               conda-forge\nlibavif16                  1.3.0            h6395336_2               conda-forge\nlibblas                    3.9.0            37_h4a7cf45_openblas     conda-forge\nlibbrotlicommon            1.1.0            hb03c661_4               conda-forge\nlibbrotlidec               1.1.0            hb03c661_4               conda-forge\nlibbrotlienc               1.1.0            hb03c661_4               conda-forge\nlibcblas                   3.9.0            37_h0358290_openblas     conda-forge\nlibcurl                    8.16.0           h4e3cde8_0               conda-forge\nlibdeflate                 1.24             h86f0d12_0               conda-forge\nlibedit                    3.1.20250104     pl5321h7949ede_0         conda-forge\nlibev                      4.33             hd590300_2               conda-forge\nlibexpat                   2.7.1            hecca717_0               conda-forge\nlibffi                     3.4.6            h2dba641_1               conda-forge\nlibfreetype                2.14.1           ha770c72_0               conda-forge\nlibfreetype6               2.14.1           h73754d4_0               conda-forge\nlibgcc                     15.2.0           h767d61c_7               conda-forge\nlibgcc-ng                  15.2.0           h69a702a_7               conda-forge\nlibgfortran                15.2.0           h69a702a_7               conda-forge\nlibgfortran5               15.2.0           hcd61629_7               conda-forge\nlibgomp                    15.2.0           h767d61c_7               conda-forge\nlibhwy                     1.3.0            h4c17acf_1               conda-forge\nlibjpeg-turbo              3.1.0            hb9d3cd8_0               conda-forge\nlibjxl                     0.11.1           h6cb5226_4               conda-forge\nliblapack                  3.9.0            37_h47877c9_openblas     conda-forge\nliblzma                    5.8.1            hb9d3cd8_2               conda-forge\nlibmpdec                   4.0.0            hb9d3cd8_0               conda-forge\nlibnghttp2                 1.67.0           had1ee68_0               conda-forge\nlibopenblas                0.3.30           pthreads_h94d23a6_2      conda-forge\nlibpng                     1.6.50           h421ea60_1               conda-forge\nlibsqlite                  3.50.4           h0c1763c_0               conda-forge\nlibssh2                    1.11.1           hcf80075_0               conda-forge\nlibstdcxx                  15.2.0           h8f9b012_7               conda-forge\nlibstdcxx-ng               15.2.0           h4852527_7               conda-forge\nlibtiff                    4.7.1            h8261f1e_0               conda-forge\nlibuuid                    2.41.2           he9a06e4_0               conda-forge\nlibwebp-base               1.6.0            hd42ef1d_0               conda-forge\nlibxcb                     1.17.0           h8a09558_0               conda-forge\nlibzlib                    1.3.1            hb9d3cd8_2               conda-forge\nlibzopfli                  1.0.3            h9c3ff4c_0               conda-forge\nloguru                     0.7.3            pyh707e725_0             conda-forge\nlz4-c                      1.10.0           h5888daf_1               conda-forge\nmarkdown                   3.9              pyhd8ed1ab_0             conda-forge\nmarkdown-it-py             4.0.0            pyhd8ed1ab_0             conda-forge\nmdurl                      0.1.2            pyhd8ed1ab_1             conda-forge\nmpc                        1.3.1            h24ddda3_1               conda-forge\nmpfr                       4.2.1            h90cbb55_3               conda-forge\nmpmath                     1.3.0            pyhd8ed1ab_1             conda-forge\nncurses                    6.5              h2d0b736_3               conda-forge\nnumpy                      2.3.3            py313hf6604e3_0          conda-forge\nonnxruntime                1.22.0           py313hd753461_0_cpu      conda-forge\nopenjpeg                   2.5.4            h55fea9a_0               conda-forge\nopenssl                    3.5.4            h26f9b46_0               conda-forge\npackaging                  25.0             pyh29332c3_1             conda-forge\npandas                     2.3.3            py313h08cd8bf_1          conda-forge\npillow                     11.3.0           py313ha492abd_3          conda-forge\npip                        25.2             pyh145f28c_0             conda-forge\nplatformdirs               4.5.0            pyhcf101f3_0             conda-forge\nprotobuf                   6.32.1           py313h50fafe1_2          conda-forge\npthread-stubs              0.4              hb9d3cd8_1002            conda-forge\npydantic                   2.11.10          pyh3cfb1c2_0             conda-forge\npydantic-core              2.33.2           py313h4b2b08d_0          conda-forge\npydantic-settings          2.11.0           pyh3cfb1c2_0             conda-forge\npygments                   2.19.2           pyhd8ed1ab_0             conda-forge\npython                     3.13.9           h2b335a9_100_cp313       conda-forge\npython-dateutil            2.9.0.post0      pyhe01879c_2             conda-forge\npython-dotenv              1.1.1            pyhe01879c_0             conda-forge\npython-flatbuffers         25.9.23          pyh1e1bc0e_0             conda-forge\npython-tzdata              2025.2           pyhd8ed1ab_0             conda-forge\npython_abi                 3.13             8_cp313                  conda-forge\npytz                       2025.2           pyhd8ed1ab_0             conda-forge\nrav1e                      0.7.1            h8fae777_3               conda-forge\nreadline                   8.2              h8c095d6_2               conda-forge\nrich                       14.2.0           pyhcf101f3_0             conda-forge\nruyaml                     0.91.0           pyhd8ed1ab_1             conda-forge\nscipy                      1.16.2           py313h11c21cd_0          conda-forge\nsetuptools                 80.9.0           pyhff2d567_0             conda-forge\nsix                        1.17.0           pyhe01879c_1             conda-forge\nsnappy                     1.2.2            h03e3b7b_0               conda-forge\nsniffio                    1.3.1            pyhd8ed1ab_1             conda-forge\nsvt-av1                    3.1.2            hecca717_0               conda-forge\nsympy                      1.14.0           pyh2585a3b_105           conda-forge\ntifffile                   2025.10.16       pyhd8ed1ab_0             conda-forge\ntk                         8.6.13           noxft_hd72426e_102       conda-forge\ntqdm                       4.67.1           pyhd8ed1ab_1             conda-forge\ntyping-extensions          4.15.0           h396c80c_0               conda-forge\ntyping-inspection          0.4.2            pyhd8ed1ab_0             conda-forge\ntyping_extensions          4.15.0           pyhcf101f3_0             conda-forge\ntzdata                     2025b            h78e105d_0               conda-forge\nxarray                     2025.1.2         pyhd8ed1ab_0             conda-forge\nxorg-libxau                1.0.12           hb9d3cd8_0               conda-forge\nxorg-libxdmcp              1.1.5            hb9d3cd8_0               conda-forge\nzfp                        1.0.1            h909a3a2_3               conda-forge\nzipp                       3.23.0           pyhd8ed1ab_0             conda-forge\nzlib-ng                    2.2.5            hde8ca8f_0               conda-forge\nzstd                       1.5.7            hb8e6e7a_2               conda-forge\n"}, "badge": null, "links": []}