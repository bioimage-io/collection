{
    "badge": null,
    "details": {
        "conda_list": null,
        "details": [
            {
                "conda_compare": null,
                "context": {
                    "file_name": "rdf.yaml",
                    "known_files": {
                        "bmz_model.py": "a0a0eda4a48303c0893ef3841a26f825d07f8d452529015373ea3282af2357dc",
                        "config.yaml": "766d9e102b8d03029c389de0de0cf9f496610f034d8cb6f8427322a352918048",
                        "input_sample.npy": "c02170e4a809473b590f461f7e9ac509bfb8e66d86a79ff023779d3423100a13",
                        "joint_indi_plus_BioSR.pth": "8bd431d42e449472bf77b2b181ce0f69c63b12703c691049837e0fb1a82b1447",
                        "output_sample.npy": "4010cf9fe293f7bd02101f657f807ed84638326642957fd6f57fc2642b06cc0e"
                    },
                    "perform_io_checks": true,
                    "root": "https://hypha.aicell.io/bioimage-io/artifacts/handsome-sloth/files?version=v0",
                    "update_hashes": false
                },
                "errors": [],
                "loc": [],
                "name": "Successfully created `ModelDescr` object.",
                "recommended_env": null,
                "status": "passed",
                "warnings": []
            },
            {
                "conda_compare": null,
                "context": {
                    "file_name": "rdf.yaml",
                    "known_files": {
                        "bmz_model.py": "a0a0eda4a48303c0893ef3841a26f825d07f8d452529015373ea3282af2357dc",
                        "config.yaml": "766d9e102b8d03029c389de0de0cf9f496610f034d8cb6f8427322a352918048",
                        "input_sample.npy": "c02170e4a809473b590f461f7e9ac509bfb8e66d86a79ff023779d3423100a13",
                        "joint_indi_plus_BioSR.pth": "8bd431d42e449472bf77b2b181ce0f69c63b12703c691049837e0fb1a82b1447",
                        "output_sample.npy": "4010cf9fe293f7bd02101f657f807ed84638326642957fd6f57fc2642b06cc0e"
                    },
                    "perform_io_checks": true,
                    "root": "https://hypha.aicell.io/bioimage-io/artifacts/handsome-sloth/files?version=v0",
                    "update_hashes": false
                },
                "errors": [],
                "loc": [],
                "name": "bioimageio.spec format validation model 0.5.4",
                "recommended_env": null,
                "status": "passed",
                "warnings": []
            },
            {
                "conda_compare": null,
                "context": null,
                "errors": [],
                "loc": [
                    "type"
                ],
                "name": "Has expected resource type",
                "recommended_env": null,
                "status": "passed",
                "warnings": []
            },
            {
                "conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    menuinst            A subcommand for installing and removing shortcuts via\n                        menuinst.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               Set repository access token and configure\n                        default_channels\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n",
                "context": null,
                "errors": [
                    {
                        "loc": [
                            "weights",
                            "pytorch_state_dict"
                        ],
                        "msg": "Output 'masks' disagrees with 463775 of 524288 expected values.\n Max relative difference: 7.58e-01 (= \\|1.48e+02 - 6.10e+02\\|/\\|6.10e+02 + 1e-6\\|) at {'batch': 0, 'channel': 0, 'y': 50, 'x': 67}\n Max absolute difference: 1.59e+03 (= \\|2.3270873e+04 - 2.1683711e+04\\|) at {'batch': 0, 'channel': 0, 'y': 146, 'x': 150}",
                        "traceback_html": "",
                        "traceback_md": "",
                        "type": "bioimageio.core",
                        "with_traceback": false
                    }
                ],
                "loc": [
                    "weights",
                    "pytorch_state_dict"
                ],
                "name": "Reproduce test outputs from test inputs (pytorch_state_dict)",
                "recommended_env": {
                    "channels": [
                        "conda-forge",
                        "nodefaults"
                    ],
                    "dependencies": [
                        "conda-forge::bioimageio.core",
                        "numpy >=2,<3",
                        "pip",
                        "pytorch==2.9.1",
                        "torchaudio",
                        "torchvision"
                    ],
                    "name": null
                },
                "status": "failed",
                "warnings": []
            },
            {
                "conda_compare": null,
                "context": null,
                "errors": [],
                "loc": [
                    "weights",
                    "pytorch_state_dict"
                ],
                "name": "Run pytorch_state_dict inference for inputs with batch_size: 1 and size parameter n: 0",
                "recommended_env": null,
                "status": "passed",
                "warnings": []
            },
            {
                "conda_compare": null,
                "context": null,
                "errors": [
                    {
                        "loc": [
                            "weights",
                            "pytorch_state_dict"
                        ],
                        "msg": "a Tensor with 2 elements cannot be converted to Scalar",
                        "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {font-weight: bold}\n.r6 {color: #0000ff; text-decoration-color: #0000ff}\n.r7 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r8 {color: #00ffff; text-decoration-color: #00ffff}\n.r9 {color: #808000; text-decoration-color: #808000}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline}\n.r11 {font-weight: bold; text-decoration: underline}\n.r12 {color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline}\n.r13 {color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold}\n.r14 {color: #808080; text-decoration-color: #808080}\n.r15 {color: #00ff00; text-decoration-color: #00ff00}\n.r16 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r17 {color: #008080; text-decoration-color: #008080; font-weight: bold}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/</span><span class=\"r5\">_resou</span> <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r5\">rce_tests.py</span>:768 in _test_model_inference_parametrized                                           <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">765 </span><span class=\"r4\">â”‚   â”‚   </span>) <span class=\"r6\">as</span> prediction_pipeline:                                                          <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">766 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r6\">for</span> n, batch_size, inputs, exptected_output_shape <span class=\"r7\">in</span> generate_test_cases():    <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">767 </span><span class=\"r4\">â”‚   â”‚   â”‚   â”‚   </span>error: Optional[<span class=\"r8\">str</span>] = <span class=\"r6\">None</span>                                                <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span>768 <span class=\"r4\">â”‚   â”‚   â”‚   â”‚   </span>result = prediction_pipeline.predict_sample_without_blocking(inputs)       <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">769 </span><span class=\"r4\">â”‚   â”‚   â”‚   â”‚   </span><span class=\"r6\">if</span> <span class=\"r8\">len</span>(result.members) != <span class=\"r8\">len</span>(exptected_output_shape):                     <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">770 </span><span class=\"r4\">â”‚   â”‚   â”‚   â”‚   â”‚   </span>error = (                                                              <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">771 </span><span class=\"r4\">â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   </span><span class=\"r9\">f&quot;Expected {</span><span class=\"r8\">len</span>(exptected_output_shape)<span class=\"r9\">} outputs,&quot;</span>                 <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/</span><span class=\"r5\">_predi</span> <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r5\">ction_pipeline.py</span>:160 in predict_sample_without_blocking                                         <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">157 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">if</span> <span class=\"r7\">not</span> skip_preprocessing:                                                         <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">158 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r8\">self</span>.apply_preprocessing(sample)                                               <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">159 </span><span class=\"r4\">â”‚   â”‚   </span>                                                                                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span>160 <span class=\"r4\">â”‚   â”‚   </span>output = <span class=\"r10\">self</span><span class=\"r11\">._adapter.forward(sample)</span>                                             <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">161 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">if</span> <span class=\"r7\">not</span> skip_postprocessing:                                                        <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">162 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r8\">self</span>.apply_postprocessing(output)                                              <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">163 </span>                                                                                           <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/backen</span> <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">ds/</span><span class=\"r5\">_model_adapter.py</span>:205 in forward                                                              <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">202 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span>)                                                                              <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">203 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r6\">for</span> in_id, in_order <span class=\"r7\">in</span> <span class=\"r8\">zip</span>(<span class=\"r8\">self</span>._input_ids, <span class=\"r8\">self</span>._input_axes)                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">204 </span><span class=\"r4\">â”‚   â”‚   </span>]                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span>205 <span class=\"r4\">â”‚   â”‚   </span>output_arrays = <span class=\"r10\">self</span><span class=\"r11\">._forward_impl(input_arrays)</span>                                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">206 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">assert</span> <span class=\"r8\">len</span>(output_arrays) &lt;= <span class=\"r8\">len</span>(<span class=\"r8\">self</span>._output_ids)                                 <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">207 </span><span class=\"r4\">â”‚   â”‚   </span>output_tensors = [                                                                 <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">208 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r6\">None</span> <span class=\"r6\">if</span> a <span class=\"r7\">is</span> <span class=\"r6\">None</span> <span class=\"r6\">else</span> Tensor(a, dims=d)                                       <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/backen</span> <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">ds/</span><span class=\"r5\">pytorch_backend.py</span>:64 in _forward_impl                                                        <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\"> 61 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span>assert_never(<span class=\"r8\">self</span>._mode)                                                       <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\"> 62 </span><span class=\"r4\">â”‚   â”‚   </span>                                                                                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\"> 63 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">with</span> ctxt():                                                                       <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span> 64 <span class=\"r4\">â”‚   â”‚   â”‚   </span>model_out = <span class=\"r10\">self</span><span class=\"r11\">._model(*tensors)</span>                                              <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\"> 65 </span><span class=\"r4\">â”‚   â”‚   </span>                                                                                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\"> 66 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">if</span> is_tuple(model_out) <span class=\"r7\">or</span> is_list(model_out):                                      <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\"> 67 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span>model_out_seq = model_out                                                      <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/nn/modules/</span><span class=\"r5\">modul</span> <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r5\">e.py</span>:1751 in _wrapped_call_impl                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1748 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">if</span> <span class=\"r8\">self</span>._compiled_call_impl <span class=\"r7\">is</span> <span class=\"r7\">not</span> <span class=\"r6\">None</span>:                                          <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1749 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r6\">return</span> <span class=\"r8\">self</span>._compiled_call_impl(*args, **kwargs)  <span class=\"r4\"># type: ignore[misc]</span>        <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1750 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">else</span>:                                                                             <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span>1751 <span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r6\">return</span> <span class=\"r10\">self</span><span class=\"r11\">._call_impl(*args, **kwargs)</span>                                       <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1752 </span><span class=\"r4\">â”‚   </span>                                                                                      <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1753 </span><span class=\"r4\">â”‚   </span><span class=\"r4\"># torchrec tests the code consistency with the following code</span>                         <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1754 </span><span class=\"r4\">â”‚   </span><span class=\"r4\"># fmt: off</span>                                                                            <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/nn/modules/</span><span class=\"r5\">modul</span> <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r5\">e.py</span>:1762 in _call_impl                                                                          <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1759 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">if</span> <span class=\"r7\">not</span> (<span class=\"r8\">self</span>._backward_hooks <span class=\"r7\">or</span> <span class=\"r8\">self</span>._backward_pre_hooks <span class=\"r7\">or</span> <span class=\"r8\">self</span>._forward_hooks   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1760 </span><span class=\"r4\">â”‚   â”‚   â”‚   â”‚   </span><span class=\"r7\">or</span> _global_backward_pre_hooks <span class=\"r7\">or</span> _global_backward_hooks                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1761 </span><span class=\"r4\">â”‚   â”‚   â”‚   â”‚   </span><span class=\"r7\">or</span> _global_forward_hooks <span class=\"r7\">or</span> _global_forward_pre_hooks):                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span>1762 <span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r6\">return</span> <span class=\"r11\">forward_call(*args, **kwargs)</span>                                          <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1763 </span><span class=\"r4\">â”‚   â”‚   </span>                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1764 </span><span class=\"r4\">â”‚   â”‚   </span>result = <span class=\"r6\">None</span>                                                                     <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1765 </span><span class=\"r4\">â”‚   â”‚   </span>called_always_called_hooks = <span class=\"r8\">set</span>()                                                <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/.cache/bioimageio/</span><span class=\"r5\">c8237442040f9275404fff211637edf9-bmz_model.py</span>:1418 in forward     <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1415 </span><span class=\"r4\">â”‚   â”‚   </span>x_normed = x_normed.float().to(device)                                            <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1416 </span><span class=\"r4\">â”‚   â”‚   </span>                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1417 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r4\"># get the model output</span>                                                            <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span>1418 <span class=\"r4\">â”‚   â”‚   </span>out = <span class=\"r10\">self</span><span class=\"r11\">.model.inference(</span>                                                       <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1419 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r11\">x_normed,</span>                                                                     <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1420 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r11\">num_timesteps=</span><span class=\"r12\">1</span><span class=\"r11\">,</span>                                                              <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1421 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r11\">infer_time=</span><span class=\"r12\">True</span>                                                               <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/utils/</span><span class=\"r5\">_contextli</span> <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r5\">b.py</span>:116 in decorate_context                                                                     <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">113 </span><span class=\"r4\">â”‚   </span><span class=\"r13\">@functools</span>.wraps(func)                                                                 <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">114 </span><span class=\"r4\">â”‚   </span><span class=\"r6\">def</span><span class=\"r14\"> </span><span class=\"r15\">decorate_context</span>(*args, **kwargs):                                                 <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">115 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">with</span> ctx_factory():                                                                <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span>116 <span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r6\">return</span> <span class=\"r11\">func(*args, **kwargs)</span>                                                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">117 </span><span class=\"r4\">â”‚   </span>                                                                                       <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">118 </span><span class=\"r4\">â”‚   </span><span class=\"r6\">return</span> decorate_context                                                                <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">119 </span>                                                                                           <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r4\">/home/runner/.cache/bioimageio/</span><span class=\"r5\">c8237442040f9275404fff211637edf9-bmz_model.py</span>:1265 in inference   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>                                                                                                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1262 </span><span class=\"r4\">â”‚   â”‚   </span>t_float_start_ch1 = t_float_start                                                 <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1263 </span><span class=\"r4\">â”‚   â”‚   </span>t_float_start_ch2 = <span class=\"r6\">1</span> - t_float_start                                             <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1264 </span><span class=\"r4\">â”‚   â”‚   </span><span class=\"r6\">if</span> infer_time <span class=\"r7\">and</span> <span class=\"r8\">self</span>.time_predictor1 <span class=\"r7\">and</span> <span class=\"r8\">self</span>.time_predictor2:                  <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span> <span class=\"r1\">â± </span>1265 <span class=\"r4\">â”‚   â”‚   â”‚   </span>t_float_start_ch1 = <span class=\"r10\">self</span><span class=\"r11\">.time_predictor1(x_in).cpu().item()</span>                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1266 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span>t_float_start_ch2 = <span class=\"r8\">self</span>.time_predictor2(x_in).cpu().item()                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1267 </span><span class=\"r4\">â”‚   â”‚   â”‚   </span><span class=\"r8\">print</span>(t_float_start_ch1, t_float_start_ch2)                                   <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â”‚</span>   <span class=\"r4\">1268 </span>                                                                                          <span class=\"r1\">â”‚</span>\n<span class=\"r1\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n<span class=\"r16\">RuntimeError: </span>a Tensor with <span class=\"r17\">2</span> elements cannot be converted to Scalar\n</code></pre>\n</body>\n</html>\n",
                        "traceback_md": "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/_resou â”‚\nâ”‚ rce_tests.py:768 in _test_model_inference_parametrized                                           â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   765 â”‚   â”‚   ) as prediction_pipeline:                                                          â”‚\nâ”‚   766 â”‚   â”‚   â”‚   for n, batch_size, inputs, exptected_output_shape in generate_test_cases():    â”‚\nâ”‚   767 â”‚   â”‚   â”‚   â”‚   error: Optional[str] = None                                                â”‚\nâ”‚ â± 768 â”‚   â”‚   â”‚   â”‚   result = prediction_pipeline.predict_sample_without_blocking(inputs)       â”‚\nâ”‚   769 â”‚   â”‚   â”‚   â”‚   if len(result.members) != len(exptected_output_shape):                     â”‚\nâ”‚   770 â”‚   â”‚   â”‚   â”‚   â”‚   error = (                                                              â”‚\nâ”‚   771 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   f\"Expected {len(exptected_output_shape)} outputs,\"                 â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/_predi â”‚\nâ”‚ ction_pipeline.py:160 in predict_sample_without_blocking                                         â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   157 â”‚   â”‚   if not skip_preprocessing:                                                         â”‚\nâ”‚   158 â”‚   â”‚   â”‚   self.apply_preprocessing(sample)                                               â”‚\nâ”‚   159 â”‚   â”‚                                                                                      â”‚\nâ”‚ â± 160 â”‚   â”‚   output = self._adapter.forward(sample)                                             â”‚\nâ”‚   161 â”‚   â”‚   if not skip_postprocessing:                                                        â”‚\nâ”‚   162 â”‚   â”‚   â”‚   self.apply_postprocessing(output)                                              â”‚\nâ”‚   163                                                                                            â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/backen â”‚\nâ”‚ ds/_model_adapter.py:205 in forward                                                              â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   202 â”‚   â”‚   â”‚   )                                                                              â”‚\nâ”‚   203 â”‚   â”‚   â”‚   for in_id, in_order in zip(self._input_ids, self._input_axes)                  â”‚\nâ”‚   204 â”‚   â”‚   ]                                                                                  â”‚\nâ”‚ â± 205 â”‚   â”‚   output_arrays = self._forward_impl(input_arrays)                                   â”‚\nâ”‚   206 â”‚   â”‚   assert len(output_arrays) <= len(self._output_ids)                                 â”‚\nâ”‚   207 â”‚   â”‚   output_tensors = [                                                                 â”‚\nâ”‚   208 â”‚   â”‚   â”‚   None if a is None else Tensor(a, dims=d)                                       â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/backen â”‚\nâ”‚ ds/pytorch_backend.py:64 in _forward_impl                                                        â”‚\nâ”‚                                                                                                  â”‚\nâ”‚    61 â”‚   â”‚   â”‚   assert_never(self._mode)                                                       â”‚\nâ”‚    62 â”‚   â”‚                                                                                      â”‚\nâ”‚    63 â”‚   â”‚   with ctxt():                                                                       â”‚\nâ”‚ â±  64 â”‚   â”‚   â”‚   model_out = self._model(*tensors)                                              â”‚\nâ”‚    65 â”‚   â”‚                                                                                      â”‚\nâ”‚    66 â”‚   â”‚   if is_tuple(model_out) or is_list(model_out):                                      â”‚\nâ”‚    67 â”‚   â”‚   â”‚   model_out_seq = model_out                                                      â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/nn/modules/modul â”‚\nâ”‚ e.py:1751 in _wrapped_call_impl                                                                  â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   1748 â”‚   â”‚   if self._compiled_call_impl is not None:                                          â”‚\nâ”‚   1749 â”‚   â”‚   â”‚   return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]        â”‚\nâ”‚   1750 â”‚   â”‚   else:                                                                             â”‚\nâ”‚ â± 1751 â”‚   â”‚   â”‚   return self._call_impl(*args, **kwargs)                                       â”‚\nâ”‚   1752 â”‚                                                                                         â”‚\nâ”‚   1753 â”‚   # torchrec tests the code consistency with the following code                         â”‚\nâ”‚   1754 â”‚   # fmt: off                                                                            â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/nn/modules/modul â”‚\nâ”‚ e.py:1762 in _call_impl                                                                          â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   1759 â”‚   â”‚   if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks   â”‚\nâ”‚   1760 â”‚   â”‚   â”‚   â”‚   or _global_backward_pre_hooks or _global_backward_hooks                   â”‚\nâ”‚   1761 â”‚   â”‚   â”‚   â”‚   or _global_forward_hooks or _global_forward_pre_hooks):                   â”‚\nâ”‚ â± 1762 â”‚   â”‚   â”‚   return forward_call(*args, **kwargs)                                          â”‚\nâ”‚   1763 â”‚   â”‚                                                                                     â”‚\nâ”‚   1764 â”‚   â”‚   result = None                                                                     â”‚\nâ”‚   1765 â”‚   â”‚   called_always_called_hooks = set()                                                â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/.cache/bioimageio/c8237442040f9275404fff211637edf9-bmz_model.py:1418 in forward     â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   1415 â”‚   â”‚   x_normed = x_normed.float().to(device)                                            â”‚\nâ”‚   1416 â”‚   â”‚                                                                                     â”‚\nâ”‚   1417 â”‚   â”‚   # get the model output                                                            â”‚\nâ”‚ â± 1418 â”‚   â”‚   out = self.model.inference(                                                       â”‚\nâ”‚   1419 â”‚   â”‚   â”‚   x_normed,                                                                     â”‚\nâ”‚   1420 â”‚   â”‚   â”‚   num_timesteps=1,                                                              â”‚\nâ”‚   1421 â”‚   â”‚   â”‚   infer_time=True                                                               â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/utils/_contextli â”‚\nâ”‚ b.py:116 in decorate_context                                                                     â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   113 â”‚   @functools.wraps(func)                                                                 â”‚\nâ”‚   114 â”‚   def decorate_context(*args, **kwargs):                                                 â”‚\nâ”‚   115 â”‚   â”‚   with ctx_factory():                                                                â”‚\nâ”‚ â± 116 â”‚   â”‚   â”‚   return func(*args, **kwargs)                                                   â”‚\nâ”‚   117 â”‚                                                                                          â”‚\nâ”‚   118 â”‚   return decorate_context                                                                â”‚\nâ”‚   119                                                                                            â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/.cache/bioimageio/c8237442040f9275404fff211637edf9-bmz_model.py:1265 in inference   â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   1262 â”‚   â”‚   t_float_start_ch1 = t_float_start                                                 â”‚\nâ”‚   1263 â”‚   â”‚   t_float_start_ch2 = 1 - t_float_start                                             â”‚\nâ”‚   1264 â”‚   â”‚   if infer_time and self.time_predictor1 and self.time_predictor2:                  â”‚\nâ”‚ â± 1265 â”‚   â”‚   â”‚   t_float_start_ch1 = self.time_predictor1(x_in).cpu().item()                   â”‚\nâ”‚   1266 â”‚   â”‚   â”‚   t_float_start_ch2 = self.time_predictor2(x_in).cpu().item()                   â”‚\nâ”‚   1267 â”‚   â”‚   â”‚   print(t_float_start_ch1, t_float_start_ch2)                                   â”‚\nâ”‚   1268                                                                                           â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\nRuntimeError: a Tensor with 2 elements cannot be converted to Scalar\n",
                        "type": "bioimageio.core",
                        "with_traceback": true
                    }
                ],
                "loc": [
                    "weights",
                    "pytorch_state_dict"
                ],
                "name": "Run pytorch_state_dict inference for parametrized inputs",
                "recommended_env": null,
                "status": "failed",
                "warnings": []
            }
        ],
        "env": [
            [
                "bioimageio.spec",
                "0.5.4.1",
                "",
                ""
            ],
            [
                "bioimageio.core",
                "0.8.0",
                "",
                ""
            ]
        ],
        "format_version": "0.5.4",
        "id": "handsome-sloth",
        "name": "bioimageio format validation",
        "source_name": "https://hypha.aicell.io/bioimage-io/artifacts/handsome-sloth/files/rdf.yaml?version=v0",
        "status": "failed",
        "type": "model"
    },
    "error": "\n|        âŒ        |                              bioimageio format validation                              |\n|       ---       |                                          ---                                           |\n| status          | failed                                                                                 |\n| source          | https://hypha.aicell.io/bioimage-io/artifacts/handsome-sloth/files/rdf.yaml?version=v0 |\n| id              | handsome-sloth                                                                         |\n| format version  | model 0.5.4                                                                            |\n| bioimageio.spec | 0.5.4.1                                                                                |\n| bioimageio.core | 0.8.0                                                                                  |\n\n|     |                     Location                    |                                                              Details                                                               |\n| --- |                       ---                       |                                                                ---                                                                 |\n| âœ”ï¸  |                                                 | Successfully created `ModelDescr` object.                                                                                          |\n| ğŸ”   | `context:perform_io_checks`                     | True                                                                                                                               |\n| ğŸ”   | `context:root`                                  | https://hypha.aicell.io/bioimage-io/artifacts/handsome-sloth/files?version=v0                                                      |\n| ğŸ”   | `context:known_files.config.yaml`               | 766d9e102b8d03029c389de0de0cf9f496610f034d8cb6f8427322a352918048                                                                   |\n| ğŸ”   | `context:known_files.input_sample.npy`          | c02170e4a809473b590f461f7e9ac509bfb8e66d86a79ff023779d3423100a13                                                                   |\n| ğŸ”   | `context:known_files.output_sample.npy`         | 4010cf9fe293f7bd02101f657f807ed84638326642957fd6f57fc2642b06cc0e                                                                   |\n| ğŸ”   | `context:known_files.bmz_model.py`              | a0a0eda4a48303c0893ef3841a26f825d07f8d452529015373ea3282af2357dc                                                                   |\n| ğŸ”   | `context:known_files.joint_indi_plus_BioSR.pth` | 8bd431d42e449472bf77b2b181ce0f69c63b12703c691049837e0fb1a82b1447                                                                   |\n| âœ”ï¸  |                                                 | bioimageio.spec format validation model 0.5.4                                                                                      |\n| âœ”ï¸  | `type`                                          | Has expected resource type                                                                                                         |\n| âŒ   | `weights.pytorch_state_dict`                    | Reproduce test outputs from test inputs (pytorch_state_dict)                                                                       |\n| ğŸ   | `weights.pytorch_state_dict`                    | recommended conda env for:                                                                                                         |\n|     |                                                 | Reproduce test outputs from test inputs (pytorch_state_dict)                                                                       |\n|     |                                                 | See [Conda Environment 1](#conda-environment-1).                                                                                   |\n| ğŸ   | `weights.pytorch_state_dict`                    | conda compare (Reproduce test outputs from test inputs (pytorch_state_dict)):                                                      |\n|     |                                                 | See [Conda Environment Comparison 1](#conda-environment-comparison-1).                                                             |\n| âŒ   | `weights.pytorch_state_dict`                    | Output 'masks' disagrees with 463775 of 524288 expected values.                                                                    |\n|     |                                                 |  Max relative difference: 7.58e-01 (= \\|1.48e+02 - 6.10e+02\\|/\\|6.10e+02 + 1e-6\\|) at {'batch': 0, 'channel': 0, 'y': 50, 'x': 67} |\n|     |                                                 |  Max absolute difference: 1.59e+03 (= \\|2.3270873e+04 - 2.1683711e+04\\|) at {'batch': 0, 'channel': 0, 'y': 146, 'x': 150}         |\n|     |                                                 |                                                                                                                                    |\n| âœ”ï¸  | `weights.pytorch_state_dict`                    | Run pytorch_state_dict inference for inputs with batch_size: 1 and size parameter n: 0                                             |\n| âŒ   | `weights.pytorch_state_dict`                    | Run pytorch_state_dict inference for parametrized inputs                                                                           |\n| âŒ   | `weights.pytorch_state_dict`                    | a Tensor with 2 elements cannot be converted to Scalar                                                                             |\n|     |                                                 | See [Traceback 1](#traceback-1).                                                                                                   |\n\n### Conda Environment 1\n\n```yaml\n%YAML 1.2\n---\nchannels:\n  - conda-forge\n  - nodefaults\ndependencies:\n  - conda-forge::bioimageio.core\n  - numpy >=2,<3\n  - pip\n  - pytorch==2.9.1\n  - torchaudio\n  - torchvision\n```\n\n\n### Conda Environment Comparison 1\n\n```\nusage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    menuinst            A subcommand for installing and removing shortcuts via\n                        menuinst.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               Set repository access token and configure\n                        default_channels\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n```\n\n\n### Traceback 1\n\n```\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/_resou â”‚\nâ”‚ rce_tests.py:768 in _test_model_inference_parametrized                                           â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   765 â”‚   â”‚   ) as prediction_pipeline:                                                          â”‚\nâ”‚   766 â”‚   â”‚   â”‚   for n, batch_size, inputs, exptected_output_shape in generate_test_cases():    â”‚\nâ”‚   767 â”‚   â”‚   â”‚   â”‚   error: Optional[str] = None                                                â”‚\nâ”‚ â± 768 â”‚   â”‚   â”‚   â”‚   result = prediction_pipeline.predict_sample_without_blocking(inputs)       â”‚\nâ”‚   769 â”‚   â”‚   â”‚   â”‚   if len(result.members) != len(exptected_output_shape):                     â”‚\nâ”‚   770 â”‚   â”‚   â”‚   â”‚   â”‚   error = (                                                              â”‚\nâ”‚   771 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   f\"Expected {len(exptected_output_shape)} outputs,\"                 â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/_predi â”‚\nâ”‚ ction_pipeline.py:160 in predict_sample_without_blocking                                         â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   157 â”‚   â”‚   if not skip_preprocessing:                                                         â”‚\nâ”‚   158 â”‚   â”‚   â”‚   self.apply_preprocessing(sample)                                               â”‚\nâ”‚   159 â”‚   â”‚                                                                                      â”‚\nâ”‚ â± 160 â”‚   â”‚   output = self._adapter.forward(sample)                                             â”‚\nâ”‚   161 â”‚   â”‚   if not skip_postprocessing:                                                        â”‚\nâ”‚   162 â”‚   â”‚   â”‚   self.apply_postprocessing(output)                                              â”‚\nâ”‚   163                                                                                            â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/backen â”‚\nâ”‚ ds/_model_adapter.py:205 in forward                                                              â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   202 â”‚   â”‚   â”‚   )                                                                              â”‚\nâ”‚   203 â”‚   â”‚   â”‚   for in_id, in_order in zip(self._input_ids, self._input_axes)                  â”‚\nâ”‚   204 â”‚   â”‚   ]                                                                                  â”‚\nâ”‚ â± 205 â”‚   â”‚   output_arrays = self._forward_impl(input_arrays)                                   â”‚\nâ”‚   206 â”‚   â”‚   assert len(output_arrays) <= len(self._output_ids)                                 â”‚\nâ”‚   207 â”‚   â”‚   output_tensors = [                                                                 â”‚\nâ”‚   208 â”‚   â”‚   â”‚   None if a is None else Tensor(a, dims=d)                                       â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/bioimageio/core/backen â”‚\nâ”‚ ds/pytorch_backend.py:64 in _forward_impl                                                        â”‚\nâ”‚                                                                                                  â”‚\nâ”‚    61 â”‚   â”‚   â”‚   assert_never(self._mode)                                                       â”‚\nâ”‚    62 â”‚   â”‚                                                                                      â”‚\nâ”‚    63 â”‚   â”‚   with ctxt():                                                                       â”‚\nâ”‚ â±  64 â”‚   â”‚   â”‚   model_out = self._model(*tensors)                                              â”‚\nâ”‚    65 â”‚   â”‚                                                                                      â”‚\nâ”‚    66 â”‚   â”‚   if is_tuple(model_out) or is_list(model_out):                                      â”‚\nâ”‚    67 â”‚   â”‚   â”‚   model_out_seq = model_out                                                      â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/nn/modules/modul â”‚\nâ”‚ e.py:1751 in _wrapped_call_impl                                                                  â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   1748 â”‚   â”‚   if self._compiled_call_impl is not None:                                          â”‚\nâ”‚   1749 â”‚   â”‚   â”‚   return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]        â”‚\nâ”‚   1750 â”‚   â”‚   else:                                                                             â”‚\nâ”‚ â± 1751 â”‚   â”‚   â”‚   return self._call_impl(*args, **kwargs)                                       â”‚\nâ”‚   1752 â”‚                                                                                         â”‚\nâ”‚   1753 â”‚   # torchrec tests the code consistency with the following code                         â”‚\nâ”‚   1754 â”‚   # fmt: off                                                                            â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/nn/modules/modul â”‚\nâ”‚ e.py:1762 in _call_impl                                                                          â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   1759 â”‚   â”‚   if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks   â”‚\nâ”‚   1760 â”‚   â”‚   â”‚   â”‚   or _global_backward_pre_hooks or _global_backward_hooks                   â”‚\nâ”‚   1761 â”‚   â”‚   â”‚   â”‚   or _global_forward_hooks or _global_forward_pre_hooks):                   â”‚\nâ”‚ â± 1762 â”‚   â”‚   â”‚   return forward_call(*args, **kwargs)                                          â”‚\nâ”‚   1763 â”‚   â”‚                                                                                     â”‚\nâ”‚   1764 â”‚   â”‚   result = None                                                                     â”‚\nâ”‚   1765 â”‚   â”‚   called_always_called_hooks = set()                                                â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/.cache/bioimageio/c8237442040f9275404fff211637edf9-bmz_model.py:1418 in forward     â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   1415 â”‚   â”‚   x_normed = x_normed.float().to(device)                                            â”‚\nâ”‚   1416 â”‚   â”‚                                                                                     â”‚\nâ”‚   1417 â”‚   â”‚   # get the model output                                                            â”‚\nâ”‚ â± 1418 â”‚   â”‚   out = self.model.inference(                                                       â”‚\nâ”‚   1419 â”‚   â”‚   â”‚   x_normed,                                                                     â”‚\nâ”‚   1420 â”‚   â”‚   â”‚   num_timesteps=1,                                                              â”‚\nâ”‚   1421 â”‚   â”‚   â”‚   infer_time=True                                                               â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/micromamba/envs/ilastik-release/lib/python3.11/site-packages/torch/utils/_contextli â”‚\nâ”‚ b.py:116 in decorate_context                                                                     â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   113 â”‚   @functools.wraps(func)                                                                 â”‚\nâ”‚   114 â”‚   def decorate_context(*args, **kwargs):                                                 â”‚\nâ”‚   115 â”‚   â”‚   with ctx_factory():                                                                â”‚\nâ”‚ â± 116 â”‚   â”‚   â”‚   return func(*args, **kwargs)                                                   â”‚\nâ”‚   117 â”‚                                                                                          â”‚\nâ”‚   118 â”‚   return decorate_context                                                                â”‚\nâ”‚   119                                                                                            â”‚\nâ”‚                                                                                                  â”‚\nâ”‚ /home/runner/.cache/bioimageio/c8237442040f9275404fff211637edf9-bmz_model.py:1265 in inference   â”‚\nâ”‚                                                                                                  â”‚\nâ”‚   1262 â”‚   â”‚   t_float_start_ch1 = t_float_start                                                 â”‚\nâ”‚   1263 â”‚   â”‚   t_float_start_ch2 = 1 - t_float_start                                             â”‚\nâ”‚   1264 â”‚   â”‚   if infer_time and self.time_predictor1 and self.time_predictor2:                  â”‚\nâ”‚ â± 1265 â”‚   â”‚   â”‚   t_float_start_ch1 = self.time_predictor1(x_in).cpu().item()                   â”‚\nâ”‚   1266 â”‚   â”‚   â”‚   t_float_start_ch2 = self.time_predictor2(x_in).cpu().item()                   â”‚\nâ”‚   1267 â”‚   â”‚   â”‚   print(t_float_start_ch1, t_float_start_ch2)                                   â”‚\nâ”‚   1268                                                                                           â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\nRuntimeError: a Tensor with 2 elements cannot be converted to Scalar\n```\n\n",
    "links": [
        "ilastik/ilastik"
    ],
    "status": "failed",
    "tool": "ilastik"
}