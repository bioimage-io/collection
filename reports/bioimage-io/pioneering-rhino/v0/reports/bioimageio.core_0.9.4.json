{"status": "failed", "score": 0.0, "error": "'unet_f905821f2882ca182ffcfcb1a4c7fd2737c0548dda88fcb58721f3159a54837f'", "details": {"name": "bioimageio format validation", "source_name": "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/rdf.yaml?version=v0", "id": "10.5281/zenodo.6334383/7805067", "type": "model", "format_version": "0.4.10", "status": "failed", "metadata_completeness": 0.0, "details": [{"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/raw.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/pred.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/doc.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/test-input.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/test-output.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/confocal_2D_unet_ovules_ds2x.pytorch?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/unet.py?version=v0": null, "confocal_2D_unet_ovules_ds2x.pytorch": "4163e310baf0a826640b9a7016b3f2fe2cb6ac38e310b479d9cfee23085c5534", "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/torchscript_tracing.pt?version=v0": null, "torchscript_tracing.pt": "c6d2e01f99d4dedd9c1f5a9093b3525f062d6e2c1f377b0e76c531cdee06cec9"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.4.10", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/raw.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/pred.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/doc.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/test-input.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/test-output.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/confocal_2D_unet_ovules_ds2x.pytorch?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/unet.py?version=v0": null, "confocal_2D_unet_ovules_ds2x.pytorch": "4163e310baf0a826640b9a7016b3f2fe2cb6ac38e310b479d9cfee23085c5534", "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/torchscript_tracing.pt?version=v0": null, "torchscript_tracing.pt": "c6d2e01f99d4dedd9c1f5a9093b3525f062d6e2c1f377b0e76c531cdee06cec9"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (pytorch_state_dict)", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "'unet_f905821f2882ca182ffcfcb1a4c7fd2737c0548dda88fcb58721f3159a54837f'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   108 \u2502   module = sys.modules.get(module_name)                                                  \u2502\n\u2502   109 \u2502   if module is None:                                                                     \u2502\n\u2502   110 \u2502   \u2502   try:                                                                               \u2502\n\u2502 \u2771 111 \u2502   \u2502   \u2502   tmp_dir = TemporaryDirectory(ignore_cleanup_errors=True)                       \u2502\n\u2502   112 \u2502   \u2502   \u2502   module_path = Path(tmp_dir.name) / module_name                                 \u2502\n\u2502   113 \u2502   \u2502   \u2502   if reader.original_file_name.endswith(\".zip\") or is_zipfile(reader):           \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   module_path.mkdir()                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nTypeError: __init__() got an unexpected keyword argument 'ignore_cleanup_errors'\n\nDuring handling of the above exception, another exception occurred:\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   642 \u2502   \u2502   inputs = get_test_inputs(model)                                                    \u2502\n\u2502   643 \u2502   \u2502   expected = get_test_outputs(model)                                                 \u2502\n\u2502   644 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 645 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   646 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   647 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   648 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(inputs)          \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502   110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502 \u2771 112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   \u2502   )                                                                      \u2502\n\u2502   115 \u2502   \u2502   \u2502   \u2502   except Exception as e:                                                     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    35 \u2502   \u2502   \u2502   raise ValueError(\"No `pytorch_state_dict` weights found\")                      \u2502\n\u2502    36 \u2502   \u2502                                                                                      \u2502\n\u2502    37 \u2502   \u2502   devices = get_devices(devices)                                                     \u2502\n\u2502 \u2771  38 \u2502   \u2502   self._model = load_torch_model(weights, load_state=True, devices=devices)          \u2502\n\u2502    39 \u2502   \u2502   if mode == \"eval\":                                                                 \u2502\n\u2502    40 \u2502   \u2502   \u2502   self._model = self._model.eval()                                               \u2502\n\u2502    41 \u2502   \u2502   elif mode == \"train\":                                                              \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   100 \u2502   load_state: bool = True,                                                               \u2502\n\u2502   101 \u2502   devices: Optional[Sequence[Union[str, torch.device]]] = None,                          \u2502\n\u2502   102 ) -> nn.Module:                                                                            \u2502\n\u2502 \u2771 103 \u2502   custom_callable = import_callable(                                                     \u2502\n\u2502   104 \u2502   \u2502   weight_spec.architecture,                                                          \u2502\n\u2502   105 \u2502   \u2502   sha256=(                                                                           \u2502\n\u2502   106 \u2502   \u2502   \u2502   weight_spec.architecture_sha256                                                \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    72 \u2502   \u2502   module = importlib.import_module(node.import_from)                                 \u2502\n\u2502    73 \u2502   \u2502   c = getattr(module, str(node.callable))                                            \u2502\n\u2502    74 \u2502   elif isinstance(node, CallableFromFile):                                               \u2502\n\u2502 \u2771  75 \u2502   \u2502   c = _import_from_file_impl(node.source_file, str(node.callable_name), **kwargs)    \u2502\n\u2502    76 \u2502   elif isinstance(node, ArchitectureFromFileDescr):                                      \u2502\n\u2502    77 \u2502   \u2502   c = _import_from_file_impl(node.source, str(node.callable), sha256=node.sha256)    \u2502\n\u2502    78 \u2502   else:                                                                                  \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   132 \u2502   \u2502   \u2502   importlib_spec.loader.exec_module(module)                                      \u2502\n\u2502   133 \u2502   \u2502                                                                                      \u2502\n\u2502   134 \u2502   \u2502   except Exception as e:                                                             \u2502\n\u2502 \u2771 135 \u2502   \u2502   \u2502   del sys.modules[module_name]                                                   \u2502\n\u2502   136 \u2502   \u2502   \u2502   raise ImportError(f\"Failed to import {source}\") from e                         \u2502\n\u2502   137 \u2502                                                                                          \u2502\n\u2502   138 \u2502   try:                                                                                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nKeyError: 'unet_f905821f2882ca182ffcfcb1a4c7fd2737c0548dda88fcb58721f3159a54837f'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r9 {color: #800080; text-decoration-color: #800080; font-weight: bold}\n.r10 {font-weight: bold}\n.r11 {color: #008000; text-decoration-color: #008000}\n.r12 {font-style: italic}\n.r13 {color: #00ffff; text-decoration-color: #00ffff}\n.r14 {color: #808080; text-decoration-color: #808080}\n.r15 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">108 </span><span class=\"r4\">\u2502   </span>module = sys.modules.get(module_name)                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">if</span> module <span class=\"r6\">is</span> <span class=\"r5\">None</span>:                                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>111 <span class=\"r4\">\u2502   \u2502   \u2502   </span>tmp_dir = TemporaryDirectory(ignore_cleanup_errors=<span class=\"r5\">True</span>)                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">112 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>module_path = Path(tmp_dir.name) / module_name                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> reader.original_file_name.endswith(<span class=\"r7\">&quot;.zip&quot;</span>) <span class=\"r6\">or</span> is_zipfile(reader):           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span>module_path.mkdir()                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">TypeError: </span><span class=\"r9\">__init__</span><span class=\"r10\">()</span> got an unexpected keyword argument <span class=\"r11\">&#x27;ignore_cleanup_errors&#x27;</span>\n\n<span class=\"r12\">During handling of the above exception, another exception occurred:</span>\n\n<span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">642 </span><span class=\"r4\">\u2502   \u2502   </span>inputs = get_test_inputs(model)                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">643 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_outputs(model)                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">644 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>645 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">646 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">647 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">648 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(inputs)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r13\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r6\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r6\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r13\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r13\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">.pytorch_backend</span><span class=\"r14\"> </span><span class=\"r5\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">111 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>112 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>)                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">115 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 35 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ValueError</span>(<span class=\"r7\">&quot;No `pytorch_state_dict` weights found&quot;</span>)                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 36 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 37 </span><span class=\"r4\">\u2502   \u2502   </span>devices = get_devices(devices)                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 38 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r13\">self</span>._model = load_torch_model(weights, load_state=<span class=\"r5\">True</span>, devices=devices)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 39 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> mode == <span class=\"r7\">&quot;eval&quot;</span>:                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 40 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r13\">self</span>._model = <span class=\"r13\">self</span>._model.eval()                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 41 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">elif</span> mode == <span class=\"r7\">&quot;train&quot;</span>:                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">100 </span><span class=\"r4\">\u2502   </span>load_state: <span class=\"r13\">bool</span> = <span class=\"r5\">True</span>,                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">101 </span><span class=\"r4\">\u2502   </span>devices: Optional[Sequence[Union[<span class=\"r13\">str</span>, torch.device]]] = <span class=\"r5\">None</span>,                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">102 </span>) -&gt; nn.Module:                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>103 <span class=\"r4\">\u2502   </span>custom_callable = import_callable(                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">104 </span><span class=\"r4\">\u2502   \u2502   </span>weight_spec.architecture,                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">105 </span><span class=\"r4\">\u2502   \u2502   </span>sha256=(                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">106 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>weight_spec.architecture_sha256                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 72 </span><span class=\"r4\">\u2502   \u2502   </span>module = importlib.import_module(node.import_from)                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 73 </span><span class=\"r4\">\u2502   \u2502   </span>c = <span class=\"r13\">getattr</span>(module, <span class=\"r13\">str</span>(node.callable))                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 74 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, CallableFromFile):                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 75 <span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source_file, <span class=\"r13\">str</span>(node.callable_name), **kwargs)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 76 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, ArchitectureFromFileDescr):                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 77 </span><span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source, <span class=\"r13\">str</span>(node.callable), sha256=node.sha256)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 78 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">else</span>:                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>importlib_spec.loader.exec_module(module)                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">134 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>135 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">del</span> sys.modules[module_name]                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">136 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ImportError</span>(<span class=\"r7\">f&quot;Failed to import {</span>source<span class=\"r7\">}&quot;</span>) <span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">e</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">137 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">138 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">KeyError: </span><span class=\"r11\">&#x27;unet_f905821f2882ca182ffcfcb1a4c7fd2737c0548dda88fcb58721f3159a54837f&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==1.10.1", "setuptools <70.0.0", "torchaudio==0.10.1", "torchvision==0.11.2"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Reproduce test outputs from test inputs (torchscript)", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==2.0.0", "setuptools <70.0.0", "torchaudio==2.0.0", "torchvision==0.15.0"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/raw.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/pred.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/doc.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/test-input.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/test-output.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/confocal_2D_unet_ovules_ds2x.pytorch?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/unet.py?version=v0": null, "confocal_2D_unet_ovules_ds2x.pytorch": "4163e310baf0a826640b9a7016b3f2fe2cb6ac38e310b479d9cfee23085c5534", "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/torchscript_tracing.pt?version=v0": null, "torchscript_tracing.pt": "c6d2e01f99d4dedd9c1f5a9093b3525f062d6e2c1f377b0e76c531cdee06cec9"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.4.10", "status": "passed", "loc": [], "errors": [], "warnings": [{"loc": ["weights", "pytorch_state_dict", "pytorch_version"], "msg": "missing. Please specify the PyTorch version these PyTorch state dict weights were created with.", "type": "warning", "severity": 35}], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/raw.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/pred.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/doc.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/test-input.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/test-output.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/confocal_2D_unet_ovules_ds2x.pytorch?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/unet.py?version=v0": null, "confocal_2D_unet_ovules_ds2x.pytorch": "4163e310baf0a826640b9a7016b3f2fe2cb6ac38e310b479d9cfee23085c5534", "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files/torchscript_tracing.pt?version=v0": null, "torchscript_tracing.pt": "c6d2e01f99d4dedd9c1f5a9093b3525f062d6e2c1f377b0e76c531cdee06cec9"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/pioneering-rhino/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (pytorch_state_dict)", "status": "passed", "loc": ["weights", "pytorch_state_dict"], "errors": [], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==1.10.1", "setuptools <70.0.0", "torchaudio==0.10.1", "torchvision==0.11.2"]}, "saved_conda_compare": "pytorch found but mismatch. Specification pkg: pytorch==1.10.1, Running pkg: pytorch=2.0.0=py3.10_cpu_0\ntorchaudio found but mismatch. Specification pkg: torchaudio==0.10.1, Running pkg: torchaudio=2.0.0=py310_cpu\ntorchvision found but mismatch. Specification pkg: torchvision==0.11.2, Running pkg: torchvision=0.15.0=py310_cpu\n"}, {"name": "Reproduce test outputs from test inputs (torchscript)", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==2.0.0", "setuptools <70.0.0", "torchaudio==2.0.0", "torchvision==0.15.0"]}, "saved_conda_compare": "Success. All the packages in the specification file are present in the environment with matching version and build string.\n"}], "env": [["bioimageio.core", "0.9.0", "", ""], ["bioimageio.spec", "0.5.4.3", "", ""]], "saved_conda_list": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, "badge": null, "links": []}