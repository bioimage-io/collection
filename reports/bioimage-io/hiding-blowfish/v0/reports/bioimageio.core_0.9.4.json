{"status": "failed", "score": 0.0, "error": "/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent\n\n'unet_64af2e39972beb94019a1c97d42b29a8d8827d1b0f0845207c3b82c1a242f354'", "details": {"name": "bioimageio format validation", "source_name": "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/rdf.yaml?version=v0", "id": "10.5281/zenodo.6406756/6811922", "type": "model", "format_version": "0.4.10", "status": "failed", "metadata_completeness": 0.7528089887640449, "details": [{"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/per_sample_scale_range.ijm?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/sample_input_0.tif?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/sample_output_0.tif?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/test_input_0.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/test_output_0.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/environment.yaml?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/unet.py?version=v0": null, "weights.pt": "afc9a185f89be44eeeabe12454a589fb9572b5bae62c64fb4215c3015fa81f0d", "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "0a5f6e018828c723369904231ad48b45e0126b417aeaaba977d15a08b897d035"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.4.10", "status": "passed", "loc": [], "errors": [], "warnings": [{"loc": ["weights", "pytorch_state_dict", "dependencies"], "msg": "Custom dependencies (conda:environment.yaml) specified. Avoid this whenever possible to allow execution in a wider range of software environments.", "type": "warning", "severity": 30}, {"loc": ["weights", "pytorch_state_dict", "pytorch_version"], "msg": "missing. Please specify the PyTorch version these PyTorch state dict weights were created with.", "type": "warning", "severity": 35}, {"loc": ["weights", "torchscript", "pytorch_version"], "msg": "missing. Please specify the PyTorch version these Torchscript weights were created with.", "type": "warning", "severity": 35}], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/per_sample_scale_range.ijm?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/sample_input_0.tif?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/sample_output_0.tif?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/test_input_0.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/test_output_0.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/environment.yaml?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/unet.py?version=v0": null, "weights.pt": "afc9a185f89be44eeeabe12454a589fb9572b5bae62c64fb4215c3015fa81f0d", "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "0a5f6e018828c723369904231ad48b45e0126b417aeaaba977d15a08b897d035"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (pytorch_state_dict)", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    755 \u2502   \u2502   test_input = get_test_input_sample(model)                                         \u2502\n\u2502    756 \u2502   \u2502   expected = get_test_output_sample(model)                                          \u2502\n\u2502    757 \u2502   \u2502                                                                                     \u2502\n\u2502 \u2771  758 \u2502   \u2502   with create_prediction_pipeline(                                                  \u2502\n\u2502    759 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format          \u2502\n\u2502    760 \u2502   \u2502   ) as prediction_pipeline:                                                         \u2502\n\u2502    761 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(test_input)     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   107 \u2502   \u2502   \u2502   if wf == \"pytorch_state_dict\":                                                 \u2502\n\u2502   108 \u2502   \u2502   \u2502   \u2502   assert weights.pytorch_state_dict is not None                              \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502 \u2771 110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502   112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502     5 from pathlib import Path                                                                   \u2502\n\u2502     6 from typing import Any, List, Literal, Optional, Sequence, Union                           \u2502\n\u2502     7                                                                                            \u2502\n\u2502 \u2771   8 import torch                                                                               \u2502\n\u2502     9 from loguru import logger                                                                  \u2502\n\u2502    10 from numpy.typing import NDArray                                                           \u2502\n\u2502    11 from torch import nn                                                                       \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   215 \u2502   # See Note [Global dependencies]                                                       \u2502\n\u2502   216 \u2502   if USE_GLOBAL_DEPS:                                                                    \u2502\n\u2502   217 \u2502   \u2502   _load_global_deps()                                                                \u2502\n\u2502 \u2771 218 \u2502   from torch._C import *  # noqa: F403                                                   \u2502\n\u2502   219                                                                                            \u2502\n\u2502   220 # Appease the type checker; ordinarily this binding is inserted by the                     \u2502\n\u2502   221 # torch._C module initialization code in C                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nImportError: /usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #808000; text-decoration-color: #808000}\n.r7 {color: #00ffff; text-decoration-color: #00ffff}\n.r8 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r9 {color: #808080; text-decoration-color: #808080}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r11 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r12 {color: #800080; text-decoration-color: #800080}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 755 </span><span class=\"r4\">\u2502   \u2502   </span>test_input = get_test_input_sample(model)                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 756 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_output_sample(model)                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 757 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 758 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 759 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 760 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 761 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(test_input)     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r6\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r7\">set</span>(deprecated_kwargs)<span class=\"r6\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r8\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r8\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r7\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r7\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">107 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> wf == <span class=\"r6\">&quot;pytorch_state_dict&quot;</span>:                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">108 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> weights.pytorch_state_dict <span class=\"r8\">is</span> <span class=\"r8\">not</span> <span class=\"r5\">None</span>                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>110 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">.pytorch_backend</span><span class=\"r9\"> </span><span class=\"r5\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">111 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">112 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">  5 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">pathlib</span><span class=\"r9\"> </span><span class=\"r5\">import</span> Path                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">  6 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> Any, List, Literal, Optional, Sequence, Union                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">  7 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>  8 <span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">torch</span>                                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">  9 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">loguru</span><span class=\"r9\"> </span><span class=\"r5\">import</span> logger                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 10 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">numpy.typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> NDArray                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 11 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">torch</span><span class=\"r9\"> </span><span class=\"r5\">import</span> nn                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">215 </span><span class=\"r4\">\u2502   </span><span class=\"r4\"># See Note [Global dependencies]</span>                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">216 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">if</span> USE_GLOBAL_DEPS:                                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">217 </span><span class=\"r4\">\u2502   \u2502   </span>_load_global_deps()                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>218 <span class=\"r4\">\u2502   </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">torch._C</span><span class=\"r9\"> </span><span class=\"r5\">import</span> *  <span class=\"r4\"># noqa: F403</span>                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">219 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">220 # Appease the type checker; ordinarily this binding is inserted by the</span>                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">221 # torch._C module initialization code in C</span>                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r11\">ImportError: </span><span class=\"r12\">/usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b/lib/python3.10/site-packages/torch/lib/</span><span class=\"r8\">libtorch_cpu.so</span>: undefined symbol: iJIT_NotifyEvent\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": "torch-em-deploy", "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "pip", "pytorch>=1.6,<2.0"]}, "saved_conda_compare": "Success. All the packages in the specification file are present in the environment with matching version and build string.\n"}, {"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/per_sample_scale_range.ijm?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/sample_input_0.tif?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/sample_output_0.tif?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/test_input_0.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/test_output_0.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/environment.yaml?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/unet.py?version=v0": null, "weights.pt": "afc9a185f89be44eeeabe12454a589fb9572b5bae62c64fb4215c3015fa81f0d", "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "0a5f6e018828c723369904231ad48b45e0126b417aeaaba977d15a08b897d035"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.4.10", "status": "passed", "loc": [], "errors": [], "warnings": [{"loc": ["weights", "pytorch_state_dict", "dependencies"], "msg": "Custom dependencies (conda:environment.yaml) specified. Avoid this whenever possible to allow execution in a wider range of software environments.", "type": "warning", "severity": 30}], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/cover.png?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/per_sample_scale_range.ijm?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/documentation.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/sample_input_0.tif?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/sample_output_0.tif?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/test_input_0.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/test_output_0.npy?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/environment.yaml?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/unet.py?version=v0": null, "weights.pt": "afc9a185f89be44eeeabe12454a589fb9572b5bae62c64fb4215c3015fa81f0d", "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files/weights-torchscript.pt?version=v0": null, "weights-torchscript.pt": "0a5f6e018828c723369904231ad48b45e0126b417aeaaba977d15a08b897d035"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/hiding-blowfish/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (pytorch_state_dict)", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "'unet_64af2e39972beb94019a1c97d42b29a8d8827d1b0f0845207c3b82c1a242f354'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   108 \u2502   module = sys.modules.get(module_name)                                                  \u2502\n\u2502   109 \u2502   if module is None:                                                                     \u2502\n\u2502   110 \u2502   \u2502   try:                                                                               \u2502\n\u2502 \u2771 111 \u2502   \u2502   \u2502   tmp_dir = TemporaryDirectory(ignore_cleanup_errors=True)                       \u2502\n\u2502   112 \u2502   \u2502   \u2502   module_path = Path(tmp_dir.name) / module_name                                 \u2502\n\u2502   113 \u2502   \u2502   \u2502   if reader.original_file_name.endswith(\".zip\") or is_zipfile(reader):           \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   module_path.mkdir()                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nTypeError: __init__() got an unexpected keyword argument 'ignore_cleanup_errors'\n\nDuring handling of the above exception, another exception occurred:\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   642 \u2502   \u2502   inputs = get_test_inputs(model)                                                    \u2502\n\u2502   643 \u2502   \u2502   expected = get_test_outputs(model)                                                 \u2502\n\u2502   644 \u2502   \u2502                                                                                      \u2502\n\u2502 \u2771 645 \u2502   \u2502   with create_prediction_pipeline(                                                   \u2502\n\u2502   646 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format           \u2502\n\u2502   647 \u2502   \u2502   ) as prediction_pipeline:                                                          \u2502\n\u2502   648 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(inputs)          \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502   110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502 \u2771 112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502   114 \u2502   \u2502   \u2502   \u2502   \u2502   )                                                                      \u2502\n\u2502   115 \u2502   \u2502   \u2502   \u2502   except Exception as e:                                                     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    35 \u2502   \u2502   \u2502   raise ValueError(\"No `pytorch_state_dict` weights found\")                      \u2502\n\u2502    36 \u2502   \u2502                                                                                      \u2502\n\u2502    37 \u2502   \u2502   devices = get_devices(devices)                                                     \u2502\n\u2502 \u2771  38 \u2502   \u2502   self._model = load_torch_model(weights, load_state=True, devices=devices)          \u2502\n\u2502    39 \u2502   \u2502   if mode == \"eval\":                                                                 \u2502\n\u2502    40 \u2502   \u2502   \u2502   self._model = self._model.eval()                                               \u2502\n\u2502    41 \u2502   \u2502   elif mode == \"train\":                                                              \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   100 \u2502   load_state: bool = True,                                                               \u2502\n\u2502   101 \u2502   devices: Optional[Sequence[Union[str, torch.device]]] = None,                          \u2502\n\u2502   102 ) -> nn.Module:                                                                            \u2502\n\u2502 \u2771 103 \u2502   custom_callable = import_callable(                                                     \u2502\n\u2502   104 \u2502   \u2502   weight_spec.architecture,                                                          \u2502\n\u2502   105 \u2502   \u2502   sha256=(                                                                           \u2502\n\u2502   106 \u2502   \u2502   \u2502   weight_spec.architecture_sha256                                                \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    72 \u2502   \u2502   module = importlib.import_module(node.import_from)                                 \u2502\n\u2502    73 \u2502   \u2502   c = getattr(module, str(node.callable))                                            \u2502\n\u2502    74 \u2502   elif isinstance(node, CallableFromFile):                                               \u2502\n\u2502 \u2771  75 \u2502   \u2502   c = _import_from_file_impl(node.source_file, str(node.callable_name), **kwargs)    \u2502\n\u2502    76 \u2502   elif isinstance(node, ArchitectureFromFileDescr):                                      \u2502\n\u2502    77 \u2502   \u2502   c = _import_from_file_impl(node.source, str(node.callable), sha256=node.sha256)    \u2502\n\u2502    78 \u2502   else:                                                                                  \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   132 \u2502   \u2502   \u2502   importlib_spec.loader.exec_module(module)                                      \u2502\n\u2502   133 \u2502   \u2502                                                                                      \u2502\n\u2502   134 \u2502   \u2502   except Exception as e:                                                             \u2502\n\u2502 \u2771 135 \u2502   \u2502   \u2502   del sys.modules[module_name]                                                   \u2502\n\u2502   136 \u2502   \u2502   \u2502   raise ImportError(f\"Failed to import {source}\") from e                         \u2502\n\u2502   137 \u2502                                                                                          \u2502\n\u2502   138 \u2502   try:                                                                                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nKeyError: 'unet_64af2e39972beb94019a1c97d42b29a8d8827d1b0f0845207c3b82c1a242f354'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r7 {color: #808000; text-decoration-color: #808000}\n.r8 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r9 {color: #800080; text-decoration-color: #800080; font-weight: bold}\n.r10 {font-weight: bold}\n.r11 {color: #008000; text-decoration-color: #008000}\n.r12 {font-style: italic}\n.r13 {color: #00ffff; text-decoration-color: #00ffff}\n.r14 {color: #808080; text-decoration-color: #808080}\n.r15 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">108 </span><span class=\"r4\">\u2502   </span>module = sys.modules.get(module_name)                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">if</span> module <span class=\"r6\">is</span> <span class=\"r5\">None</span>:                                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>111 <span class=\"r4\">\u2502   \u2502   \u2502   </span>tmp_dir = TemporaryDirectory(ignore_cleanup_errors=<span class=\"r5\">True</span>)                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">112 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>module_path = Path(tmp_dir.name) / module_name                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> reader.original_file_name.endswith(<span class=\"r7\">&quot;.zip&quot;</span>) <span class=\"r6\">or</span> is_zipfile(reader):           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span>module_path.mkdir()                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">TypeError: </span><span class=\"r9\">__init__</span><span class=\"r10\">()</span> got an unexpected keyword argument <span class=\"r11\">&#x27;ignore_cleanup_errors&#x27;</span>\n\n<span class=\"r12\">During handling of the above exception, another exception occurred:</span>\n\n<span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">642 </span><span class=\"r4\">\u2502   \u2502   </span>inputs = get_test_inputs(model)                                                    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">643 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_outputs(model)                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">644 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>645 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">646 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">647 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">648 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(inputs)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r7\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r13\">set</span>(deprecated_kwargs)<span class=\"r7\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r6\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r6\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r13\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r13\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">110 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">.pytorch_backend</span><span class=\"r14\"> </span><span class=\"r5\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">111 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>112 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">114 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>)                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">115 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 35 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ValueError</span>(<span class=\"r7\">&quot;No `pytorch_state_dict` weights found&quot;</span>)                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 36 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 37 </span><span class=\"r4\">\u2502   \u2502   </span>devices = get_devices(devices)                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 38 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r13\">self</span>._model = load_torch_model(weights, load_state=<span class=\"r5\">True</span>, devices=devices)          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 39 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> mode == <span class=\"r7\">&quot;eval&quot;</span>:                                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 40 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r13\">self</span>._model = <span class=\"r13\">self</span>._model.eval()                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 41 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">elif</span> mode == <span class=\"r7\">&quot;train&quot;</span>:                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">100 </span><span class=\"r4\">\u2502   </span>load_state: <span class=\"r13\">bool</span> = <span class=\"r5\">True</span>,                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">101 </span><span class=\"r4\">\u2502   </span>devices: Optional[Sequence[Union[<span class=\"r13\">str</span>, torch.device]]] = <span class=\"r5\">None</span>,                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">102 </span>) -&gt; nn.Module:                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>103 <span class=\"r4\">\u2502   </span>custom_callable = import_callable(                                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">104 </span><span class=\"r4\">\u2502   \u2502   </span>weight_spec.architecture,                                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">105 </span><span class=\"r4\">\u2502   \u2502   </span>sha256=(                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">106 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>weight_spec.architecture_sha256                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 72 </span><span class=\"r4\">\u2502   \u2502   </span>module = importlib.import_module(node.import_from)                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 73 </span><span class=\"r4\">\u2502   \u2502   </span>c = <span class=\"r13\">getattr</span>(module, <span class=\"r13\">str</span>(node.callable))                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 74 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, CallableFromFile):                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 75 <span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source_file, <span class=\"r13\">str</span>(node.callable_name), **kwargs)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 76 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">elif</span> <span class=\"r13\">isinstance</span>(node, ArchitectureFromFileDescr):                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 77 </span><span class=\"r4\">\u2502   \u2502   </span>c = _import_from_file_impl(node.source, <span class=\"r13\">str</span>(node.callable), sha256=node.sha256)    <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 78 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">else</span>:                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/6957a898500e9707d2a72c887d10fb220eba92e15c14aaeeddbbc322dd3dedb8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>importlib_spec.loader.exec_module(module)                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">134 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">except</span> <span class=\"r13\">Exception</span> <span class=\"r5\">as</span> e:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>135 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">del</span> sys.modules[module_name]                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">136 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> <span class=\"r13\">ImportError</span>(<span class=\"r7\">f&quot;Failed to import {</span>source<span class=\"r7\">}&quot;</span>) <span class=\"r5\">from</span><span class=\"r14\"> </span><span class=\"r15\">e</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">137 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">138 </span><span class=\"r4\">\u2502   </span><span class=\"r5\">try</span>:                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r8\">KeyError: </span><span class=\"r11\">&#x27;unet_64af2e39972beb94019a1c97d42b29a8d8827d1b0f0845207c3b82c1a242f354&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": "torch-em-deploy", "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "pip", "pytorch>=1.6,<2.0"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}, {"name": "Reproduce test outputs from test inputs (torchscript)", "status": "passed", "loc": ["weights", "torchscript"], "errors": [], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==1.10.1", "setuptools <70.0.0", "torchaudio==0.10.1", "torchvision==0.11.2"]}, "saved_conda_compare": "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n\nconda is a tool for managing and deploying applications, environments and packages.\n\noptions:\n  -h, --help            Show this help message and exit.\n  -v, --verbose         Can be used multiple times. Once for detailed output,\n                        twice for INFO logging, thrice for DEBUG logging, four\n                        times for TRACE logging.\n  --no-plugins          Disable all plugins that are not built into conda.\n  -V, --version         Show the conda version number and exit.\n\ncommands:\n  The following built-in and plugins subcommands are available.\n\n  COMMAND\n    activate            Activate a conda environment.\n    clean               Remove unused packages and caches.\n    commands            List all available conda subcommands (including those\n                        from plugins). Generally only used by tab-completion.\n    compare             Compare packages between conda environments.\n    config              Modify configuration values in .condarc.\n    content-trust       Signing and verification tools for Conda\n    create              Create a new conda environment from a list of\n                        specified packages.\n    deactivate          Deactivate the current active conda environment.\n    doctor              Display a health report for your environment.\n    env                 Create and manage conda environments.\n    export              Export a given environment\n    info                Display information about current conda install.\n    init                Initialize conda for shell interaction.\n    install             Install a list of packages into a specified conda\n                        environment.\n    list                List installed packages in a conda environment.\n    notices             Retrieve latest channel notifications.\n    package             Create low-level conda packages. (EXPERIMENTAL)\n    remove (uninstall)  Remove a list of packages from a specified conda\n                        environment.\n    rename              Rename an existing environment.\n    repoquery           Advanced search for repodata.\n    run                 Run an executable in a conda environment.\n    search              Search for packages and display associated information\n                        using the MatchSpec format.\n    token               See `conda token --help`.\n    tos                 A subcommand for viewing, accepting, rejecting, and\n                        otherwise interacting with a channel's Terms of\n                        Service (ToS). This plugin periodically checks for\n                        updated Terms of Service for the active/selected\n                        channels. Channels with a Terms of Service will need\n                        to be accepted or rejected prior to use. Conda will\n                        only allow package installation from channels without\n                        a Terms of Service or with an accepted Terms of\n                        Service. Attempting to use a channel with a rejected\n                        Terms of Service will result in an error.\n    update (upgrade)    Update conda packages to the latest compatible\n                        version.\n"}], "env": [["bioimageio.spec", "0.5.5.5", "", ""], ["bioimageio.core", "0.9.3", "", ""]], "saved_conda_list": "# packages in environment at /usr/share/miniconda/envs/96189b829af48e5ff48931e2aad6d1ff4eafea247b62c8a70dc5ba4e3f69fc2b:\n#\n# Name                     Version          Build                    Channel\n_openmp_mutex              4.5              4_kmp_llvm               conda-forge\nannotated-types            0.7.0            pyhd8ed1ab_1             conda-forge\nanyio                      4.11.0           pyhcf101f3_0             conda-forge\naom                        3.9.1            hac33072_0               conda-forge\nbioimageio.core            0.9.3            pyhd8ed1ab_0             conda-forge\nbioimageio.spec            0.5.5.5          pyhd8ed1ab_0             conda-forge\nblas                       2.137            mkl                      conda-forge\nblas-devel                 3.9.0            37_hcf00494_mkl          conda-forge\nblosc                      1.21.6           he440d0b_1               conda-forge\nbrunsli                    0.1              he3183e4_1               conda-forge\nbzip2                      1.0.8            hda65f42_8               conda-forge\nc-ares                     1.34.5           hb9d3cd8_0               conda-forge\nc-blosc2                   2.19.1           h4cfbee9_0               conda-forge\nca-certificates            2025.10.5        hbd8a1cb_0               conda-forge\ncached-property            1.5.2            hd8ed1ab_1               conda-forge\ncached_property            1.5.2            pyha770c72_1             conda-forge\ncertifi                    2025.10.5        pyhd8ed1ab_0             conda-forge\ncharls                     2.4.2            h59595ed_0               conda-forge\ncolorama                   0.4.6            pyhd8ed1ab_1             conda-forge\ndav1d                      1.2.1            hd590300_0               conda-forge\ndistro                     1.9.0            pyhd8ed1ab_1             conda-forge\ndnspython                  2.8.0            pyhcf101f3_0             conda-forge\nemail-validator            2.3.0            pyhd8ed1ab_0             conda-forge\nemail_validator            2.3.0            hd8ed1ab_0               conda-forge\nexceptiongroup             1.3.0            pyhd8ed1ab_0             conda-forge\nfilelock                   3.20.0           pyhd8ed1ab_0             conda-forge\ngenericache                0.5.2            pyhd8ed1ab_0             conda-forge\ngiflib                     5.2.2            hd590300_0               conda-forge\nh11                        0.16.0           pyhd8ed1ab_0             conda-forge\nh2                         4.3.0            pyhcf101f3_0             conda-forge\nh5py                       3.14.0           nompi_py310h4aa865e_101  conda-forge\nhdf5                       1.14.6           nompi_h6e4c0c1_103       conda-forge\nhpack                      4.1.0            pyhd8ed1ab_0             conda-forge\nhttpcore                   1.0.9            pyh29332c3_0             conda-forge\nhttpx                      0.28.1           pyhd8ed1ab_0             conda-forge\nhyperframe                 6.1.0            pyhd8ed1ab_0             conda-forge\nicu                        75.1             he02047a_0               conda-forge\nidna                       3.11             pyhd8ed1ab_0             conda-forge\nimagecodecs                2025.3.30        py310h4eb8eaf_2          conda-forge\nimageio                    2.37.0           pyhfb79c49_0             conda-forge\nimportlib-metadata         8.7.0            pyhe01879c_1             conda-forge\njxrlib                     1.1              hd590300_3               conda-forge\nkeyutils                   1.6.3            hb9d3cd8_0               conda-forge\nkrb5                       1.21.3           h659f571_0               conda-forge\nlcms2                      2.17             h717163a_0               conda-forge\nld_impl_linux-64           2.44             ha97dd6f_2               conda-forge\nlerc                       4.0.0            h0aef613_1               conda-forge\nlibaec                     1.1.4            h3f801dc_0               conda-forge\nlibavif16                  1.3.0            h6395336_2               conda-forge\nlibblas                    3.9.0            37_h5875eb1_mkl          conda-forge\nlibbrotlicommon            1.1.0            hb03c661_4               conda-forge\nlibbrotlidec               1.1.0            hb03c661_4               conda-forge\nlibbrotlienc               1.1.0            hb03c661_4               conda-forge\nlibcblas                   3.9.0            37_hfef963f_mkl          conda-forge\nlibcurl                    8.14.1           h332b0f4_0               conda-forge\nlibdeflate                 1.24             h86f0d12_0               conda-forge\nlibedit                    3.1.20250104     pl5321h7949ede_0         conda-forge\nlibev                      4.33             hd590300_2               conda-forge\nlibexpat                   2.7.1            hecca717_0               conda-forge\nlibffi                     3.5.2            h9ec8514_0               conda-forge\nlibfreetype                2.14.1           ha770c72_0               conda-forge\nlibfreetype6               2.14.1           h73754d4_0               conda-forge\nlibgcc                     15.2.0           h767d61c_7               conda-forge\nlibgcc-ng                  15.2.0           h69a702a_7               conda-forge\nlibgfortran                15.2.0           h69a702a_7               conda-forge\nlibgfortran5               15.2.0           hcd61629_7               conda-forge\nlibhwloc                   2.12.1           default_h7f8ec31_1002    conda-forge\nlibhwy                     1.3.0            h4c17acf_1               conda-forge\nlibiconv                   1.18             h3b78370_2               conda-forge\nlibjpeg-turbo              3.1.0            hb9d3cd8_0               conda-forge\nlibjxl                     0.11.1           h6cb5226_4               conda-forge\nliblapack                  3.9.0            37_h5e43f62_mkl          conda-forge\nliblapacke                 3.9.0            37_hdba1596_mkl          conda-forge\nliblzma                    5.8.1            hb9d3cd8_2               conda-forge\nlibnghttp2                 1.67.0           had1ee68_0               conda-forge\nlibnsl                     2.0.1            hb9d3cd8_1               conda-forge\nlibpng                     1.6.50           h421ea60_1               conda-forge\nlibsqlite                  3.50.4           h0c1763c_0               conda-forge\nlibssh2                    1.11.1           hcf80075_0               conda-forge\nlibstdcxx                  15.2.0           h8f9b012_7               conda-forge\nlibstdcxx-ng               15.2.0           h4852527_7               conda-forge\nlibtiff                    4.7.1            h8261f1e_0               conda-forge\nlibuuid                    2.41.2           he9a06e4_0               conda-forge\nlibwebp-base               1.6.0            hd42ef1d_0               conda-forge\nlibxcb                     1.17.0           h8a09558_0               conda-forge\nlibxcrypt                  4.4.36           hd590300_1               conda-forge\nlibxml2                    2.15.0           h26afc86_1               conda-forge\nlibxml2-16                 2.15.0           ha9997c6_1               conda-forge\nlibzlib                    1.3.1            hb9d3cd8_2               conda-forge\nlibzopfli                  1.0.3            h9c3ff4c_0               conda-forge\nllvm-openmp                21.1.3           h4922eb0_0               conda-forge\nloguru                     0.7.3            pyh707e725_0             conda-forge\nlz4-c                      1.10.0           h5888daf_1               conda-forge\nmarkdown                   3.9              pyhd8ed1ab_0             conda-forge\nmarkdown-it-py             4.0.0            pyhd8ed1ab_0             conda-forge\nmdurl                      0.1.2            pyhd8ed1ab_1             conda-forge\nmkl                        2024.2.2         ha770c72_17              conda-forge\nmkl-devel                  2024.2.2         ha770c72_17              conda-forge\nmkl-include                2024.2.2         ha770c72_17              conda-forge\nncurses                    6.5              h2d0b736_3               conda-forge\nnumpy                      2.2.6            py310hefbff90_0          conda-forge\nopenjpeg                   2.5.4            h55fea9a_0               conda-forge\nopenssl                    3.5.4            h26f9b46_0               conda-forge\npackaging                  25.0             pyh29332c3_1             conda-forge\npandas                     2.3.3            py310h0158d43_1          conda-forge\npillow                     11.3.0           py310h6557065_3          conda-forge\npip                        25.2             pyh8b19718_0             conda-forge\nplatformdirs               4.5.0            pyhcf101f3_0             conda-forge\npthread-stubs              0.4              hb9d3cd8_1002            conda-forge\npydantic                   2.11.10          pyh3cfb1c2_0             conda-forge\npydantic-core              2.33.2           py310hbcd0ec0_0          conda-forge\npydantic-settings          2.11.0           pyh3cfb1c2_0             conda-forge\npygments                   2.19.2           pyhd8ed1ab_0             conda-forge\npython                     3.10.19          hd994cfb_1_cpython       conda-forge\npython-dateutil            2.9.0.post0      pyhe01879c_2             conda-forge\npython-dotenv              1.1.1            pyhe01879c_0             conda-forge\npython-tzdata              2025.2           pyhd8ed1ab_0             conda-forge\npython_abi                 3.10             8_cp310                  conda-forge\npytorch                    1.13.1           py3.10_cpu_0             pytorch\npytorch-mutex              1.0              cpu                      pytorch\npytz                       2025.2           pyhd8ed1ab_0             conda-forge\nrav1e                      0.7.1            h8fae777_3               conda-forge\nreadline                   8.2              h8c095d6_2               conda-forge\nrich                       14.2.0           pyhcf101f3_0             conda-forge\nruyaml                     0.91.0           pyhd8ed1ab_1             conda-forge\nscipy                      1.15.2           py310h1d65ade_0          conda-forge\nsetuptools                 80.9.0           pyhff2d567_0             conda-forge\nsix                        1.17.0           pyhe01879c_1             conda-forge\nsnappy                     1.2.2            h03e3b7b_0               conda-forge\nsniffio                    1.3.1            pyhd8ed1ab_1             conda-forge\nsvt-av1                    3.1.2            hecca717_0               conda-forge\ntbb                        2021.13.0        hb60516a_3               conda-forge\ntifffile                   2025.5.10        pyhd8ed1ab_0             conda-forge\ntk                         8.6.13           noxft_hd72426e_102       conda-forge\ntqdm                       4.67.1           pyhd8ed1ab_1             conda-forge\ntyping-extensions          4.15.0           h396c80c_0               conda-forge\ntyping-inspection          0.4.2            pyhd8ed1ab_0             conda-forge\ntyping_extensions          4.15.0           pyhcf101f3_0             conda-forge\ntzdata                     2025b            h78e105d_0               conda-forge\nwheel                      0.45.1           pyhd8ed1ab_1             conda-forge\nxarray                     2025.1.2         pyhd8ed1ab_0             conda-forge\nxorg-libxau                1.0.12           hb9d3cd8_0               conda-forge\nxorg-libxdmcp              1.1.5            hb9d3cd8_0               conda-forge\nzfp                        1.0.1            h909a3a2_3               conda-forge\nzipp                       3.23.0           pyhd8ed1ab_0             conda-forge\nzlib-ng                    2.2.5            hde8ca8f_0               conda-forge\nzstd                       1.5.7            hb8e6e7a_2               conda-forge\n"}, "badge": null, "links": []}