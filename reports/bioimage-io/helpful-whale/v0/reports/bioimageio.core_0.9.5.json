{
    "badge": null,
    "details": {
        "details": [
            {
                "context": {
                    "file_name": "rdf.yaml",
                    "known_files": {
                        "https://hypha.aicell.io/bioimage-io/artifacts/helpful-whale/files/doc.md?version=v0": null,
                        "https://hypha.aicell.io/bioimage-io/artifacts/helpful-whale/files/input_sample.npy?version=v0": null,
                        "https://hypha.aicell.io/bioimage-io/artifacts/helpful-whale/files/model.py?version=v0": null,
                        "https://hypha.aicell.io/bioimage-io/artifacts/helpful-whale/files/model_weights.pth?version=v0": null,
                        "https://hypha.aicell.io/bioimage-io/artifacts/helpful-whale/files/output_sample.npy?version=v0": null,
                        "input_sample.npy": "c6fd7bfa334cefe2612cbe5a1f0205a92bb3adc3fc748ae85ab8c2f1ca24ac38",
                        "model.py": "47bd0e745eb83d5ed5543fc4db677f10d24a7e5aecd5dd1db62a90ce0c4e9494",
                        "model_weights.pth": "67ce426095120fbc53d0f0de1b9099c0600ed6781758692e1ce61af122a80291",
                        "output_sample.npy": "06a4565f92f291fe116f3a6374dabe221ba5c5b201fce1e1613bd367d1dbddb9"
                    },
                    "original_source_name": null,
                    "perform_io_checks": true,
                    "root": "https://hypha.aicell.io/bioimage-io/artifacts/helpful-whale/files?version=v0",
                    "update_hashes": false
                },
                "errors": [],
                "loc": [],
                "name": "Successfully created `ModelDescr` instance.",
                "recommended_env": null,
                "saved_conda_compare": null,
                "status": "passed",
                "warnings": []
            },
            {
                "context": null,
                "errors": [],
                "loc": [],
                "name": "bioimageio.spec format validation model 0.5.6",
                "recommended_env": null,
                "saved_conda_compare": null,
                "status": "passed",
                "warnings": [
                    {
                        "loc": [
                            "documentation"
                        ],
                        "msg": "No '# Validation' (sub)section found in doc.md.",
                        "severity": 30,
                        "type": "warning"
                    },
                    {
                        "loc": [
                            "inputs",
                            0,
                            "sample_tensor"
                        ],
                        "msg": "Needs to be filled for FAIR compliance",
                        "severity": 35,
                        "type": "warning"
                    },
                    {
                        "loc": [
                            "outputs",
                            0,
                            "sample_tensor"
                        ],
                        "msg": "Needs to be filled for FAIR compliance",
                        "severity": 35,
                        "type": "warning"
                    }
                ]
            },
            {
                "context": null,
                "errors": [
                    {
                        "loc": [
                            "weights",
                            "pytorch_state_dict"
                        ],
                        "msg": "Input image(s) must be 4-dimensional (batch, channel, height, width), got shape torch.Size([3, 512, 512])",
                        "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {font-weight: bold}\n.r6 {color: #0000ff; text-decoration-color: #0000ff}\n.r7 {color: #00ffff; text-decoration-color: #00ffff}\n.r8 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r9 {color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline}\n.r10 {font-weight: bold; text-decoration: underline}\n.r11 {color: #bfbf7f; text-decoration-color: #bfbf7f}\n.r12 {color: #808000; text-decoration-color: #808000}\n.r13 {color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline}\n.r14 {color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline}\n.r15 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r16 {color: #800080; text-decoration-color: #800080; font-weight: bold}\n.r17 {color: #008080; text-decoration-color: #008080; font-weight: bold}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">╭─────────────────────────────── </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> ────────────────────────────────╮</span>\n<span class=\"r1\">│</span> <span class=\"r4\">/home/runner/.local/lib/python3.12/site-packages/bioimageio/core/</span><span class=\"r5\">_resource_tests.py</span>:787 in _test <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 784 </span><span class=\"r4\">│   │   </span><span class=\"r6\">with</span> create_prediction_pipeline(                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 785 </span><span class=\"r4\">│   │   │   </span>bioimageio_model=model, devices=devices, weight_format=weight_format          <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 786 </span><span class=\"r4\">│   │   </span>) <span class=\"r6\">as</span> prediction_pipeline:                                                         <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r1\">❱ </span> 787 <span class=\"r4\">│   │   │   </span>results = prediction_pipeline.predict_sample_without_blocking(test_input)     <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 788 </span><span class=\"r4\">│   │   </span>                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 789 </span><span class=\"r4\">│   │   </span><span class=\"r6\">if</span> <span class=\"r7\">len</span>(results.members) != <span class=\"r7\">len</span>(expected.members):                                 <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 790 </span><span class=\"r4\">│   │   │   </span>add_error_entry(                                                              <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r4\">/home/runner/.local/lib/python3.12/site-packages/bioimageio/core/</span><span class=\"r5\">_prediction_pipeline.py</span>:160 in  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">157 </span><span class=\"r4\">│   │   </span><span class=\"r6\">if</span> <span class=\"r8\">not</span> skip_preprocessing:                                                         <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">158 </span><span class=\"r4\">│   │   │   </span><span class=\"r7\">self</span>.apply_preprocessing(sample)                                               <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">159 </span><span class=\"r4\">│   │   </span>                                                                                   <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r1\">❱ </span>160 <span class=\"r4\">│   │   </span>output = <span class=\"r9\">self</span><span class=\"r10\">._adapter.forward(sample)</span>                                             <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">161 </span><span class=\"r4\">│   │   </span><span class=\"r6\">if</span> <span class=\"r8\">not</span> skip_postprocessing:                                                        <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">162 </span><span class=\"r4\">│   │   │   </span><span class=\"r7\">self</span>.apply_postprocessing(output)                                              <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">163 </span>                                                                                           <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r4\">/home/runner/.local/lib/python3.12/site-packages/bioimageio/core/backends/</span><span class=\"r5\">_model_adapter.py</span>:202  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">199 </span><span class=\"r4\">│   │   │   </span>)                                                                              <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">200 </span><span class=\"r4\">│   │   │   </span><span class=\"r6\">for</span> in_id, in_order <span class=\"r8\">in</span> <span class=\"r7\">zip</span>(<span class=\"r7\">self</span>._input_ids, <span class=\"r7\">self</span>._input_axes)                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">201 </span><span class=\"r4\">│   │   </span>]                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r1\">❱ </span>202 <span class=\"r4\">│   │   </span>output_arrays = <span class=\"r9\">self</span><span class=\"r10\">._forward_impl(input_arrays)</span>                                   <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">203 </span><span class=\"r4\">│   │   </span><span class=\"r6\">assert</span> <span class=\"r7\">len</span>(output_arrays) &lt;= <span class=\"r7\">len</span>(<span class=\"r7\">self</span>._output_ids)                                 <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">204 </span><span class=\"r4\">│   │   </span>output_tensors = [                                                                 <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">205 </span><span class=\"r4\">│   │   │   </span><span class=\"r6\">None</span> <span class=\"r6\">if</span> a <span class=\"r8\">is</span> <span class=\"r6\">None</span> <span class=\"r6\">else</span> Tensor(a, dims=d)                                       <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r4\">/home/runner/.local/lib/python3.12/site-packages/bioimageio/core/backends/</span><span class=\"r5\">pytorch_backend.py</span>:65  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 62 </span><span class=\"r4\">│   │   │   </span>assert_never(<span class=\"r7\">self</span>._mode)                                                       <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 63 </span><span class=\"r4\">│   │   </span>                                                                                   <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 64 </span><span class=\"r4\">│   │   </span><span class=\"r6\">with</span> ctxt():                                                                       <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r1\">❱ </span> 65 <span class=\"r4\">│   │   │   </span>model_out = <span class=\"r9\">self</span><span class=\"r10\">._model(*tensors)</span>                                              <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 66 </span><span class=\"r4\">│   │   </span>                                                                                   <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 67 </span><span class=\"r4\">│   │   </span><span class=\"r6\">if</span> is_tuple(model_out) <span class=\"r8\">or</span> is_list(model_out):                                      <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\"> 68 </span><span class=\"r4\">│   │   │   </span>model_out_seq = model_out                                                      <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r4\">/home/runner/.local/lib/python3.12/site-packages/torch/nn/modules/</span><span class=\"r5\">module.py</span>:1775 in _wrapped_cal <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1772 </span><span class=\"r4\">│   │   </span><span class=\"r6\">if</span> <span class=\"r7\">self</span>._compiled_call_impl <span class=\"r8\">is</span> <span class=\"r8\">not</span> <span class=\"r6\">None</span>:                                          <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1773 </span><span class=\"r4\">│   │   │   </span><span class=\"r6\">return</span> <span class=\"r7\">self</span>._compiled_call_impl(*args, **kwargs)  <span class=\"r4\"># type: ignore[misc]</span>        <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1774 </span><span class=\"r4\">│   │   </span><span class=\"r6\">else</span>:                                                                             <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r1\">❱ </span>1775 <span class=\"r4\">│   │   │   </span><span class=\"r6\">return</span> <span class=\"r9\">self</span><span class=\"r10\">._call_impl(*args, **kwargs)</span>                                       <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1776 </span><span class=\"r4\">│   </span>                                                                                      <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1777 </span><span class=\"r4\">│   </span><span class=\"r4\"># torchrec tests the code consistency with the following code</span>                         <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1778 </span><span class=\"r4\">│   </span><span class=\"r4\"># fmt: off</span>                                                                            <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r4\">/home/runner/.local/lib/python3.12/site-packages/torch/nn/modules/</span><span class=\"r5\">module.py</span>:1786 in _call_impl   <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1783 </span><span class=\"r4\">│   │   </span><span class=\"r6\">if</span> <span class=\"r8\">not</span> (<span class=\"r7\">self</span>._backward_hooks <span class=\"r8\">or</span> <span class=\"r7\">self</span>._backward_pre_hooks <span class=\"r8\">or</span> <span class=\"r7\">self</span>._forward_hooks <span class=\"r8\">o</span> <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1784 </span><span class=\"r4\">│   │   │   │   </span><span class=\"r8\">or</span> _global_backward_pre_hooks <span class=\"r8\">or</span> _global_backward_hooks                   <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1785 </span><span class=\"r4\">│   │   │   │   </span><span class=\"r8\">or</span> _global_forward_hooks <span class=\"r8\">or</span> _global_forward_pre_hooks):                   <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r1\">❱ </span>1786 <span class=\"r4\">│   │   │   </span><span class=\"r6\">return</span> <span class=\"r10\">forward_call(*args, **kwargs)</span>                                          <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1787 </span><span class=\"r4\">│   │   </span>                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1788 </span><span class=\"r4\">│   │   </span>result = <span class=\"r6\">None</span>                                                                     <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">1789 </span><span class=\"r4\">│   │   </span>called_always_called_hooks = <span class=\"r7\">set</span>()                                                <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r4\">/tmp/tmp_28ef4ju/</span><span class=\"r5\">model_47bd0e745eb83d5ed5543fc4db677f10d24a7e5aecd5dd1db62a90ce0c4e9494.py</span>:139 i <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>                                                                                                  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">136 </span><span class=\"r11\">│   │   │   </span><span class=\"r12\">ValueError: If input dimensions are invalid</span>                                    <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">137 </span><span class=\"r11\">│   │   </span><span class=\"r12\">&quot;&quot;&quot;</span>                                                                                <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">138 </span><span class=\"r4\">│   │   </span><span class=\"r6\">if</span> <span class=\"r7\">len</span>(x.shape) != <span class=\"r6\">4</span>:                                                              <span class=\"r1\">│</span>\n<span class=\"r1\">│</span> <span class=\"r1\">❱ </span>139 <span class=\"r4\">│   │   │   </span><span class=\"r13\">raise</span><span class=\"r10\"> </span><span class=\"r9\">ValueError</span><span class=\"r10\">(</span>                                                              <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">140 </span><span class=\"r4\">│   │   │   │   </span><span class=\"r14\">f&quot;Input image(s) must be 4-dimensional (batch, channel, height, width), &quot;</span>  <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">141 </span><span class=\"r4\">│   │   │   │   </span><span class=\"r14\">f&quot;got shape {</span><span class=\"r10\">x.shape</span><span class=\"r14\">}&quot;</span>                                                     <span class=\"r1\">│</span>\n<span class=\"r1\">│</span>   <span class=\"r4\">142 </span><span class=\"r4\">│   │   │   </span><span class=\"r10\">)</span>                                                                              <span class=\"r1\">│</span>\n<span class=\"r1\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span class=\"r15\">ValueError: </span>Input <span class=\"r16\">image</span><span class=\"r5\">(</span>s<span class=\"r5\">)</span> must be <span class=\"r17\">4</span>-dimensional <span class=\"r5\">(</span>batch, channel, height, width<span class=\"r5\">)</span>, got shape <span class=\"r16\">torch.Size</span><span class=\"r5\">([</span><span class=\"r17\">3</span>, <span class=\"r17\">512</span>, <span class=\"r17\">512</span><span class=\"r5\">])</span>\n</code></pre>\n</body>\n</html>\n",
                        "traceback_md": "╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮\n│ /home/runner/.local/lib/python3.12/site-packages/bioimageio/core/_resource_tests.py:787 in _test │\n│                                                                                                  │\n│    784 │   │   with create_prediction_pipeline(                                                  │\n│    785 │   │   │   bioimageio_model=model, devices=devices, weight_format=weight_format          │\n│    786 │   │   ) as prediction_pipeline:                                                         │\n│ ❱  787 │   │   │   results = prediction_pipeline.predict_sample_without_blocking(test_input)     │\n│    788 │   │                                                                                     │\n│    789 │   │   if len(results.members) != len(expected.members):                                 │\n│    790 │   │   │   add_error_entry(                                                              │\n│                                                                                                  │\n│ /home/runner/.local/lib/python3.12/site-packages/bioimageio/core/_prediction_pipeline.py:160 in  │\n│                                                                                                  │\n│   157 │   │   if not skip_preprocessing:                                                         │\n│   158 │   │   │   self.apply_preprocessing(sample)                                               │\n│   159 │   │                                                                                      │\n│ ❱ 160 │   │   output = self._adapter.forward(sample)                                             │\n│   161 │   │   if not skip_postprocessing:                                                        │\n│   162 │   │   │   self.apply_postprocessing(output)                                              │\n│   163                                                                                            │\n│                                                                                                  │\n│ /home/runner/.local/lib/python3.12/site-packages/bioimageio/core/backends/_model_adapter.py:202  │\n│                                                                                                  │\n│   199 │   │   │   )                                                                              │\n│   200 │   │   │   for in_id, in_order in zip(self._input_ids, self._input_axes)                  │\n│   201 │   │   ]                                                                                  │\n│ ❱ 202 │   │   output_arrays = self._forward_impl(input_arrays)                                   │\n│   203 │   │   assert len(output_arrays) <= len(self._output_ids)                                 │\n│   204 │   │   output_tensors = [                                                                 │\n│   205 │   │   │   None if a is None else Tensor(a, dims=d)                                       │\n│                                                                                                  │\n│ /home/runner/.local/lib/python3.12/site-packages/bioimageio/core/backends/pytorch_backend.py:65  │\n│                                                                                                  │\n│    62 │   │   │   assert_never(self._mode)                                                       │\n│    63 │   │                                                                                      │\n│    64 │   │   with ctxt():                                                                       │\n│ ❱  65 │   │   │   model_out = self._model(*tensors)                                              │\n│    66 │   │                                                                                      │\n│    67 │   │   if is_tuple(model_out) or is_list(model_out):                                      │\n│    68 │   │   │   model_out_seq = model_out                                                      │\n│                                                                                                  │\n│ /home/runner/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1775 in _wrapped_cal │\n│                                                                                                  │\n│   1772 │   │   if self._compiled_call_impl is not None:                                          │\n│   1773 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]        │\n│   1774 │   │   else:                                                                             │\n│ ❱ 1775 │   │   │   return self._call_impl(*args, **kwargs)                                       │\n│   1776 │                                                                                         │\n│   1777 │   # torchrec tests the code consistency with the following code                         │\n│   1778 │   # fmt: off                                                                            │\n│                                                                                                  │\n│ /home/runner/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1786 in _call_impl   │\n│                                                                                                  │\n│   1783 │   │   if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks o │\n│   1784 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hooks                   │\n│   1785 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks):                   │\n│ ❱ 1786 │   │   │   return forward_call(*args, **kwargs)                                          │\n│   1787 │   │                                                                                     │\n│   1788 │   │   result = None                                                                     │\n│   1789 │   │   called_always_called_hooks = set()                                                │\n│                                                                                                  │\n│ /tmp/tmp_28ef4ju/model_47bd0e745eb83d5ed5543fc4db677f10d24a7e5aecd5dd1db62a90ce0c4e9494.py:139 i │\n│                                                                                                  │\n│   136 │   │   │   ValueError: If input dimensions are invalid                                    │\n│   137 │   │   \"\"\"                                                                                │\n│   138 │   │   if len(x.shape) != 4:                                                              │\n│ ❱ 139 │   │   │   raise ValueError(                                                              │\n│   140 │   │   │   │   f\"Input image(s) must be 4-dimensional (batch, channel, height, width), \"  │\n│   141 │   │   │   │   f\"got shape {x.shape}\"                                                     │\n│   142 │   │   │   )                                                                              │\n╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\nValueError: Input image(s) must be 4-dimensional (batch, channel, height, width), got shape torch.Size([3, 512, 512])\n",
                        "type": "bioimageio.core",
                        "with_traceback": true
                    }
                ],
                "loc": [
                    "weights",
                    "pytorch_state_dict"
                ],
                "name": "Reproduce test outputs from test inputs (pytorch_state_dict)",
                "recommended_env": {
                    "channels": [
                        "pytorch",
                        "conda-forge",
                        "nodefaults"
                    ],
                    "dependencies": [
                        "conda-forge::bioimageio.core",
                        "numpy >=2,<3",
                        "pip",
                        "pytorch==2.3.0",
                        "torchaudio==2.3.0",
                        "torchvision==0.18.0"
                    ],
                    "name": null
                },
                "saved_conda_compare": "Success. All the packages in the specification file are present in the environment with matching version and build string.\n",
                "status": "failed",
                "warnings": []
            }
        ],
        "env": [
            [
                "bioimageio.spec",
                "0.5.6.0",
                "",
                ""
            ]
        ],
        "format_version": "0.5.6",
        "id": "helpful-whale",
        "metadata_completeness": 0.6190476190476191,
        "name": "bioimageio format validation",
        "saved_conda_list": "# packages in environment at /usr/share/miniconda/envs/core:\n#\n# Name                     Version          Build            Channel\n",
        "source_name": "https://hypha.aicell.io/bioimage-io/artifacts/helpful-whale/files/rdf.yaml?version=v0",
        "status": "valid-format",
        "traceback": null,
        "type": "model",
        "warnings": null
    },
    "error": "Input image(s) must be 4-dimensional (batch, channel, height, width), got shape torch.Size([3, 512, 512])",
    "links": [],
    "score": 0.5,
    "status": "failed"
}