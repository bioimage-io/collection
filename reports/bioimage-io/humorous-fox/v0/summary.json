{
    "rdf_content": {
        "name": "SEM_n2v",
        "id": "humorous-fox",
        "id_emoji": "ðŸ¦Š",
        "description": "This model is a UNet trained using the Noise2Void algorithm to denoise images.The training data consists of crops from an SEM dataset (T.-O. Buchholz et al., Methods Cell Biol, 2020). The notebook used to train this model is available on the CAREamics documentation website at the following link: https://careamics.github.io/0.1/applications/N2V2/SEM/.",
        "covers": [
            "cover.png"
        ],
        "authors": [
            {
                "affiliation": "Human Technopole",
                "name": "CAREamics authors"
            }
        ],
        "attachments": [
            {
                "source": "careamics.yaml",
                "sha256": "d5d602508ae597470fdc926ac6674848bbbc4ab88120fd5c3da4c138a4c681f1"
            }
        ],
        "cite": [
            {
                "text": "Krull, A., Buchholz, T.O. and Jug, F., 2019. \"Noise2Void - Learning denoising from single noisy images\". In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 2129-2137).",
                "doi": "10.1109/cvpr.2019.00223"
            }
        ],
        "license": "BSD-3-Clause",
        "links": [
            "https://github.com/CAREamics/careamics",
            "https://careamics.github.io/latest/"
        ],
        "tags": [
            "denoising",
            "restoration",
            "UNet",
            "2D",
            "CAREamics",
            "pytorch",
            "Noise2Void"
        ],
        "version": "0.1.0",
        "format_version": "0.5.4",
        "type": "model",
        "documentation": "README.md",
        "inputs": [
            {
                "id": "input",
                "axes": [
                    {
                        "type": "batch"
                    },
                    {
                        "type": "channel",
                        "channel_names": [
                            "channel"
                        ]
                    },
                    {
                        "size": 256,
                        "id": "y",
                        "type": "space"
                    },
                    {
                        "size": 256,
                        "id": "x",
                        "type": "space"
                    }
                ],
                "test_tensor": {
                    "source": "inputs.npy",
                    "sha256": "889f8bbdd258b300276e63bf676e07436830a2117400688fd255dbc2328e5bef"
                },
                "preprocessing": [
                    {
                        "id": "ensure_dtype",
                        "kwargs": {
                            "dtype": "float32"
                        }
                    },
                    {
                        "id": "fixed_zero_mean_unit_variance",
                        "kwargs": {
                            "mean": [
                                39216.046875
                            ],
                            "std": [
                                18678.18359375
                            ],
                            "axis": "channel"
                        }
                    },
                    {
                        "id": "ensure_dtype",
                        "kwargs": {
                            "dtype": "float32"
                        }
                    }
                ]
            }
        ],
        "outputs": [
            {
                "id": "prediction",
                "axes": [
                    {
                        "type": "batch"
                    },
                    {
                        "type": "channel",
                        "channel_names": [
                            "channel"
                        ]
                    },
                    {
                        "size": 256,
                        "id": "y",
                        "type": "space"
                    },
                    {
                        "size": 256,
                        "id": "x",
                        "type": "space"
                    }
                ],
                "test_tensor": {
                    "source": "outputs.npy",
                    "sha256": "f0b89719944dfb0a3aeb20ac9eebbe109bb2453929d5fe3d16a13c99e502813b"
                },
                "postprocessing": [
                    {
                        "id": "fixed_zero_mean_unit_variance",
                        "kwargs": {
                            "mean": [
                                -2.0995642684453917
                            ],
                            "std": [
                                0.000052538396543070526
                            ],
                            "axis": "channel"
                        }
                    },
                    {
                        "id": "ensure_dtype",
                        "kwargs": {
                            "dtype": "float32"
                        }
                    }
                ]
            }
        ],
        "weights": {
            "pytorch_state_dict": {
                "source": "weights.pth",
                "sha256": "8d6db553ab4558095fc956fcf8763ae57a87cdc13a608d9738eaab08fe0dea71",
                "architecture": {
                    "callable": "UNet",
                    "kwargs": {
                        "conv_dims": 2,
                        "num_classes": 1,
                        "in_channels": 1,
                        "depth": 2,
                        "num_channels_init": 32,
                        "final_activation": "None",
                        "n2v2": false,
                        "independent_channels": true,
                        "use_batch_norm": true
                    },
                    "import_from": "careamics.models.unet"
                },
                "pytorch_version": "2.7.1+cu126",
                "dependencies": {
                    "source": "environment.yml",
                    "sha256": "bb314d1b60ff8b12ff6c156525680cd10e7770e1a088e9d7ca29724ffcad6ee0"
                }
            }
        },
        "config": {
            "bioimageio": {
                "test_kwargs": {
                    "pytorch_state_dict": {
                        "absolute_tolerance": 0.01,
                        "relative_tolerance": 0.01
                    }
                }
            }
        }
    },
    "rdf_yaml_sha256": "a5c81ba94e649cc8eb53955500b5c655d50eee11945c51c2ed331e50d2e4386e",
    "status": "untested"
}