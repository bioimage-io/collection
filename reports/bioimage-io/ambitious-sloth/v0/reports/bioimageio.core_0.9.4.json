{"status": "failed", "score": 0.0, "error": "No module named 'torch'\n\nNo module named 'onnxruntime'\n\nNo module named 'onnxruntime'", "details": {"name": "bioimageio format validation", "source_name": "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/rdf.yaml?version=v0", "id": "ambitious-sloth", "type": "model", "format_version": "0.5.5", "status": "failed", "metadata_completeness": 0.75, "details": [{"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/cover.png?version=v0": null, "https://github.com/kreshuklab/hylfm-net": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/README.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_input.npy?version=v0": null, "test_input.npy": "39d9cb7a8aeca76e4c915ab21b3ef317429dba81b8fef601fe7a0b18f1338538", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_input.tif?version=v0": null, "sample_input.tif": "dc47897c483e5ba42965b00171cbf5b96de33c4bf46b0521cb888358657c8f37", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_output.npy?version=v0": null, "test_output.npy": "5c31cdd9d99e67fd10f9d387b4315dc978257c8805e2c8300621212b4a122ef7", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_output.tif?version=v0": null, "sample_output.tif": "15eb3df516c6c7dd06b23f11f4b0ea5479c342d9fb9a88c870e0e75f48103733", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.onnx?version=v0": null, "weights.onnx": "55ad061651840fe4b6da6733c52402ae3296392f74fed8a9482e4bc62040938f", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/model.py?version=v0": null, "model.py": "67c4280cdbd1d815888b9247d80b0af9ad8f525d6b5c802797a908e795db93fc", "weights.pt": "461f1151d7fea5857ce8f9ceaf9cdf08b5f78ce41785725e39a77d154ccea90a", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights_torchscript.pt?version=v0": null, "weights_torchscript.pt": "ec01e0c212b5eb422dda208af004665799637a2f2729d0ebf2e884e5d9966fc2"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.5.5", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/cover.png?version=v0": null, "https://github.com/kreshuklab/hylfm-net": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/README.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_input.npy?version=v0": null, "test_input.npy": "39d9cb7a8aeca76e4c915ab21b3ef317429dba81b8fef601fe7a0b18f1338538", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_input.tif?version=v0": null, "sample_input.tif": "dc47897c483e5ba42965b00171cbf5b96de33c4bf46b0521cb888358657c8f37", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_output.npy?version=v0": null, "test_output.npy": "5c31cdd9d99e67fd10f9d387b4315dc978257c8805e2c8300621212b4a122ef7", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_output.tif?version=v0": null, "sample_output.tif": "15eb3df516c6c7dd06b23f11f4b0ea5479c342d9fb9a88c870e0e75f48103733", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.onnx?version=v0": null, "weights.onnx": "55ad061651840fe4b6da6733c52402ae3296392f74fed8a9482e4bc62040938f", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/model.py?version=v0": null, "model.py": "67c4280cdbd1d815888b9247d80b0af9ad8f525d6b5c802797a908e795db93fc", "weights.pt": "461f1151d7fea5857ce8f9ceaf9cdf08b5f78ce41785725e39a77d154ccea90a", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights_torchscript.pt?version=v0": null, "weights_torchscript.pt": "ec01e0c212b5eb422dda208af004665799637a2f2729d0ebf2e884e5d9966fc2"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (onnx)", "status": "passed", "loc": ["weights", "onnx"], "errors": [], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "onnxruntime", "pip"]}, "saved_conda_compare": "Success. All the packages in the specification file are present in the environment with matching version and build string.\n"}, {"name": "Run onnx inference for inputs with batch_size: 1 and size parameter n: 0", "status": "passed", "loc": ["weights", "onnx"], "errors": [], "warnings": [], "context": null, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (pytorch_state_dict)", "status": "failed", "loc": ["weights", "pytorch_state_dict"], "errors": [{"loc": ["weights", "pytorch_state_dict"], "msg": "No module named 'torch'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    774 \u2502   \u2502   test_input = get_test_input_sample(model)                                         \u2502\n\u2502    775 \u2502   \u2502   expected = get_test_output_sample(model)                                          \u2502\n\u2502    776 \u2502   \u2502                                                                                     \u2502\n\u2502 \u2771  777 \u2502   \u2502   with create_prediction_pipeline(                                                  \u2502\n\u2502    778 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format          \u2502\n\u2502    779 \u2502   \u2502   ) as prediction_pipeline:                                                         \u2502\n\u2502    780 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(test_input)     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   107 \u2502   \u2502   \u2502   if wf == \"pytorch_state_dict\":                                                 \u2502\n\u2502   108 \u2502   \u2502   \u2502   \u2502   assert weights.pytorch_state_dict is not None                              \u2502\n\u2502   109 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502 \u2771 110 \u2502   \u2502   \u2502   \u2502   \u2502   from .pytorch_backend import PytorchModelAdapter                       \u2502\n\u2502   111 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502   112 \u2502   \u2502   \u2502   \u2502   \u2502   return PytorchModelAdapter(                                            \u2502\n\u2502   113 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502     5 from pathlib import Path                                                                   \u2502\n\u2502     6 from typing import Any, List, Literal, Optional, Sequence, Union                           \u2502\n\u2502     7                                                                                            \u2502\n\u2502 \u2771   8 import torch                                                                               \u2502\n\u2502     9 from loguru import logger                                                                  \u2502\n\u2502    10 from numpy.typing import NDArray                                                           \u2502\n\u2502    11 from torch import nn                                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nModuleNotFoundError: No module named 'torch'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #808000; text-decoration-color: #808000}\n.r7 {color: #00ffff; text-decoration-color: #00ffff}\n.r8 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r9 {font-weight: bold; text-decoration: underline}\n.r10 {color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold; text-decoration: underline}\n.r11 {color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline}\n.r12 {color: #808080; text-decoration-color: #808080}\n.r13 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r14 {color: #808080; text-decoration-color: #808080; font-weight: bold; text-decoration: underline}\n.r15 {color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline}\n.r16 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r17 {color: #008000; text-decoration-color: #008000}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 774 </span><span class=\"r4\">\u2502   \u2502   </span>test_input = get_test_input_sample(model)                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 775 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_output_sample(model)                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 776 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 777 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 778 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 779 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 780 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(test_input)     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r6\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r7\">set</span>(deprecated_kwargs)<span class=\"r6\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r8\">or</span> <span class=\"r9\">create_model_adapter(</span>                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r9\">model_description=bioimageio_model,</span>                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r9\">devices=devices,</span>                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r9\">weight_format_priority_order=weights_format </span><span class=\"r10\">and</span><span class=\"r9\"> (weights_format,),</span>                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r7\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r7\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r11\">raise</span><span class=\"r9\"> errors[</span><span class=\"r11\">0</span><span class=\"r9\">]</span>                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">107 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">if</span> wf == <span class=\"r6\">&quot;pytorch_state_dict&quot;</span>:                                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">108 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> weights.pytorch_state_dict <span class=\"r8\">is</span> <span class=\"r8\">not</span> <span class=\"r5\">None</span>                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">109 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>110 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r12\"> </span><span class=\"r13\">.pytorch_backend</span><span class=\"r12\"> </span><span class=\"r5\">import</span> PytorchModelAdapter                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">111 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">112 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> PytorchModelAdapter(                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">113 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">  5 </span><span class=\"r5\">from</span><span class=\"r12\"> </span><span class=\"r13\">pathlib</span><span class=\"r12\"> </span><span class=\"r5\">import</span> Path                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">  6 </span><span class=\"r5\">from</span><span class=\"r12\"> </span><span class=\"r13\">typing</span><span class=\"r12\"> </span><span class=\"r5\">import</span> Any, List, Literal, Optional, Sequence, Union                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">  7 </span>                                                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>  8 <span class=\"r11\">import</span><span class=\"r14\"> </span><span class=\"r15\">torch</span>                                                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">  9 </span><span class=\"r5\">from</span><span class=\"r12\"> </span><span class=\"r13\">loguru</span><span class=\"r12\"> </span><span class=\"r5\">import</span> logger                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 10 </span><span class=\"r5\">from</span><span class=\"r12\"> </span><span class=\"r13\">numpy.typing</span><span class=\"r12\"> </span><span class=\"r5\">import</span> NDArray                                                           <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 11 </span><span class=\"r5\">from</span><span class=\"r12\"> </span><span class=\"r13\">torch</span><span class=\"r12\"> </span><span class=\"r5\">import</span> nn                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r16\">ModuleNotFoundError: </span>No module named <span class=\"r17\">&#x27;torch&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["pytorch", "conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "mkl ==2024.0.0", "numpy <2", "pip", "pytorch==1.13.0", "setuptools <70.0.0", "torchaudio==0.13.0", "torchvision==0.14.0"]}, "saved_conda_compare": "mkl not found\nnumpy found but mismatch. Specification pkg: numpy[version='<2'], Running pkg: numpy=2.3.4=py313hf6604e3_0\npytorch not found\nsetuptools found but mismatch. Specification pkg: setuptools[version='<70.0.0'], Running pkg: setuptools=80.9.0=pyhff2d567_0\ntorchaudio not found\ntorchvision not found\n"}, {"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/cover.png?version=v0": null, "https://github.com/kreshuklab/hylfm-net": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/README.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_input.npy?version=v0": null, "test_input.npy": "39d9cb7a8aeca76e4c915ab21b3ef317429dba81b8fef601fe7a0b18f1338538", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_input.tif?version=v0": null, "sample_input.tif": "dc47897c483e5ba42965b00171cbf5b96de33c4bf46b0521cb888358657c8f37", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_output.npy?version=v0": null, "test_output.npy": "5c31cdd9d99e67fd10f9d387b4315dc978257c8805e2c8300621212b4a122ef7", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_output.tif?version=v0": null, "sample_output.tif": "15eb3df516c6c7dd06b23f11f4b0ea5479c342d9fb9a88c870e0e75f48103733", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.onnx?version=v0": null, "weights.onnx": "55ad061651840fe4b6da6733c52402ae3296392f74fed8a9482e4bc62040938f", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/model.py?version=v0": null, "model.py": "67c4280cdbd1d815888b9247d80b0af9ad8f525d6b5c802797a908e795db93fc", "weights.pt": "461f1151d7fea5857ce8f9ceaf9cdf08b5f78ce41785725e39a77d154ccea90a", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights_torchscript.pt?version=v0": null, "weights_torchscript.pt": "ec01e0c212b5eb422dda208af004665799637a2f2729d0ebf2e884e5d9966fc2"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.5.5", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/cover.png?version=v0": null, "https://github.com/kreshuklab/hylfm-net": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/README.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_input.npy?version=v0": null, "test_input.npy": "39d9cb7a8aeca76e4c915ab21b3ef317429dba81b8fef601fe7a0b18f1338538", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_input.tif?version=v0": null, "sample_input.tif": "dc47897c483e5ba42965b00171cbf5b96de33c4bf46b0521cb888358657c8f37", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_output.npy?version=v0": null, "test_output.npy": "5c31cdd9d99e67fd10f9d387b4315dc978257c8805e2c8300621212b4a122ef7", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_output.tif?version=v0": null, "sample_output.tif": "15eb3df516c6c7dd06b23f11f4b0ea5479c342d9fb9a88c870e0e75f48103733", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.onnx?version=v0": null, "weights.onnx": "55ad061651840fe4b6da6733c52402ae3296392f74fed8a9482e4bc62040938f", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/model.py?version=v0": null, "model.py": "67c4280cdbd1d815888b9247d80b0af9ad8f525d6b5c802797a908e795db93fc", "weights.pt": "461f1151d7fea5857ce8f9ceaf9cdf08b5f78ce41785725e39a77d154ccea90a", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights_torchscript.pt?version=v0": null, "weights_torchscript.pt": "ec01e0c212b5eb422dda208af004665799637a2f2729d0ebf2e884e5d9966fc2"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (onnx)", "status": "failed", "loc": ["weights", "onnx"], "errors": [{"loc": ["weights", "onnx"], "msg": "No module named 'onnxruntime'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    774 \u2502   \u2502   test_input = get_test_input_sample(model)                                         \u2502\n\u2502    775 \u2502   \u2502   expected = get_test_output_sample(model)                                          \u2502\n\u2502    776 \u2502   \u2502                                                                                     \u2502\n\u2502 \u2771  777 \u2502   \u2502   with create_prediction_pipeline(                                                  \u2502\n\u2502    778 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format          \u2502\n\u2502    779 \u2502   \u2502   ) as prediction_pipeline:                                                         \u2502\n\u2502    780 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(test_input)     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   127 \u2502   \u2502   \u2502   elif wf == \"onnx\":                                                             \u2502\n\u2502   128 \u2502   \u2502   \u2502   \u2502   assert weights.onnx is not None                                            \u2502\n\u2502   129 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502 \u2771 130 \u2502   \u2502   \u2502   \u2502   \u2502   from .onnx_backend import ONNXModelAdapter                             \u2502\n\u2502   131 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502   132 \u2502   \u2502   \u2502   \u2502   \u2502   return ONNXModelAdapter(                                               \u2502\n\u2502   133 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    2 import warnings                                                                             \u2502\n\u2502    3 from typing import Any, List, Optional, Sequence, Union                                     \u2502\n\u2502    4                                                                                             \u2502\n\u2502 \u2771  5 import onnxruntime as rt  # pyright: ignore[reportMissingTypeStubs]                         \u2502\n\u2502    6 from numpy.typing import NDArray                                                            \u2502\n\u2502    7                                                                                             \u2502\n\u2502    8 from bioimageio.spec.model import v0_4, v0_5                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nModuleNotFoundError: No module named 'onnxruntime'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #808000; text-decoration-color: #808000}\n.r7 {color: #00ffff; text-decoration-color: #00ffff}\n.r8 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r9 {color: #808080; text-decoration-color: #808080}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r11 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r12 {color: #008000; text-decoration-color: #008000}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 774 </span><span class=\"r4\">\u2502   \u2502   </span>test_input = get_test_input_sample(model)                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 775 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_output_sample(model)                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 776 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 777 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 778 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 779 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 780 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(test_input)     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r6\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r7\">set</span>(deprecated_kwargs)<span class=\"r6\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r8\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r8\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r7\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r7\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">127 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">elif</span> wf == <span class=\"r6\">&quot;onnx&quot;</span>:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">128 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> weights.onnx <span class=\"r8\">is</span> <span class=\"r8\">not</span> <span class=\"r5\">None</span>                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">129 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>130 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">.onnx_backend</span><span class=\"r9\"> </span><span class=\"r5\">import</span> ONNXModelAdapter                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">131 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> ONNXModelAdapter(                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 2 </span><span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">warnings</span>                                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 3 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> Any, List, Optional, Sequence, Union                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 4 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 5 <span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">onnxruntime</span><span class=\"r9\"> </span><span class=\"r5\">as</span><span class=\"r9\"> </span><span class=\"r10\">rt</span>  <span class=\"r4\"># pyright: ignore[reportMissingTypeStubs]</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 6 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">numpy.typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> NDArray                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 7 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 8 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">bioimageio.spec.model</span><span class=\"r9\"> </span><span class=\"r5\">import</span> v0_4, v0_5                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r11\">ModuleNotFoundError: </span>No module named <span class=\"r12\">&#x27;onnxruntime&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "onnxruntime", "pip"]}, "saved_conda_compare": "onnxruntime not found\n"}, {"name": "Successfully created `ModelDescr` instance.", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/cover.png?version=v0": null, "https://github.com/kreshuklab/hylfm-net": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/README.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_input.npy?version=v0": null, "test_input.npy": "39d9cb7a8aeca76e4c915ab21b3ef317429dba81b8fef601fe7a0b18f1338538", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_input.tif?version=v0": null, "sample_input.tif": "dc47897c483e5ba42965b00171cbf5b96de33c4bf46b0521cb888358657c8f37", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_output.npy?version=v0": null, "test_output.npy": "5c31cdd9d99e67fd10f9d387b4315dc978257c8805e2c8300621212b4a122ef7", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_output.tif?version=v0": null, "sample_output.tif": "15eb3df516c6c7dd06b23f11f4b0ea5479c342d9fb9a88c870e0e75f48103733", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.onnx?version=v0": null, "weights.onnx": "55ad061651840fe4b6da6733c52402ae3296392f74fed8a9482e4bc62040938f", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/model.py?version=v0": null, "model.py": "67c4280cdbd1d815888b9247d80b0af9ad8f525d6b5c802797a908e795db93fc", "weights.pt": "461f1151d7fea5857ce8f9ceaf9cdf08b5f78ce41785725e39a77d154ccea90a", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights_torchscript.pt?version=v0": null, "weights_torchscript.pt": "ec01e0c212b5eb422dda208af004665799637a2f2729d0ebf2e884e5d9966fc2"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "bioimageio.spec format validation model 0.5.5", "status": "passed", "loc": [], "errors": [], "warnings": [], "context": {"file_name": "rdf.yaml", "original_source_name": null, "perform_io_checks": true, "known_files": {"https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/cover.png?version=v0": null, "https://github.com/kreshuklab/hylfm-net": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/README.md?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_input.npy?version=v0": null, "test_input.npy": "39d9cb7a8aeca76e4c915ab21b3ef317429dba81b8fef601fe7a0b18f1338538", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_input.tif?version=v0": null, "sample_input.tif": "dc47897c483e5ba42965b00171cbf5b96de33c4bf46b0521cb888358657c8f37", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/test_output.npy?version=v0": null, "test_output.npy": "5c31cdd9d99e67fd10f9d387b4315dc978257c8805e2c8300621212b4a122ef7", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/sample_output.tif?version=v0": null, "sample_output.tif": "15eb3df516c6c7dd06b23f11f4b0ea5479c342d9fb9a88c870e0e75f48103733", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.onnx?version=v0": null, "weights.onnx": "55ad061651840fe4b6da6733c52402ae3296392f74fed8a9482e4bc62040938f", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights.pt?version=v0": null, "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/model.py?version=v0": null, "model.py": "67c4280cdbd1d815888b9247d80b0af9ad8f525d6b5c802797a908e795db93fc", "weights.pt": "461f1151d7fea5857ce8f9ceaf9cdf08b5f78ce41785725e39a77d154ccea90a", "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files/weights_torchscript.pt?version=v0": null, "weights_torchscript.pt": "ec01e0c212b5eb422dda208af004665799637a2f2729d0ebf2e884e5d9966fc2"}, "update_hashes": false, "root": "https://hypha.aicell.io/bioimage-io/artifacts/ambitious-sloth/files?version=v0"}, "recommended_env": null, "saved_conda_compare": null}, {"name": "Reproduce test outputs from test inputs (onnx)", "status": "failed", "loc": ["weights", "onnx"], "errors": [{"loc": ["weights", "onnx"], "msg": "No module named 'onnxruntime'", "type": "bioimageio.core", "with_traceback": true, "traceback_md": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    774 \u2502   \u2502   test_input = get_test_input_sample(model)                                         \u2502\n\u2502    775 \u2502   \u2502   expected = get_test_output_sample(model)                                          \u2502\n\u2502    776 \u2502   \u2502                                                                                     \u2502\n\u2502 \u2771  777 \u2502   \u2502   with create_prediction_pipeline(                                                  \u2502\n\u2502    778 \u2502   \u2502   \u2502   bioimageio_model=model, devices=devices, weight_format=weight_format          \u2502\n\u2502    779 \u2502   \u2502   ) as prediction_pipeline:                                                         \u2502\n\u2502    780 \u2502   \u2502   \u2502   results = prediction_pipeline.predict_sample_without_blocking(test_input)     \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   368 \u2502   \u2502   \u2502   f\"deprecated create_prediction_pipeline kwargs: {set(deprecated_kwargs)}\"      \u2502\n\u2502   369 \u2502   \u2502   )                                                                                  \u2502\n\u2502   370 \u2502                                                                                          \u2502\n\u2502 \u2771 371 \u2502   model_adapter = model_adapter or create_model_adapter(                                 \u2502\n\u2502   372 \u2502   \u2502   model_description=bioimageio_model,                                                \u2502\n\u2502   373 \u2502   \u2502   devices=devices,                                                                   \u2502\n\u2502   374 \u2502   \u2502   weight_format_priority_order=weights_format and (weights_format,),                 \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   166 \u2502   \u2502   assert errors                                                                      \u2502\n\u2502   167 \u2502   \u2502   if len(weight_format_priority_order) == 1:                                         \u2502\n\u2502   168 \u2502   \u2502   \u2502   assert len(errors) == 1                                                        \u2502\n\u2502 \u2771 169 \u2502   \u2502   \u2502   raise errors[0]                                                                \u2502\n\u2502   170 \u2502   \u2502                                                                                      \u2502\n\u2502   171 \u2502   \u2502   else:                                                                              \u2502\n\u2502   172 \u2502   \u2502   \u2502   msg = (                                                                        \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502   127 \u2502   \u2502   \u2502   elif wf == \"onnx\":                                                             \u2502\n\u2502   128 \u2502   \u2502   \u2502   \u2502   assert weights.onnx is not None                                            \u2502\n\u2502   129 \u2502   \u2502   \u2502   \u2502   try:                                                                       \u2502\n\u2502 \u2771 130 \u2502   \u2502   \u2502   \u2502   \u2502   from .onnx_backend import ONNXModelAdapter                             \u2502\n\u2502   131 \u2502   \u2502   \u2502   \u2502   \u2502                                                                          \u2502\n\u2502   132 \u2502   \u2502   \u2502   \u2502   \u2502   return ONNXModelAdapter(                                               \u2502\n\u2502   133 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   model_description=model_description, devices=devices               \u2502\n\u2502                                                                                                  \u2502\n\u2502 /usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p \u2502\n\u2502                                                                                                  \u2502\n\u2502    2 import warnings                                                                             \u2502\n\u2502    3 from typing import Any, List, Optional, Sequence, Union                                     \u2502\n\u2502    4                                                                                             \u2502\n\u2502 \u2771  5 import onnxruntime as rt  # pyright: ignore[reportMissingTypeStubs]                         \u2502\n\u2502    6 from numpy.typing import NDArray                                                            \u2502\n\u2502    7                                                                                             \u2502\n\u2502    8 from bioimageio.spec.model import v0_4, v0_5                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\nModuleNotFoundError: No module named 'onnxruntime'\n", "traceback_html": "<!DOCTYPE html>\n<html>\n<head>\n<meta charset=\"UTF-8\">\n<style>\n.r1 {color: #800000; text-decoration-color: #800000}\n.r2 {color: #800000; text-decoration-color: #800000; font-weight: bold}\n.r3 {color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold}\n.r4 {color: #7f7f7f; text-decoration-color: #7f7f7f}\n.r5 {color: #0000ff; text-decoration-color: #0000ff}\n.r6 {color: #808000; text-decoration-color: #808000}\n.r7 {color: #00ffff; text-decoration-color: #00ffff}\n.r8 {color: #ff00ff; text-decoration-color: #ff00ff}\n.r9 {color: #808080; text-decoration-color: #808080}\n.r10 {color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline}\n.r11 {color: #ff0000; text-decoration-color: #ff0000; font-weight: bold}\n.r12 {color: #008000; text-decoration-color: #008000}\nbody {\n    color: #000000;\n    background-color: #ffffff;\n}\n</style>\n</head>\n<body>\n    <pre style=\"font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span class=\"r2\">Traceback </span><span class=\"r3\">(most recent call last)</span><span class=\"r1\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 774 </span><span class=\"r4\">\u2502   \u2502   </span>test_input = get_test_input_sample(model)                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 775 </span><span class=\"r4\">\u2502   \u2502   </span>expected = get_test_output_sample(model)                                          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 776 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 777 <span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">with</span> create_prediction_pipeline(                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 778 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>bioimageio_model=model, devices=devices, weight_format=weight_format          <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 779 </span><span class=\"r4\">\u2502   \u2502   </span>) <span class=\"r5\">as</span> prediction_pipeline:                                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 780 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>results = prediction_pipeline.predict_sample_without_blocking(test_input)     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">368 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r6\">f&quot;deprecated create_prediction_pipeline kwargs: {</span><span class=\"r7\">set</span>(deprecated_kwargs)<span class=\"r6\">}&quot;</span>      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">369 </span><span class=\"r4\">\u2502   \u2502   </span>)                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">370 </span><span class=\"r4\">\u2502   </span>                                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>371 <span class=\"r4\">\u2502   </span>model_adapter = model_adapter <span class=\"r8\">or</span> create_model_adapter(                                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">372 </span><span class=\"r4\">\u2502   \u2502   </span>model_description=bioimageio_model,                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">373 </span><span class=\"r4\">\u2502   \u2502   </span>devices=devices,                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">374 </span><span class=\"r4\">\u2502   \u2502   </span>weight_format_priority_order=weights_format <span class=\"r8\">and</span> (weights_format,),                 <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">166 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">assert</span> errors                                                                      <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">167 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">if</span> <span class=\"r7\">len</span>(weight_format_priority_order) == <span class=\"r5\">1</span>:                                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">168 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> <span class=\"r7\">len</span>(errors) == <span class=\"r5\">1</span>                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>169 <span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">raise</span> errors[<span class=\"r5\">0</span>]                                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">170 </span><span class=\"r4\">\u2502   \u2502   </span>                                                                                   <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">171 </span><span class=\"r4\">\u2502   \u2502   </span><span class=\"r5\">else</span>:                                                                              <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">172 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span>msg = (                                                                        <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">127 </span><span class=\"r4\">\u2502   \u2502   \u2502   </span><span class=\"r5\">elif</span> wf == <span class=\"r6\">&quot;onnx&quot;</span>:                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">128 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">assert</span> weights.onnx <span class=\"r8\">is</span> <span class=\"r8\">not</span> <span class=\"r5\">None</span>                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">129 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">try</span>:                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span>130 <span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">.onnx_backend</span><span class=\"r9\"> </span><span class=\"r5\">import</span> ONNXModelAdapter                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">131 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span>                                                                       <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">132 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   </span><span class=\"r5\">return</span> ONNXModelAdapter(                                               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\">133 </span><span class=\"r4\">\u2502   \u2502   \u2502   \u2502   \u2502   \u2502   </span>model_description=model_description, devices=devices               <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r4\">/usr/share/miniconda/envs/e87a49b5469f491e36944738dbc7dbfd65d4861932e2cffdf644b4f3d28e3f8c/lib/p</span> <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>                                                                                                  <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 2 </span><span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">warnings</span>                                                                             <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 3 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> Any, List, Optional, Sequence, Union                                     <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 4 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span> <span class=\"r1\">\u2771 </span> 5 <span class=\"r5\">import</span><span class=\"r9\"> </span><span class=\"r10\">onnxruntime</span><span class=\"r9\"> </span><span class=\"r5\">as</span><span class=\"r9\"> </span><span class=\"r10\">rt</span>  <span class=\"r4\"># pyright: ignore[reportMissingTypeStubs]</span>                         <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 6 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">numpy.typing</span><span class=\"r9\"> </span><span class=\"r5\">import</span> NDArray                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 7 </span>                                                                                            <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2502</span>   <span class=\"r4\"> 8 </span><span class=\"r5\">from</span><span class=\"r9\"> </span><span class=\"r10\">bioimageio.spec.model</span><span class=\"r9\"> </span><span class=\"r5\">import</span> v0_4, v0_5                                                <span class=\"r1\">\u2502</span>\n<span class=\"r1\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n<span class=\"r11\">ModuleNotFoundError: </span>No module named <span class=\"r12\">&#x27;onnxruntime&#x27;</span>\n</code></pre>\n</body>\n</html>\n"}], "warnings": [], "context": null, "recommended_env": {"name": null, "channels": ["conda-forge", "nodefaults"], "dependencies": ["conda-forge::bioimageio.core", "onnxruntime", "pip"]}, "saved_conda_compare": "onnxruntime not found\n"}], "env": [["bioimageio.spec", "0.5.5.6", "", ""], ["bioimageio.core", "0.9.4", "", ""]], "saved_conda_list": "# packages in environment at /usr/share/miniconda/envs/95227f474ca45b024cf315edb4101e4919199d0a79ef5ff1eb474dc8ce1ec4d8:\n#\n# Name                     Version          Build                    Channel\n_libgcc_mutex              0.1              conda_forge              conda-forge\n_openmp_mutex              4.5              2_gnu                    conda-forge\nannotated-types            0.7.0            pyhd8ed1ab_1             conda-forge\nanyio                      4.11.0           pyhcf101f3_0             conda-forge\naom                        3.9.1            hac33072_0               conda-forge\nbioimageio.core            0.9.4            pyhd8ed1ab_0             conda-forge\nbioimageio.spec            0.5.5.6          pyhd8ed1ab_0             conda-forge\nblosc                      1.21.6           he440d0b_1               conda-forge\nbrunsli                    0.1              he3183e4_1               conda-forge\nbzip2                      1.0.8            hda65f42_8               conda-forge\nc-ares                     1.34.5           hb9d3cd8_0               conda-forge\nc-blosc2                   2.21.3           h4cfbee9_0               conda-forge\nca-certificates            2025.10.5        hbd8a1cb_0               conda-forge\ncached-property            1.5.2            hd8ed1ab_1               conda-forge\ncached_property            1.5.2            pyha770c72_1             conda-forge\ncertifi                    2025.10.5        pyhd8ed1ab_0             conda-forge\ncharls                     2.4.2            h59595ed_0               conda-forge\ncolorama                   0.4.6            pyhd8ed1ab_1             conda-forge\ncoloredlogs                15.0.1           pyhd8ed1ab_4             conda-forge\ncpython                    3.13.9           py313hd8ed1ab_101        conda-forge\ndav1d                      1.2.1            hd590300_0               conda-forge\ndistro                     1.9.0            pyhd8ed1ab_1             conda-forge\ndnspython                  2.8.0            pyhcf101f3_0             conda-forge\nemail-validator            2.3.0            pyhd8ed1ab_0             conda-forge\nemail_validator            2.3.0            hd8ed1ab_0               conda-forge\nexceptiongroup             1.3.0            pyhd8ed1ab_0             conda-forge\nfilelock                   3.20.0           pyhd8ed1ab_0             conda-forge\ngenericache                0.5.2            pyhd8ed1ab_0             conda-forge\ngiflib                     5.2.2            hd590300_0               conda-forge\ngmp                        6.3.0            hac33072_2               conda-forge\ngmpy2                      2.2.1            py313h86d8783_1          conda-forge\nh11                        0.16.0           pyhd8ed1ab_0             conda-forge\nh2                         4.3.0            pyhcf101f3_0             conda-forge\nh5py                       3.15.1           nompi_py313h253c126_100  conda-forge\nhdf5                       1.14.6           nompi_h6e4c0c1_103       conda-forge\nhpack                      4.1.0            pyhd8ed1ab_0             conda-forge\nhttpcore                   1.0.9            pyh29332c3_0             conda-forge\nhttpx                      0.28.1           pyhd8ed1ab_0             conda-forge\nhumanfriendly              10.0             pyh707e725_8             conda-forge\nhyperframe                 6.1.0            pyhd8ed1ab_0             conda-forge\nidna                       3.11             pyhd8ed1ab_0             conda-forge\nimagecodecs                2025.8.2         py313h718aa22_4          conda-forge\nimageio                    2.37.0           pyhfb79c49_0             conda-forge\nimportlib-metadata         8.7.0            pyhe01879c_1             conda-forge\njxrlib                     1.1              hd590300_3               conda-forge\nkeyutils                   1.6.3            hb9d3cd8_0               conda-forge\nkrb5                       1.21.3           h659f571_0               conda-forge\nlcms2                      2.17             h717163a_0               conda-forge\nld_impl_linux-64           2.44             ha97dd6f_2               conda-forge\nlerc                       4.0.0            h0aef613_1               conda-forge\nlibabseil                  20250814.1       cxx17_hee66210_0         conda-forge\nlibaec                     1.1.4            h3f801dc_0               conda-forge\nlibavif16                  1.3.0            h6395336_2               conda-forge\nlibblas                    3.9.0            37_h4a7cf45_openblas     conda-forge\nlibbrotlicommon            1.1.0            hb03c661_4               conda-forge\nlibbrotlidec               1.1.0            hb03c661_4               conda-forge\nlibbrotlienc               1.1.0            hb03c661_4               conda-forge\nlibcblas                   3.9.0            37_h0358290_openblas     conda-forge\nlibcurl                    8.16.0           h4e3cde8_0               conda-forge\nlibdeflate                 1.24             h86f0d12_0               conda-forge\nlibedit                    3.1.20250104     pl5321h7949ede_0         conda-forge\nlibev                      4.33             hd590300_2               conda-forge\nlibexpat                   2.7.1            hecca717_0               conda-forge\nlibffi                     3.5.2            h9ec8514_0               conda-forge\nlibfreetype                2.14.1           ha770c72_0               conda-forge\nlibfreetype6               2.14.1           h73754d4_0               conda-forge\nlibgcc                     15.2.0           h767d61c_7               conda-forge\nlibgcc-ng                  15.2.0           h69a702a_7               conda-forge\nlibgfortran                15.2.0           h69a702a_7               conda-forge\nlibgfortran5               15.2.0           hcd61629_7               conda-forge\nlibgomp                    15.2.0           h767d61c_7               conda-forge\nlibhwy                     1.3.0            h4c17acf_1               conda-forge\nlibjpeg-turbo              3.1.0            hb9d3cd8_0               conda-forge\nlibjxl                     0.11.1           h6cb5226_4               conda-forge\nliblapack                  3.9.0            37_h47877c9_openblas     conda-forge\nliblzma                    5.8.1            hb9d3cd8_2               conda-forge\nlibmpdec                   4.0.0            hb9d3cd8_0               conda-forge\nlibnghttp2                 1.67.0           had1ee68_0               conda-forge\nlibopenblas                0.3.30           pthreads_h94d23a6_2      conda-forge\nlibpng                     1.6.50           h421ea60_1               conda-forge\nlibsqlite                  3.50.4           h0c1763c_0               conda-forge\nlibssh2                    1.11.1           hcf80075_0               conda-forge\nlibstdcxx                  15.2.0           h8f9b012_7               conda-forge\nlibstdcxx-ng               15.2.0           h4852527_7               conda-forge\nlibtiff                    4.7.1            h8261f1e_0               conda-forge\nlibuuid                    2.41.2           he9a06e4_0               conda-forge\nlibwebp-base               1.6.0            hd42ef1d_0               conda-forge\nlibxcb                     1.17.0           h8a09558_0               conda-forge\nlibzlib                    1.3.1            hb9d3cd8_2               conda-forge\nlibzopfli                  1.0.3            h9c3ff4c_0               conda-forge\nloguru                     0.7.3            pyh707e725_0             conda-forge\nlz4-c                      1.10.0           h5888daf_1               conda-forge\nmarkdown                   3.9              pyhd8ed1ab_0             conda-forge\nmarkdown-it-py             4.0.0            pyhd8ed1ab_0             conda-forge\nmdurl                      0.1.2            pyhd8ed1ab_1             conda-forge\nmpc                        1.3.1            h24ddda3_1               conda-forge\nmpfr                       4.2.1            h90cbb55_3               conda-forge\nmpmath                     1.3.0            pyhd8ed1ab_1             conda-forge\nncurses                    6.5              h2d0b736_3               conda-forge\nnumpy                      2.3.4            py313hf6604e3_0          conda-forge\nonnxruntime                1.22.0           py313hd753461_0_cpu      conda-forge\nopenjpeg                   2.5.4            h55fea9a_0               conda-forge\nopenssl                    3.5.4            h26f9b46_0               conda-forge\npackaging                  25.0             pyh29332c3_1             conda-forge\npandas                     2.3.3            py313h08cd8bf_1          conda-forge\npillow                     11.3.0           py313ha492abd_3          conda-forge\npip                        25.2             pyh145f28c_0             conda-forge\nplatformdirs               4.5.0            pyhcf101f3_0             conda-forge\nprotobuf                   6.32.1           py313h50fafe1_2          conda-forge\npthread-stubs              0.4              hb9d3cd8_1002            conda-forge\npydantic                   2.11.10          pyh3cfb1c2_0             conda-forge\npydantic-core              2.33.2           py313h4b2b08d_0          conda-forge\npydantic-settings          2.11.0           pyh3cfb1c2_0             conda-forge\npygments                   2.19.2           pyhd8ed1ab_0             conda-forge\npython                     3.13.9           hc97d973_101_cp313       conda-forge\npython-dateutil            2.9.0.post0      pyhe01879c_2             conda-forge\npython-dotenv              1.1.1            pyhe01879c_0             conda-forge\npython-flatbuffers         25.9.23          pyh1e1bc0e_0             conda-forge\npython-tzdata              2025.2           pyhd8ed1ab_0             conda-forge\npython_abi                 3.13             8_cp313                  conda-forge\npytz                       2025.2           pyhd8ed1ab_0             conda-forge\nrav1e                      0.7.1            h8fae777_3               conda-forge\nreadline                   8.2              h8c095d6_2               conda-forge\nrich                       14.2.0           pyhcf101f3_0             conda-forge\nruyaml                     0.91.0           pyhd8ed1ab_1             conda-forge\nscipy                      1.16.2           py313h11c21cd_0          conda-forge\nsetuptools                 80.9.0           pyhff2d567_0             conda-forge\nsix                        1.17.0           pyhe01879c_1             conda-forge\nsnappy                     1.2.2            h03e3b7b_0               conda-forge\nsniffio                    1.3.1            pyhd8ed1ab_1             conda-forge\nsvt-av1                    3.1.2            hecca717_0               conda-forge\nsympy                      1.14.0           pyh2585a3b_105           conda-forge\ntifffile                   2025.10.16       pyhd8ed1ab_0             conda-forge\ntk                         8.6.13           noxft_hd72426e_102       conda-forge\ntqdm                       4.67.1           pyhd8ed1ab_1             conda-forge\ntyping-extensions          4.15.0           h396c80c_0               conda-forge\ntyping-inspection          0.4.2            pyhd8ed1ab_0             conda-forge\ntyping_extensions          4.15.0           pyhcf101f3_0             conda-forge\ntzdata                     2025b            h78e105d_0               conda-forge\nxarray                     2025.1.2         pyhd8ed1ab_0             conda-forge\nxorg-libxau                1.0.12           hb9d3cd8_0               conda-forge\nxorg-libxdmcp              1.1.5            hb9d3cd8_0               conda-forge\nzfp                        1.0.1            h909a3a2_3               conda-forge\nzipp                       3.23.0           pyhd8ed1ab_0             conda-forge\nzlib-ng                    2.2.5            hde8ca8f_0               conda-forge\nzstd                       1.5.7            hb8e6e7a_2               conda-forge\n"}, "badge": null, "links": []}